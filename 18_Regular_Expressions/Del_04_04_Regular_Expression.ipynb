{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 04: Parsanje, analiza podatkov in generiranje poročil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are used to identify whether a pattern exists in a given sequence of characters (string) or not. They help in manipulating textual data, which is often a pre-requisite for data science projects that involve text mining. You must have come across some application of regular expressions: they are used at the server side to validate the format of email addresses or password during registration, used for parsing text data files to find, replace or delete certain string, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> String containing a combination of normal characters and special meta characters that describes patterns to find text or positions within a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As powerful as regular expressions are, they can be difficult to learn at first and the syntax can look visually intimidating. As a result, a lot of students end up disliking regular expressions and try to avoid using them, instead opting to write more cumbersome code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That said, learning (and loving!) regular expressions is something that is a worthwhile investment\n",
    "- Once you understand how they work, complex operations with string data can be written a lot quicker, which will save you time.\n",
    "- Regular expressions are often faster to execute than their manual equivalents.\n",
    "- Regular expressions are supported in almost every modern programming language, as well as other places like command line utilities and databases. Understanding regular expressions gives you a powerful tool that you can use wherever you work with data.\n",
    "We could probably fill a whole Dataquest course with the intricacies of regular expressions, but instead we're going to give you a two-mission tour of the main components.\n",
    "\n",
    "One thing to keep in mind before we start: don't expect to remember all of the regular expression syntax. The most important thing is to understand the core principles, what is possible, and where to look up the details. This will mean you can quickly jog your memory whenever you need regular expressions.\n",
    "\n",
    "With that in mind, don't be put off if some things in these missions don't stick in your memory. As long as you are able to write and understand regular expressions with the help of documentation and/or other reference guides, you have all the skills you need to excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Online tester](https://regexr.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Regular Expression Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with regular expressions, we use the term pattern to describe a regular expression that we've written. If the pattern is found within the string we're searching, we say that it has matched.\n",
    "\n",
    "As we previously learned, letters and numbers represent themselves in regular expressions. If we wanted to find the string \"and\" within another string, the regex pattern for that is simply and:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, regular expressions are supported by the re module. That means that if you want to start using them in your Python scripts, you have to import this module with the help of import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[re — Regular expression operations](https://docs.python.org/3/library/re.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both patterns and strings to be searched can be Unicode strings (str) as well as 8-bit strings (bytes). However, Unicode strings and 8-bit strings cannot be mixed: that is, you cannot match a Unicode string with a byte pattern or vice-versa; similarly, when asking for a substitution, the replacement string must be of the same type as both the pattern and the search string.\n",
    "\n",
    "Regular expressions use the backslash character ('\\') to indicate special forms or to allow special characters to be used without invoking their special meaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to use Python’s raw string notation for regular expression patterns; backslashes are not handled in any special way in a string literal prefixed with 'r'. So r\"\\n\" is a two-character string containing '\\' and 'n', while \"\\n\" is a one-character string containing a newline. Usually patterns will be expressed in Python code using this raw string notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, a backslash followed by certain characters represents an escape sequence — like the \\n sequence — which we previously learned represents a new line. These escape sequences can result in unintended consequences for our regular expressions. Let's take a look at a string containing the substring \\b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\b world\n"
     ]
    }
   ],
   "source": [
    "print('hello\\b world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The escape sequence \\b represents a backspace, so the final letter from our string is removed. The character sequence \\b has a special meaning in regular expressions (which we'll learn about later), so we need a way to write these characters without triggering the escape sequence.\n",
    "\n",
    "One way is to add an extra backslash before the \"b\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\\b world\n"
     ]
    }
   ],
   "source": [
    "print('hello\\\\b world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can make regular expressions even more difficult to read and interpret, so instead we use raw strings, which we denote by prefixing our string with the r character. Let's take a look at the code from above with a raw string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\\b world\n"
     ]
    }
   ],
   "source": [
    "print(r'hello\\b world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We strongly recommend using raw strings for every regex you write, rather than remember which sequences are escape sequences and using raw strings selectively. That way, you'll never encounter a situation where you forget or overlook something which causes your regex to break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have an object representing a compiled regular expression, what do you do with it? Pattern objects have several methods and attributes. Only the most significant ones will be covered here; consult the re docs for a complete listing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 28%\">\n",
    "<col style=\"width: 72%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Method/Attribute</p></th>\n",
    "<th class=\"head\"><p>Purpose</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">match()</span></code></p></td>\n",
    "<td><p>Determine if the RE matches at the beginning\n",
    "of the string.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">search()</span></code></p></td>\n",
    "<td><p>Scan through a string, looking for any\n",
    "location where this RE matches.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">findall()</span></code></p></td>\n",
    "<td><p>Find all substrings where the RE matches, and\n",
    "returns them as a list.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">finditer()</span></code></p></td>\n",
    "<td><p>Find all substrings where the RE matches, and\n",
    "returns them as an <a class=\"reference internal\" href=\"../glossary.html#term-iterator\"><span class=\"xref std std-term\">iterator</span></a>.</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match() and search() return None if no match can be found. If they’re successful, a match object instance is returned, containing information about the match: where it starts and ends, the substring it matched, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.match(pattern, string, flags=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If zero or more characters at the beginning of string match this regular expression, return a corresponding match object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return None if the string does not match the pattern; note that this is different from a zero-length match. Note that even in MULTILINE mode, re.match() will only match at the beginning of the string and not at the beginning of each line.\n",
    "If you want to locate a match anywhere in string, use search() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(re.match(r'dog', 'today is dog day'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='dog'>\n"
     ]
    }
   ],
   "source": [
    "match = re.match(r'dog', 'dog day is today')\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can query the match object for information about the matching string. Match object instances also have several methods and attributes; the most important ones are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"docutils align-default\">\n",
    "<colgroup>\n",
    "<col style=\"width: 29%\">\n",
    "<col style=\"width: 71%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Method/Attribute</p></th>\n",
    "<th class=\"head\"><p>Purpose</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">group()</span></code></p></td>\n",
    "<td><p>Return the string matched by the RE</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">start()</span></code></p></td>\n",
    "<td><p>Return the starting position of the match</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">end()</span></code></p></td>\n",
    "<td><p>Return the ending position of the match</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">span()</span></code></p></td>\n",
    "<td><p>Return a tuple containing the (start, end)\n",
    "positions  of the match</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group() returns the substring that was matched by the RE. start() and end() return the starting and ending index of the match. span() returns both start and end indexes in a single tuple. Since the match() method only checks if the RE matches at the start of a string, start() will always be zero. However, the search() method of patterns scans through the string, so the match may not start at zero in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.search(pattern, string, flags=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan through string looking for the first location where the regular expression pattern produces a match, and return a corresponding match object. Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 4), match='and'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"and\", \"hand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In actual programs, the most common style is to store the match object in a variable, and then check if it was None. This usually looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found:  and\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r\"and\", \"hand\")\n",
    "if m:\n",
    "    print('Match found: ', m.group())\n",
    "else:\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Python offers two different primitive operations based on regular expressions: re.match() checks for a match only at the beginning of the string, while re.search() checks for a match anywhere in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.findall(r'regex', string)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all matches of a pattern. \n",
    "\n",
    "Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movies', 'movies']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"movies\", \"Love movies! I had fun yesterday going to the movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.finditer(pattern, string, flags=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return an iterator yielding match objects over all non-overlapping matches for the RE pattern in string. The string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findall() has to create the entire list before it can be returned as the result. The finditer() method returns a sequence of match object instances as an iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator= re.finditer(r\"movies\", \"Love movies! I had fun yesterday going to the movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<callable_iterator at 0x7f8895fb6f10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 11)\n",
      "(46, 52)\n"
     ]
    }
   ],
   "source": [
    "for match in iterator:\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.split(r'regex', string)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split string at each match: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nice Place to eat', \" I'll come back\", ' Excellent meat', '']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r\"!\", \"Nice Place to eat! I'll come back! Excellent meat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.sub(r'regex', new, string)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace one or many matches with a string: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have a nice car and a nice house in a nice neighborhood'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"yellow\", \"nice\", \"I have a yellow car and a yellow house in a yellow neighborhood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `re.fullmatch(pattern, string, flags=0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the whole string matches the regular expression pattern, return a corresponding match object.: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the whole string matches the regular expression pattern, return a corresponding match object. Return None if the string does not match the pattern; note that this is different from a zero-length match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first of these we'll learn is called a set. A set allows us to specify two or more characters that can match in a single character's position.\n",
    "\n",
    "We define a set by placing the characters we want to match for in square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = [\"Julie's favorite color is Blue.\",\n",
    "               \"Keli's favorite color is Green.\",\n",
    "               \"Craig's favorite colors are blue and red.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely, you'll notice the first string contains the substring Blue with a capital letter, where the third string contains the substring blue in all lowercase. We can use the set [Bb] for the first character so that we can match both variations, and then use that to count how many times Blue or blue occur in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "blue_mentions = 0\n",
    "pattern = r\"[Bb]lue\"\n",
    "\n",
    "for s in string_list:\n",
    "    if re.search(pattern, s):\n",
    "        blue_mentions += 1\n",
    "\n",
    "print(blue_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use this technique to find out how many times Python is mentioned in the title of stories in our Hacker News dataset. We'll use a set to check for both Python with a capital 'P' and python with a lowercase 'p'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "hn = pd.read_csv('data/hacker_news.csv')\n",
    "titles = hn[\"title\"].tolist()\n",
    "python_mentions = 0\n",
    "pattern = r\"[Pp]ython\"\n",
    "\n",
    "for t in titles:\n",
    "    if re.search(pattern, t):\n",
    "        python_mentions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regular Expressions to Select Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous two screens, we used regular expressions to count how many titles contain Python or python. What if we wanted to view those titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_titles = []\n",
    "for t in titles:\n",
    "    if re.search(pattern, t):\n",
    "        python_titles.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From Python to Lua: Why We Switched',\n",
       " 'Ubuntu 16.04 LTS to Ship Without Python 2',\n",
       " 'Create a GUI Application Using Qt and Python in Minutes',\n",
       " \"How I Solved GCHQ's Xmas Card with Python and Pycosat. (Explanation and Source)\",\n",
       " 'Unikernel Power Comes to Java, Node.js, Go, and Python Apps',\n",
       " 'Developing a computational pipeline using the asyncio module in Python 3',\n",
       " 'Show HN: Minimal, modern embedded V8 for Python',\n",
       " 'Python integration for the Duktape Javascript interpreter',\n",
       " 'Python 3 on Google App Engine flexible environment now in beta',\n",
       " 'IronPython 3 (python for .net) development restarted']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've learned how to perform simple matches with sets, and how to use quantifiers to specify when a character should repeat a certain number of times. Let's continue by looking at a more complex example.\n",
    "\n",
    "Some stories submitted to Hacker News include a topic tag in brackets, like [pdf]. Here are a few examples of story titles with these tags:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    [video] Google Self-Driving SUV Sideswipes Bus\n",
    "    New Directions in Cryptography by Diffie and Hellman (1976) [pdf]\n",
    "    Wallace and Gromit  The Great Train Chase (1993) [video]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this screen, our task is going to be to find how many titles in our dataset have tags.\n",
    "\n",
    "Our first inclination may be to create the regex [pdf]. Unfortunately, the brackets would be interpreted as a set, so our pattern would match the single characters p, d, or f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match the substring \"[pdf]\", we can use backslashes to escape both the open and closing brackets: \\[pdf\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other critical part of our task of identifying how many titles have tags is knowing how to match the characters between the brackets (like pdf and video) without knowing ahead of time what the different topic tags will be.\n",
    "\n",
    "To match unknown characters using regular expressions, we use character classes. Character classes allow us to match certain groups of characters. We've actually seen two examples of character classes already:\n",
    "- The set notation using brackets to match any of a number of characters.\n",
    "- The range notation, which we used to match ranges of digits (like [0-9]).\n",
    "\n",
    "Let's look at a summary of syntax for some of the regex character classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"character classes one\" src=\"https://s3.amazonaws.com/dq-content/354/character_classes_v2_1.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two new things we can observe from this table:\n",
    "- Ranges can be used for letters as well as numbers.\n",
    "- Sets and ranges can be combined.\n",
    "\n",
    "Just like with quantifiers, there are some other common character classes which we'll use a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"character classes two\" src=\"https://s3.amazonaws.com/dq-content/354/character_classes_v2_2.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative character classes are character classes that match every character except a character class. Let's look at a table of the common negative character classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"negative character classes\" src=\"https://s3.amazonaws.com/dq-content/354/negative_character_classes.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja1: Are they bots?\n",
    "\n",
    "The company that you are working for asked you to perform a sentiment analysis using a dataset with tweets. First of all, you need to do some cleaning and extract some information.\n",
    "While printing out some text, you realize that some tweets contain user mentions. Some of these mentions follow a very strange pattern. A few examples that you notice: @robot3!, @robot5& and @robot7#\n",
    "\n",
    "To analyze if those users are bots, you will do a proof of concept with one tweet and extract them using the .findall() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/short_tweets.csv') as f:\n",
    "    sentiment_analysis = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The advantage of regular expressions is that you can use both normal characters and metacharacters. You can easily extract complex patterns, which would be more complicated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja2: Find the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While examining the tweet text in your dataset, you detect that some tweets carry extra information. The text contains the number of retweets, user mentions, and likes of that tweet. So, you decide to extract this important information.\n",
    "\n",
    "The information is given as in this example:\n",
    "\n",
    "Agh...snow! User_mentions:9, likes: 5, number of retweets: 4\n",
    "\n",
    "You also bring your list of metacharacters: \\d digit, \\w word character, \\s whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of retweets\n",
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using metacharacters in regular expressions will allow you to match types of characters such as digits. Remember to always specify whitespaces as \\s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja3: Match and split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the tweets in your dataset were downloaded incorrectly. Instead of having spaces to separate words, they have strange characters. You decide to use regular expressions to handle this situation. You print some of these tweets to understand which pattern you need to match.\n",
    "\n",
    "You notice that the sentences are always separated by a special character, followed by a number, the word break, and after that, another special character, e.g &4break!. The words are always separated by a special character, the word new, and a normal random character, e.g #newH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "#print(re.findall(regex_sentence, sentiment_analysis))\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, ' ', sentiment_analysis)\n",
    "#print(re.findall(regex_sentence, sentiment_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, ' ', sentiment_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetitions / Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Validate the following string: password1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "password = \"password1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 12), match='password1234'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"\\w\\w\\w\\w\\w\\w\\w\\w\\d\\d\\d\\d\", password) # vidimo da to ni najlepše"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Quantiers:\n",
    "A metacharacter that tells the regex\n",
    "engine how many times to match a\n",
    "character immediately to its left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name for this type of regular expression syntax is called a quantifier. Quantifiers specify how many of the previous character our pattern requires, which can help us when we want to match substrings of specific lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific type of quantifier we saw above is called a numeric quantifier. Here are the different types of numeric quantifiers we can use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"quantifiers\" src=\"https://s3.amazonaws.com/dq-content/354/quantifiers_numeric.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the last two examples above omit the first and last character as wildcards, in the same way that we can omit the first or last indicies when slicing lists.\n",
    "\n",
    "In addition to numeric quantifiers, there are single characters in regex that specify some common quantifiers that you're likely to use. A summary of them is below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"quantifiers\" src=\"https://s3.amazonaws.com/dq-content/354/quantifiers_other.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Once or more: +`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Date of start: 4-3. Date of registration: 10-04.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-3', '10-04']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\d+-\\d+\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Zero times or more: *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@ameli!a', '@joh&&n', '@mary90']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"The concert was amazing! @ameli!a @joh&&n @mary90\"\n",
    "re.findall(r\"@\\w+\\W*\\w+\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Zero times or once: ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color', 'colour']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The color of this image is amazing. However, the colour blue could be brighter.\"\n",
    "re.findall(r\"colou?r\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `n times at least, m times at most : {n, m}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_number = \"John: 1-966-847-3131 Michelle: 54-908-42-42424\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-966-847-3131', '54-908-42-42424']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\d{1,2}-\\d{3}-\\d{2,3}-\\d{4,}\", phone_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Immediately to the left `r\"apple+` : + applies to e and not to apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 4: Everything clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to your Twitter sentiment analysis project! There are several types of strings that increase your sentiment analysis complexity. But these strings do not provide any useful sentiment. Among them, we can have links and user mentions.\n",
    "\n",
    "In order to clean the tweets, you want to extract some examples first. You know that most of the times links start with http and do not contain any whitespace, e.g. https://www.datacamp.com. User mentions start with @ and can have letters and numbers only, e.g. @johnsmith3.\n",
    "\n",
    "You write down some helpful quantifiers to help you: * zero or more times, + once or more, ? zero or once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['0,1467962897,Mon Apr 06 23:01:04 PDT 2009,NO_QUERY,aleskywalker,@nick_carter Come to the chat  just 15 minutes  please? http://fanclub.backstreetboys.com/chat.php',\n",
    "'0,1467962938,Mon Apr 06 23:01:04 PDT 2009,NO_QUERY,jess___x,Boredd. Colddd @blueKnight39 Internet keeps stuffing up. Save me! https://www.tellyourstory.com',\n",
    "'0,1467963418,Mon Apr 06 23:01:14 PDT 2009,NO_QUERY,Zimily,\"I had a horrible nightmare last night @anitaLopez98 @MyredHat31 which affected my sleep, now I\\'m really tired\"',\n",
    "'0,1467963477,Mon Apr 06 23:01:15 PDT 2009,NO_QUERY,Augustina22,\"im lonely  keep me company @YourBestCompany! @foxRadio https://radio.foxnews.com 22 female, new york\"',\n",
    "'0,1467963715,Mon Apr 06 23:01:18 PDT 2009,NO_QUERY,missmadison,@Born_4_Broadway Lost  and it was St. Ignacius Prepatory School. Haha.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://fanclub.backstreetboys.com/chat.php']\n",
      "['@nick_carter']\n",
      "['https://www.tellyourstory.com']\n",
      "['@blueKnight39']\n",
      "[]\n",
      "['@anitaLopez98', '@MyredHat31']\n",
      "['https://radio.foxnews.com']\n",
      "['@YourBestCompany', '@foxRadio']\n",
      "[]\n",
      "['@Born_4_Broadway']\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Write regex to match http links and print out result\n",
    "    print(re.findall(r\"http\\S+\", tweet))\n",
    "\n",
    "    # Write regex to match user mentions and print out result\n",
    "    print(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions provide very useful metacharacters that you should not forget to use. \\S is an example. It is very useful to use when you know a pattern doesn't contain spaces and you have reached the end when you do find one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 5: Some time ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I would like to apologize for the repeated Video Games Live related tweets. 32 minutes ago', '@zaydia but i cant figure out how to get there / back / pay for a hotel 1st May 2019', 'FML: So much for seniority, bc of technological ineptness 23rd June 2018 17:54']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are interested in knowing when the tweets were posted. After reading a little bit more, you learn that dates are provided in different ways. You decide to extract the dates using .findall() so you can normalize them afterwards to make them all look the same.\n",
    "\n",
    "You realize that the dates are always presented in one of the following ways:\n",
    "- 27 minutes ago\n",
    "- 4 hours ago\n",
    "- 23rd june 2018\n",
    "- 1st september 2019 17:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['32 minutes ago']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates, 27 minutes ago or 4 hours ago\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\s\\w+\\s\\w+\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['1st May 2019']\n",
      "['23rd June 2018']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates, 23rd june 2018\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\", date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['23rd June 2018 17:54']\n"
     ]
    }
   ],
   "source": [
    "# Complete the for loop with a regex to find dates, 1st september 2019 17:25\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{1,2}:\\d{2}\", date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling dates can become a really difficult task. Fortunately, regular expressions can simplify this task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 6: Getting tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next step is to tokenize the text of your tweets. Tokenization is the process of breaking a string into lexical units or, in simpler terms, words. But first, you need to remove hashtags so they do not cloud your process. You realize that hashtags start with a # symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens.\n",
    "\n",
    "You bring your list of quantifiers to help you: * zero o more times, + once or more, ? zero or once, {n, m} minimum n, maximum m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ITS NOT ENOUGH TO SAY THAT IMISS U    '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions can be very useful when replacing and splitting string using complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex metacharacters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Match any character (except newline): .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_links = \"Just check out this link: www.amazingpics.com. It has amazing photos!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"www com\", my_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are often scenarios where we want to specifically match a pattern at the start and end of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the word boundary anchor, the other two most common anchors are the beginning anchor and the end anchor, which represent the start and the end of the string, respectfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"positional anchors\" src=\"https://s3.amazonaws.com/dq-content/354/positional_anchors.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ^ character is used both as a beginning anchor and to indicate a negative set, depending on whether the character preceding it is a [ or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.amazingpics.com']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"www.+com\", my_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Start ofthe string: ^`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"the 80s music was much better that the 90s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 80s', 'the 90s']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"the\\s\\d+s\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 80s']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"^the\\s\\d+s\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `End ofthe string: $`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"the 80s music hits were much better that the 90s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the 90s']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"the\\s\\d+s$\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Escape special characters: \\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"I love the music of Mr.Go. However, the sound was too loud.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'lov', 'th', 'musi', 'o', 'Mr.Go', 'However', 'th', 'soun', 'wa', 'to', 'loud.']\n"
     ]
    }
   ],
   "source": [
    "print(re.split(r\".\\s\", my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love the music of Mr.Go', 'However, the sound was too loud.']\n"
     ]
    }
   ],
   "source": [
    "print(re.split(r\"\\.\\s\", my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `OR operator: Set of characters: [ ]`\n",
    "- `OR operator: Character: |`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"Elephants are the world's largest land animal! I would love to see an elephant one day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephant', 'elephant']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"Elephant|elephant\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"Yesterday I spent my afternoon with my friends: MaryJohn2 Clary3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MaryJohn2', 'Clary3']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"[a-zA-Z]+\\d\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_string = \"My&name&is#John Smith. I%live$in#London.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is John Smith. I live in London.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"[#$%&]\", \" \", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Set of characters: [ ], ^ transforms the expression to negative`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.hola.com']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_links = \"Bad website: www.99.com. Favorite site: www.hola.com\"\n",
    "re.findall(r\"www[^0-9]+com\", my_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 7: Finding files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not satisfied with your tweets dataset cleaning. There are still extra strings that do not provide any sentiment. Among them are strings refer to text file names.\n",
    "\n",
    "You also find a way to detect them:\n",
    "- They appear at the start of the string.\n",
    "- They always start with a sequence of 2 or 3 upper or lowercase vowels (a e i o u).\n",
    "- They always finish with the txt ending.\n",
    "\n",
    "You are not sure if you should remove them directly. So you write a script to find and store them in a separate dataset.\n",
    "\n",
    "You write down some metacharacters to help you: ^ anchor to beginning, . any character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['AIshadowhunters.txt aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company',\n",
    " \"ouMYTAXES.txt I am worried that I won't get my $900 even though I paid tax last year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIshadowhunters.txt']\n",
      " aaaaand back to my literature review. At least i have a friendly cup of coffee to keep me company\n",
      "['ouMYTAXES.txt']\n",
      " I am worried that I won't get my $900 even though I paid tax last year\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"^[aeiouAEIOU]{2,3}.+txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "    # Find all matches of the regex\n",
    "    print(re.findall(regex, text))\n",
    "\n",
    "    # Replace all matches with empty string\n",
    "    print(re.sub(regex, '', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot . metacharacter is very useful when we want to match all repetitions of any character. However, we need to very careful how we use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 8: Give me your email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A colleague has asked for your help! When a user signs up on the company website, they must provide a valid email address.\n",
    "The company puts some rules in place to verify that the given email address is valid:\n",
    "- The first part can contain:\n",
    "    - Upper A-Z and lowercase letters a-z\n",
    "    - Numbers\n",
    "    - Characters: !, #, %, &, *, $, .\n",
    "- Must have @\n",
    "- Domain:\n",
    "    - Can contain any word characters\n",
    "    - But only .com ending is allowed\n",
    "    \n",
    "The project consist of writing a script that checks if the email address follow the correct pattern. Your colleague gave you a list of email addresses as examples to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = ['n.john.smith@gmail.com', '87victory@hotmail.com', '!#mary-=@msca.net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email n.john.smith@gmail.com is a valid email\n",
      "The email 87victory@hotmail.com is a valid email\n",
      "The email !#mary-=@msca.net is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"[A-Za-z-0-9!#%&*$~.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "    # Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "        print(f\"The email {example} is a valid email\")\n",
    "    else:\n",
    "        print(f\"The email {example} is invalid\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating strings is a task that becomes simpler when we use regular expressions. Square brackets are very useful for optional characters. Notice that we used the .match() method. The reason is that we want to match the pattern from the beginning of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 9: Invalid password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second part of the website project is to write a script that validates the password entered by the user. The company also puts some rules in order to verify valid passwords:\n",
    "- It can contain lowercase a-z and uppercase letters A-Z\n",
    "- It can contain numbers\n",
    "- It can contain the symbols: *, #, $, %, !, &, .\n",
    "- It must be at least 8 characters long but not more than 20\n",
    "\n",
    "Your colleague also gave you a list of passwords as examples to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = ['Apple34!rose', 'My87hou#4$', 'abc123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The password Apple34!rose is a valid password\n",
      "The password My87hou#4$ is a valid password\n",
      "The password abc123 is invalid\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match a valid password\n",
    "regex = r\"[a-zA-Z0-9!#%&*$~\\.]{8,20}\"\n",
    "\n",
    "for example in passwords:\n",
    "    # Scan the strings to find a match\n",
    "    if re.search(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "        print(f\"The password {example} is a valid password\")\n",
    "    else:\n",
    "        print(f\"The password {example} is invalid\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used the .search() method. The reason is that we want to scan the string to match the pattern. We are not interested in where the regex finds the match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Flags to Modify Regex Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we've been using sets like [Pp] to match different capitalizations in our regular expressions. This strategy works well when there is only one character that has capitalization, but becomes cumbersome when we need to cater for multiple instances.\n",
    "\n",
    "Within the titles, there are many different formatting styles used to represent the word \"email.\" Here is a list of the variations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "email_tests = ['email', 'Email', 'e Mail', 'e mail', 'E-mail', 'e-mail', 'eMail', 'E-Mail', 'EMAIL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write a regular expression for this, we would need to use a set for all five letters in email, which would make our regular expression very hard to read.\n",
    "\n",
    "Instead, we can use flags to specify that our regular expression should ignore case.\n",
    "\n",
    "Both re.search() and the pandas regular expression methods accept an optional flags argument. This argument accepts one or more flags, which are special variables in the re module that modify the behavior of the regex interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A <a target=\"_blank\" href=\"https://docs.python.org/3/library/re.html#re.A\">list of all available flags</a> is in the documentation, but by far the most common and the most useful is the <a target=\"_blank\" href=\"https://docs.python.org/3/library/re.html#re.I\"><code>re.IGNORECASE</code> flag</a>, which is also available using the alias <code>re.I</code> for convenience.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"e[\\-\\s]?mail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match='email'>\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(0, 6), match='e mail'>\n",
      "None\n",
      "<re.Match object; span=(0, 6), match='e-mail'>\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# without flag\n",
    "for email in email_tests:\n",
    "    print(re.match(pattern, email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match='email'>\n",
      "<re.Match object; span=(0, 5), match='Email'>\n",
      "<re.Match object; span=(0, 6), match='e Mail'>\n",
      "<re.Match object; span=(0, 6), match='e mail'>\n",
      "<re.Match object; span=(0, 6), match='E-mail'>\n",
      "<re.Match object; span=(0, 6), match='e-mail'>\n",
      "<re.Match object; span=(0, 5), match='eMail'>\n",
      "<re.Match object; span=(0, 6), match='E-Mail'>\n",
      "<re.Match object; span=(0, 5), match='EMAIL'>\n"
     ]
    }
   ],
   "source": [
    "for email in email_tests:\n",
    "    print(re.match(pattern, email, flags=re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy versus Non-Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of matching methods:\n",
    "- Greedy\n",
    "- Non-greedy or lazy\n",
    "\n",
    "Standard quantiers are greedy by default: * , + , ? , {num, num}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Greedy: match as many characters as possible`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the longest match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='12345'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\"\\d+\", \"12345bcada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backtracks when too many character matched. Gives up characters one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='xhello'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\".*hello\", \"xhelloxxxxxx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Lazy: match as few characters as needed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the shortest match. Append ? to greedy quantiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='1'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\"\\d+?\", \"12345bcada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backtracks when too few characters matched. Expands characters one a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='xhello'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(r\".*?hello\", \"xhelloxxxxxx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When repeating a regular expression, as in a\\*, the resulting action is to consume as much of the pattern as possible. This fact often bites you when you’re trying to match a pair of balanced delimiters, such as the angle brackets surrounding an HTML tag. The naive pattern for matching a single HTML tag doesn’t work because of the greedy nature of .\\*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '<html><head><title>Title</title>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 32)\n"
     ]
    }
   ],
   "source": [
    "print(re.match('<.*>', s).span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>Title</title>\n"
     ]
    }
   ],
   "source": [
    "print(re.match('<.*>', s).group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the solution is to use the non-greedy qualifiers *?, +?, ??, or {m,n}?, which match as little text as possible. In the above example, the '>' is tried immediately after the first '<' matches, and when it fails, the engine advances a character at a time, retrying the '>' at every step. This produces just the right result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n"
     ]
    }
   ],
   "source": [
    "print(re.match('<.*?>', s).group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that parsing HTML or XML with regular expressions is painful. Quick-and-dirty patterns will handle common cases, but HTML and XML have special cases that will break the obvious regular expression; by the time you’ve written a regular expression that handles all of the possible cases, the patterns will be very complicated. Use an HTML or XML parser module for such tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 10: Understanding the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to keep working and cleaning your tweets dataset. You realize that there are some HTML tags present. You need to remove them but keep the inside content as they are useful for analysis.\n",
    "\n",
    "Let's take a look at this sentence containing an HTML tag:\n",
    "\n",
    "    I want to see that <strong>amazing show</strong> again!.\n",
    "\n",
    "You know that for getting HTML tag you need to match anything that sits inside angle brackets < >. But the biggest problem is that the closing tag has the same structure. If you match too much, you will end up removing key information. So you need to decide whether to use a greedy or a lazy quantifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'I want to see that <strong>amazing show</strong> again!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to see that amazing show again!\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "#string_notags = re.sub(r\"<.+>\", \"\", string) # greedy\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a greedy quantifier will try to match as much as possible while a non-greedy quantifier will do it as few times as needed, expanding one character at a time and giving us the match we are looking for. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 11: Greedy matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you see that numbers still appear in the text of the tweets. So, you decide to find all of them.\n",
    "\n",
    "Let's imagine that you want to extract the number contained in the sentence I was born on April 24th. A lazy quantifier will make the regex return 2 and 4, because they will match as few characters as needed. However, a greedy quantifier will return the entire 24 due to its need to match as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'Was intending to finish editing my 536-page novel manuscript tonight, but that will probably not happen. And only 12 pages are left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '3', '6', '1', '2']\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression \n",
    "numbers_found_lazy = re.findall(r\"\\d+?\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['536', '12']\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression \n",
    "numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though greedy quantifiers lead to longer matches, they are sometimes the best option. Because lazy quantifiers match as few as possible, they return a shorter match than we expected. It is always good to know when to use greedy and lazy quantifiers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 12: Lazy approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have done some cleaning in your dataset but you are worried that there are sentences encased in parentheses that may cloud your analysis.\n",
    "\n",
    "Again, a greedy or a lazy quantifier may lead to different results.\n",
    "\n",
    "For example, if you want to extract a word starting with a and ending with e in the string I like apple pie, you may think that applying the greedy regex a.+e will return apple. However, your match will be apple pie. A way to overcome this is to make it lazy by using ? which will return apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = \"Put vacation photos online (They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"(They were so cute) a few yrs ago. PC crashed, and now I forget the name of the site (I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a greedy regex expression to match \n",
    "sentences_found_greedy = re.findall(r\"\\(.+\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(sentences_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(They were so cute)', \"(I'm crying)\"]\n"
     ]
    }
   ],
   "source": [
    "# Write a lazy regex expression\n",
    "sentences_found_lazy = re.findall(r\"\\(.+?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the results\n",
    "print(sentences_found_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that using greedy quantifiers always leads to longer matches that sometimes are not desired. Making quantifiers lazy by adding ? to match a shorter pattern is a very important consideration to keep in mind when handling data for text mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a capture group by wrapping the part of our pattern we want to capture in parentheses. If we want to capture the whole pattern, we just wrap the whole pattern in a pair of parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Clary has 2 friends who she spends a lot time with. Susan has 3 brothers while John has 4 sisters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clary has 2 friends', 'Susan has 3 brothers', 'John has 4 sisters']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[A-Za-z]+\\s\\w+\\s\\d+\\s\\w+', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use parentheses to group and capture characters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clary', 'Susan', 'John']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('([A-Za-z]+)\\s\\w+\\s\\d+\\s\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Clary', '2', 'friends'),\n",
       " ('Susan', '3', 'brothers'),\n",
       " ('John', '4', 'sisters')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('([A-Za-z]+)\\s\\w+\\s(\\d+)\\s(\\w+)', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Match a specic subpattern in a pattern\n",
    "- Use it for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Clary', '2', 'dogs'), ('John', '3', 'cats')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets = re.findall('([A-Za-z]+)\\s\\w+\\s(\\d+)\\s(\\w+)', \"Clary has 2 dogs but John has 3 cats\")\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clary'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply a quantier to the entire group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(16, 22), match='3e4r5f'>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"(\\d[A-Za-z])+\", \"My user name is 3e4r5fg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Capture a repeated group (\\d+) vs. repeat a capturing group (\\d)+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '3']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"My lucky numbers are 8755 and 33\"\n",
    "re.findall(r\"(\\d)+\", my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8755', '33']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"(\\d+)\", my_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 13: Try another name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are still working on your Twitter sentiment analysis. You analyze now some things that caught your attention. You noticed that there are email addresses inserted in some tweets. Now, you are curious to find out which is the most common name.\n",
    "\n",
    "You want to extract the first part of the email. E.g. if you have the email marysmith90@gmail.com, you are only interested in marysmith90.\n",
    "You need to match the entire expression. So you make sure to extract only names present in emails. Also, you are only interested in names containing upper (e.g. A,B, Z) or lowercase letters (e.g. a, d, z) and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices', 'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.', 'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r\"([A-Za-z0-9]+)@\\S+\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print(f\"Lists of users found in this tweet: {email_matched}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Remember that placing a subpattern inside parenthesis will capture that content and stores it temporarily in memory. This can be later reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 14: Flying home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your boss assigned you to a small project. They are performing an analysis of the travels people made to attend business meetings. You are given a dataset with only the email subjects for each of the people traveling.\n",
    "\n",
    "You learn that the text followed a pattern. Here is an example:\n",
    "\n",
    "Here you have your boarding pass LA4214 AER-CDB 06NOV.\n",
    "\n",
    "You need to extract the information about the flight:\n",
    "\n",
    "- The two letters indicate the airline (e.g LA),\n",
    "- The 4 numbers are the flight number (e.g. 4214).\n",
    "- The three letters correspond to the departure (e.g AER),\n",
    "- The destination (CDB),\n",
    "- The date (06NOV) of the flight.\n",
    "\n",
    "All letters are always uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('IB', '3723', 'AMS', 'MAD', '06OCT')]\n",
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, text)\n",
    "\n",
    "print(flight_matches)\n",
    "\n",
    "#Print the matches\n",
    "print(f\"Airline: {flight_matches[0][0]} Flight number: {flight_matches[0][1]}\")\n",
    "print(f\"Departure: {flight_matches[0][2]} Destination: {flight_matches[0][3]}\")\n",
    "print(f\"Date: {flight_matches[0][4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findall() returns a list of tuples. The nth element of each tuple is the element corresponding to group n. This provides us with an easy way to access and organize our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 15: Extracting URL Parts Using Multiple Capture Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task we will be performing first is extracting the different components of the URLs in order to analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls = [\n",
    " 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
    " 'http://www.interactivedynamicvideo.com/',\n",
    " 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
    " 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',\n",
    " 'HTTPS://github.com/keppel/pinn',\n",
    " 'Http://phys.org/news/2015-09-scale-solar-youve.html',\n",
    " 'https://iot.seeed.cc',\n",
    " 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',\n",
    " 'http://beta.crowdfireapp.com/?beta=agnipath',\n",
    " 'https://www.valid.ly?param'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Protocol\n",
    "- Domain\n",
    "- Page path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this, we'll create a regular expression with multiple capture groups. Multiple capture groups in regular expressions are defined the same way as single capture groups — using pairs of parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https', 'www.amazon.com', 'Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429')]\n",
      "[('http', 'www.interactivedynamicvideo.com', '')]\n",
      "[('http', 'www.nytimes.com', '2007/11/07/movies/07stein.html?_r=0')]\n",
      "[('http', 'evonomics.com', 'advertising-cannot-maintain-internet-heres-solution/')]\n",
      "[('HTTPS', 'github.com', 'keppel/pinn')]\n",
      "[('Http', 'phys.org', 'news/2015-09-scale-solar-youve.html')]\n",
      "[('https', 'iot.seeed.cc', '')]\n",
      "[('http', 'www.bfilipek.com', '2016/04/custom-deleters-for-c-smart-pointers.html')]\n",
      "[('http', 'beta.crowdfireapp.com', '?beta=agnipath')]\n",
      "[('https', 'www.valid.ly', '?param')]\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"(.+)://([\\w\\.]+)/?(.*)\"\n",
    "results = []\n",
    "\n",
    "\n",
    "for url in test_urls:\n",
    "    comp = re.findall(pattern, url)\n",
    "    results.append(comp)\n",
    "    print(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('https',\n",
       "   'www.amazon.com',\n",
       "   'Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429')],\n",
       " [('http', 'www.interactivedynamicvideo.com', '')],\n",
       " [('http', 'www.nytimes.com', '2007/11/07/movies/07stein.html?_r=0')],\n",
       " [('http',\n",
       "   'evonomics.com',\n",
       "   'advertising-cannot-maintain-internet-heres-solution/')],\n",
       " [('HTTPS', 'github.com', 'keppel/pinn')],\n",
       " [('Http', 'phys.org', 'news/2015-09-scale-solar-youve.html')],\n",
       " [('https', 'iot.seeed.cc', '')],\n",
       " [('http',\n",
       "   'www.bfilipek.com',\n",
       "   '2016/04/custom-deleters-for-c-smart-pointers.html')],\n",
       " [('http', 'beta.crowdfireapp.com', '?beta=agnipath')],\n",
       " [('https', 'www.valid.ly', '?param')]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http', 6), ('https', 4)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count protocol\n",
    "Counter([result[0][0].lower() for result in results]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbered and named groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Numbered groups`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Python 3.0 was released on 12-03-2008.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = re.search('(\\d{1,2})-(\\d{2})-(\\d{4})', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(27, 37), match='12-03-2008'>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-03-2008'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Named groups`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to name a capture group we use the syntax ?P, where name is the name of our capture group. This syntax goes after the open parentheses, but before the regex syntax that defines the capture group:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (?P<name>regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Austin'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Austin, 78701\"\n",
    "cities = re.search(r\"(?P<city>[A-Za-z]+).*?(?P<zipcode>\\d{5})\", text)\n",
    "cities.group(\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78701'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.group(\"zipcode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 16: Parsing PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now need to work on another small project you have been delaying. Your company gave you some PDF files of signed contracts. The goal of the project is to create a database with the information you parse from them. Three of these columns should correspond to the day, month, and year when the contract was signed.\n",
    "The dates appear as Signed on 05/24/2016 (05 indicating the month, 24 the day). You decide to use capturing groups to extract this information. Also, you would like to retrieve that information so you can store it separately in different variables.\n",
    "\n",
    "You decide to do a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Provider’s status as an independent contractor. Signed on 03/25/2001.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "    \"day\": dates.group(2),\n",
    "    \"month\": dates.group(1),\n",
    "    \"year\": dates.group(3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    }
   ],
   "source": [
    "# Complete the format method to print-out\n",
    "print(f\"Our first contract is dated back to {signature['year']}. Particularly, the day {signature['day']} of the month {signature['month']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that each capturing group is assigned a number according to its position in the regex. Only if you use .search() and .match(), you can use .group() to retrieve the groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vaja 17: Extracting URL Parts Using Named Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https\n",
      "www.amazon.com\n",
      "Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429\n",
      "------------------\n",
      "http\n",
      "www.interactivedynamicvideo.com\n",
      "\n",
      "------------------\n",
      "http\n",
      "www.nytimes.com\n",
      "2007/11/07/movies/07stein.html?_r=0\n",
      "------------------\n",
      "http\n",
      "evonomics.com\n",
      "advertising-cannot-maintain-internet-heres-solution/\n",
      "------------------\n",
      "HTTPS\n",
      "github.com\n",
      "keppel/pinn\n",
      "------------------\n",
      "Http\n",
      "phys.org\n",
      "news/2015-09-scale-solar-youve.html\n",
      "------------------\n",
      "https\n",
      "iot.seeed.cc\n",
      "\n",
      "------------------\n",
      "http\n",
      "www.bfilipek.com\n",
      "2016/04/custom-deleters-for-c-smart-pointers.html\n",
      "------------------\n",
      "http\n",
      "beta.crowdfireapp.com\n",
      "?beta=agnipath\n",
      "------------------\n",
      "https\n",
      "www.valid.ly\n",
      "?param\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"(?P<protocol>.+)://(?P<domain>[\\w\\.]+)/?(?P<path>.*)\"\n",
    "\n",
    "for url in test_urls:\n",
    "    comp = re.search(pattern, url)\n",
    "    print(comp.group('protocol'))\n",
    "    print(comp.group('domain'))\n",
    "    print(comp.group('path'))\n",
    "    print('------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
