{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever had to work with a dataset so large that it overwhelmed your machine’s memory? Or maybe you have a complex function that needs to maintain an internal state every time it’s called, but the function is too small to justify creating its own class. In these cases and more, generators and the Python yield statement are here to help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python generators are a powerful, but misunderstood tool. They’re often treated as too difficult a concept for beginning programmers to learn — creating the illusion that beginners should hold off on learning generators until they are ready. I think this assessment is unfair, and that you can use generators sooner than you think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’ve never encountered a generator before, the most common real-life example of a generator is a backup generator, which creates —\n",
    "\n",
    "generates — electricity for your house or office. Conceptually, Python generators generate values one at a time from a given sequence, instead of giving the entirety of the sequence at once. This one-at-a-time fashion of generators is what makes them so compatible with for loops. If this sounds confusing, don’t worry too much. As we explain how to create generators, it will become more clear. There are two ways to create a generator. They differ in their syntax, but the end result is still a generator. We’ll teach these concepts by covering their syntax and comparing them to a similar, but non-generator equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primer če želimo narediti countdown funkcijo\n",
    "def countdown(num):\n",
    "    print('Starting')\n",
    "    while num > 0:\n",
    "        return num\n",
    "        num -= 1\n",
    "    print('Stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(countdown(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normal Python function will always return one value, whether it be a list, an integer or some other object. But what if you wanted to be able to call a function and have it yield a series of values? That is where generators come in. A generator works by “saving” where it last left off (or yielding) and giving the calling function a value. So instead of returning the execution to the caller, it just gives temporary control back. To do this magic, a generator function requires Python’s yield statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The generator function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator function is just like a regular function but with a key difference: the yield keyword replaces return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular function\n",
    "def function_a():\n",
    "    return \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function\n",
    "def generator_a():\n",
    "    yield \"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two functions above perform exactly same action (returning/yielding the same string). However, if you try to inspect the generator function, it won’t match what the regular function shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generator_a at 0x7f39bc2d9228>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a regular function tells Python to go back to where the function is located in our code, perform the code within the block, and return the result. In order to get the generator function to yield its values, you need to pass it into the next() function. next() is a special function that asks, “What’s the next item in the iteration?” In fact, next() is the precise function that is called when you run a for loop! Lists, dictionaries, strings, and the like all implement next(), so this is why you can incorporate them into loops in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generator_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asking the generator what the next item is\n",
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6f04a83eb931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Do not do this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do not do this\n",
    "next(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have to pass in generator function with the parentheses since the function itself is the generator. Providing only the function name will throw an error since you’re trying to give next() a function name. As expected, the generator function will yield “a” once we invoke the next() function. This example is not fully representative of what a generator is useful for. Remember that generators produce a stream of values, so yielding a single value doesn’t really qualify as a stream. To do this, we can actually put in multiple yield statements into a generator function. These yield statements form the sequence that the generator will output. We’ll create a generator and bind it to a varible mg. Then, if we keep passing mg into next(), we’ll get to the next yield. If we keep going past, we’ll be given a StopIteration error to tell us that the generator has no more values to give. The StopIteration error is actually how a for loop knows when to stop iterating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_generate():\n",
    "    yield \"a\"\n",
    "    yield \"b\"\n",
    "    yield \"c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg = multi_generate()\n",
    "next(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a88c2ad7c462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning multi_generate to mg is a crucial step in using a generator function. Binding a generator to mg allows us to create a single instance of a generator we can refer back to. We can continue passing mg into next() and get those other yield statements. Observe what happens if we just keep trying to pass in multi_generate itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(multi_generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(multi_generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s easy to think of generators as a machine that waits for one command and one command only: next(). Once you call next() on the generator, it will dispense the next value in the sequence it is holding. Otherwise, you can’t do much else with a generator. The image below represents our generator as a simple machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to get the result of the first yield statement. The reason behind this is subtle. When we pass the generator function itself into next(), Python assumes you are passing a new instance of multi_generate into it, so it will always give you the first yield result. By binding the generator to a variable, Python knows you are trying to act on the same thing when you pass it into next(). We’ve noted that as we keep passing in mg into next, we get the other yield results. This is possible only if the generator somehow remembers what it last did. This memory is what distinguishes generator functions from regular functions! Once you use a function, it’s a one-and-done deal. Once you return the value from the function. A generator will keep yielding values until its out. This brings us to another important property of generators. Once we’ve finished iterating through them, we can’t use them anymore. Once we got through all three yield values in mg, it can’t provide anything to us anymore. We’d have to store another instance of the multi_generate generator to begin asking next() statements of it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vaja: probajo prejšnji češit z genratorji\n",
    "def countdown(num):\n",
    "    print('Starting')\n",
    "    while num > 0:\n",
    "        yield num\n",
    "        num -= 1\n",
    "    print('Stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "c = countdown(3)\n",
    "print(next(c))\n",
    "print(next(c))\n",
    "print(next(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data still hasn’t been read in yet, so let’s do that with a generator function. The data is called recipeData.csv, and its contained in a CSV file. We’ll use the open() function to enable us to read it, and we’ll start using next() function to read what the first few lines of the CSV are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a generator that will generate the data row by row\n",
    "def beerDataGenerator():\n",
    "    file = \"data/recipeData.csv\"\n",
    "    with open(file, encoding=\"ISO-8859-1\") as f:\n",
    "        for row in f:\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python basically turns the file object into a generator when we iterate over it in this manner. This allows us to process files that are too large to load into memory. You will find generators useful for any large data set that you need to work with in chunks or when you need to generate a large data set that would otherwise fill up your all your computer’s memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll slowly dissect the above code:\n",
    "- We’ve designated dataGenerator as our generator function that will dispense our CSV file row by row. The function includes the name of the file in file, and this enables us to use the open() function to be able to read it.\n",
    "- While we’ve discussed that Python objects like lists and dictionaries can be iterated over, we can also iterate over files that we open() as well.\n",
    "- The encoding tells Python what kinds of characters it should expect to see; ISO-8859-1 specifically refers to Latin-1.\n",
    "- The for loop will start with the first row in the CSV file, yield that row, and then save its current place in reading the file until the generator function is called again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re following along with the data on your own computer, you’ll need to replace file with the exact path on your computer to where the file is located. This will enable Python to find it when you want to open() it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to store an instance of the generator so we can refer back to it\n",
    "beer = beerDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BeerID,Name,URL,Style,StyleID,Size(L),OG,FG,ABV,IBU,Color,BoilSize,BoilTime,BoilGravity,Efficiency,MashThickness,SugarScale,BrewMethod,PitchRate,PrimaryTemp,PrimingMethod,PrimingAmount,UserId\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(beer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,Vanilla Cream Ale,/homebrew/recipe/view/1633/vanilla-cream-ale,Cream Ale,45,21.77,1.055,1.013,5.48,17.65,4.83,28.39,75,1.038,70,N/A,Specific Gravity,All Grain,N/A,17.78,corn sugar,4.5 oz,116\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(beer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we’ve created a beerDataGenerator in beer, we can start passing it into next() to look at the data itself. As the CSV file suggests, the columns are separated by commas. Furthermore, each row ends with an \\n, which indicates a line break. We found that the first item in recipeData.csv to is a list of column names and the first row to describe a delicious Vanilla Cream Ale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You may be asking, “We can store the data in a list comprehension! Why jump through an extra hoop and use a generator?” As a programmer, you may encounter Big Data. This is a somewhat nebulous term, and so we won’t delve into the various Big Data definitions here. Suffice to say that any Big Data file is too big to assign to a variable. Our data file doesn’t qualify as Big Data, but we can still learn a lot by imposing a restriction on ourselves to recreate this conundrum. We’ll assume for now that our beer data is so large in size that we are incapable of storing all of the data in a list of lists. With the normal route of reading in data blocked off, we are forced to reconsider our options. This is where generators come in. We’ll explain later precisely why generators work here, but until then we can rest assured that our generator function will enable us to read the data in the first place, albeit not all at once. Along with generator functions, we can also create generators using generator expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The generator expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early, we compared our generator function to a regular function since they have many similar aspects. For generation expressions, we’ll use list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_example = [n**2 for n in [1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "genex_example = (n**2 for n in [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7f39ad5305e8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genex_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lc_example is our list comprehension, while genex_example is our generator expression that performs almost the same task. Take note that the only difference between the two is that the generator expression is surrounded by parentheses, rather than brackets. If we either of these iterators in a for loop, they will produce the same result and will be indistinguishable. However, if we try to inspect these variables in our interpreter, they produce different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is similar to what we saw when we tried to look at a regular function and a generator function. Python also recognizes that genex_example is a generator in generator expression form (). As lc_example is a list, we can perform all of the operations that they support: indexing, slicing, mutation, etc. We cannot do this with the generator expression. Generators are specialized as an easy to produce an output one-at-a-time, so they do not support these operations. However, like list comprehensions we can implement logic within generator expressions to form a filter if we needed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "genex_example2 = (n**2 for n in [1, 2, 3, 4, 5] if n >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(genex_example2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectively, there is no difference in how we will use a generator function or generator expression. Once we have our generator expression, we can call next() on it to start getting the values it will produce. Once we go through all of the values that the generator expression can produce, we cannot use it anymore. This contrasts against a list comprehension, which we can reuse as much as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(genex_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(genex_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(genex_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(genex_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(genex_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2a868c6bae12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenex_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(genex_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea that we can only use generators once is tied to the idea of their consumption. Recall that when we iterate over some iterator, we perform some operation on each of the values within. We then move on with our analysis using these processed values, meaning that typically we may not need the original iterator. Generators fit perfectly into this need, allowing us to form an iterator that we can use once and then not have to worry about it taking up space after we use it (in a for loop, for example). We talked about next() as the way to get the values from the generators, but its often better to use generators in for loops. Using next() forces us to have to deal with the StopIteration ourselves, but the for loop uses this to know when to stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "genex_example = (n**2 for n in [1, 2, 3, 4, 5])\n",
    "# Using a for loop to consume a generator is better than using next()\n",
    "for ge in genex_example:\n",
    "    print(ge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One distinction that generator expressions have over functions is their succinctness. Generator functions take up multiple lines, whereas we can fit generator expressions in one line. Multiple lines are not bad in and of itself, but it opens up functions to greater complexity that may introduce bugs later on. We’ll rewrite our generator function as a one-line expression that read in our beer data. This conciseness that will come in handy later in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_data = \"data/recipeData.csv\"\n",
    "\n",
    "# This one line perfoms the same action as beerDataGenerator()!\n",
    "lines =  (line for line in open(beer_data, encoding=\"ISO-8859-1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Generators produce values one-at-a-time as opposed to giving them all at once.\n",
    "- There are two ways to create generators: generator functions and generator expressions.\n",
    "- Generator functions yield, regular functions return.\n",
    "- Generator expressions need (), list comprehensions use [].\n",
    "- You can only use a generator once.\n",
    "- There are two ways to get values from generators: the next() function and a for loop. The for loop is often the preferred method.\n",
    "- We can use generators to read files and give us one line at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laziness and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know now that generators produce a single value from a defined sequence, but only when we ask next() or within a for loop. We call this lazy evaluation. Generators are lazy because they only give us a value when we ask for it. The flipside here is that only that single value takes up memory. The ultimate result is that generators are incredibly memory efficient, which makes it a perfect candidate for reading and using Big Data files. Once we ask for the next value of a generator, the old value is discarded. Once we go through the entire generator, it is also discarded from memory as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently haven’t learned anything from the beer data. All we’ve done so far is to take the original CSV file and create a generator that will yield each line in the CSV, one at a time in the form of a string. Unless we’d like to do some crazy string manipulation, we’ll need to think of a way to get our data into a readable, useable form. Below is a representation of what our code currently does: a simple read from file and output of a single line from the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators come to the rescue again here! So far in the article, we’ve been passing in other structures, specifically iterators, to the generators to indicate what sequence we’d like to generate from. However, generators are iterators themselves too — why don’t we create another generator that takes the output another generator? Our lines generator outputs the line in its entirety, so we’ll make a second generator that does some formatting for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_data = \"data/recipeData.csv\"\n",
    "\n",
    "lines =  (line for line in open(beer_data, encoding=\"ISO-8859-1\"))\n",
    "lists = (l.split(\",\") for l in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end result of our generators is a stream of lists, each containing the data within a row of the CSV. If we iterate through lists, we’ll be able to easily access the data elements within and perform the analyses we need! We’ve effectively made a pipeline for our data set, starting from the raw data set and sending it through 2 generators to get it into a familiar form. Remember that generators aren’t lists themselves, they merely generate a single element of a sequence and only take up the amount that element needs. By piping generators together, we’ve created a quick, easy-to-read way for us to read data that would be inaccessible through normal means. There’s some real power to this approach, and its significance can’t be understated. We didn’t need to create any temporary lists to hold intermediate values as we processed them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this pipeline, each generator is put in charge of a single operation that will eventually be applied to all rows of the data set. Although having each list is good, there’s still some small issues that need to be addressed before we can do any meaningul analyses. First, we’d like to take the column names since they aren’t data and then turn them into a dictionary that would make any further code easier to read. Note: if you’re running this code on your own machine, you must remember that you can only use generators once. If you use the generator in a for loop to view the output, you’ll need to run the data and the whole pipeline again. Thankfully, the generators run fast here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_data = \"data/recipeData.csv\"\n",
    "\n",
    "lines =  (line for line in open(beer_data, encoding=\"ISO-8859-1\"))\n",
    "lists = (l.split(\",\") for l in lines)\n",
    "\n",
    "# Take the column names out of the generator and store them, leaving only data\n",
    "columns = next(lists)\n",
    "\n",
    "# Take these columns and use them to create an informative dictionary\n",
    "beerdicts = (dict(zip(columns, data)) for data in lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BeerID': '1',\n",
       " 'Name': 'Vanilla Cream Ale',\n",
       " 'URL': '/homebrew/recipe/view/1633/vanilla-cream-ale',\n",
       " 'Style': 'Cream Ale',\n",
       " 'StyleID': '45',\n",
       " 'Size(L)': '21.77',\n",
       " 'OG': '1.055',\n",
       " 'FG': '1.013',\n",
       " 'ABV': '5.48',\n",
       " 'IBU': '17.65',\n",
       " 'Color': '4.83',\n",
       " 'BoilSize': '28.39',\n",
       " 'BoilTime': '75',\n",
       " 'BoilGravity': '1.038',\n",
       " 'Efficiency': '70',\n",
       " 'MashThickness': 'N/A',\n",
       " 'SugarScale': 'Specific Gravity',\n",
       " 'BrewMethod': 'All Grain',\n",
       " 'PitchRate': 'N/A',\n",
       " 'PrimaryTemp': '17.78',\n",
       " 'PrimingMethod': 'corn sugar',\n",
       " 'PrimingAmount': '4.5 oz',\n",
       " 'UserId\\n': '116\\n'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(beerdicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beerdicts does some simple formatting, which gives our pipeline even more power!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great place to start inquiring our data about our future beer brewing choices. Now that we have our generator pipeline in place, we can start consuming the data produced by the generators and create some insights. We usually consume generators using for loops, so we’ll use one to figure out what the most popular type of homebrewed beer is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_counts = {}\n",
    "for bd in beerdicts:\n",
    "    if bd[\"Style\"] not in beer_counts:\n",
    "        beer_counts[bd[\"Style\"]] = 1\n",
    "    else:\n",
    "        beer_counts[bd[\"Style\"]] += 1\n",
    "\n",
    "most_popular = 0\n",
    "most_popular_type = None\n",
    "for beer, count in beer_counts.items():\n",
    "    if count > most_popular:\n",
    "        most_popular = count\n",
    "        most_popular_type = beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'American IPA'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_popular_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is ubiquitous in data wrangling and processing, and you’ve probably seen it before. The only new thing here is that instead of referring back to a list of lists containing our data, we rely on dictionaries that are produced by our generators. With generators, we are able to make the same inquires we’d want from any Big Data set as we would a regular-sized one. We now know that American IPAs are the most popular homebrewed beer in the data set, and we know how many entries they have in the data. We can try figuring out how strong our beer should be. This data is contained in the “ABV” (Alcohol By Volume) key. Since we are working with dictionaries as the output of our generator stream, why don’t we add another generator to hone in on the exact values we want to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "abv = (float(bd[\"ABV\"]) for bd in beerdicts if bd[\"Style\"] == \"American IPA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76944.87000000004"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11940"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.44429396984925"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average ABV for an American IPA\n",
    "sum(abv)/most_popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should take special note of our use of sum() with the abv generator. It is not immediately intuitive that sum() will sum up all of the ABV values that it receives. You may think of sum() as reducing the whole output of the generator into one value. By dividing this sum by the number of American IPA entires there are, we got the average. Our data suggests that your average American IPA is about 6.4% alcohol by volume! Our last generator abv takes the dictionaries that are output by beerdicts and outputs the ABV key, but only if the beer is an American IPA. Filters on our generator expression form a powerful tool in our pipeline. If we think of each successive generator as a modular component, we can then swap out generators for others that may have a more desirable functionality. If we wanted to change what kind of beer we wanted to investigate or look at another beer characteristic, the only thing we need to change is the generator operation. The picture below expresses the different parts of the generator pipeline approach. It consists of some raw data you want to process, the pipeline that does the actual processing, and the final consumption of the output of this pipeline. Following this pattern will enable you to reenact what we’ve done with the beer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re used to the workflow of using a list of lists and leveraging all the list methods to do your analyses, this new approach to data wrangling might be strange. However, the data pipeline is a powerful concept that can be immediately incorporated into your code and you should try it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Primeri iz prakse](https://github.com/dabeaz/generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Reading Large Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use case of generators is to work with data streams or large files, like CSV files. These text files separate data into columns by using commas. This format is a common way to share data. Now, what if you want to count the number of rows in a CSV file? The code block below shows one way of counting those rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader(file_name):\n",
    "    file = open(file_name)\n",
    "    result = file.read().split(\"\\n\")\n",
    "    file.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count is 572\n"
     ]
    }
   ],
   "source": [
    "csv_gen = csv_reader(\"data/nile.csv\")\n",
    "row_count = 0\n",
    "\n",
    "for row in csv_gen:\n",
    "    row_count += 1\n",
    "\n",
    "print(f\"Row count is {row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this example, you might expect csv_gen to be a list. To populate this list, csv_reader() opens a file and loads its contents into csv_gen. Then, the program iterates over the list and increments row_count for each row.\n",
    "\n",
    "This is a reasonable explanation, but would this design still work if the file is very large? What if the file is larger than the memory you have available? To answer this question, let’s assume that csv_reader() just opens the file and reads it into an array:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function opens a given file and uses file.read() along with .split() to add each line as a separate element to a list. If you were to use this version of csv_reader() in the row counting code block you saw further up, then you’d get the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, open() returns a generator object that you can lazily iterate through line by line. However, file.read().split() loads everything into memory at once, causing the MemoryError.\n",
    "\n",
    "Before that happens, you’ll probably notice your computer slow to a crawl. You might even need to kill the program with a KeyboardInterrupt. So, how can you handle these huge data files? Take a look at a new definition of csv_reader():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader(file_name):\n",
    "    for row in open(file_name, \"r\"):\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count is 571\n"
     ]
    }
   ],
   "source": [
    "csv_gen = csv_reader(\"data/nile.csv\")\n",
    "row_count = 0\n",
    "\n",
    "for row in csv_gen:\n",
    "    row_count += 1\n",
    "\n",
    "print(f\"Row count is {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#možnost 1\n",
    "file = \"data/nile.csv\"\n",
    "# Use generators to get number of rows, with one row in memory\n",
    "def line_aggregate(file):\n",
    "    rows = 0\n",
    "    with open(file, encoding='ISO-8859-1') as f:\n",
    "        for row in f:\n",
    "            rows += 1\n",
    "        return rows\n",
    "    \n",
    "line_aggregate(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571\n"
     ]
    }
   ],
   "source": [
    "# možnost 2\n",
    "file = \"data/nile.csv\"\n",
    "num_lines = sum(1 for line in open(file))\n",
    "print(num_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version, you open the file, iterate through it, and yield a row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s happening here? Well, you’ve essentially turned csv_reader() into a generator function. This version opens a file, loops through each line, and yields each row, instead of returning it.\n",
    "\n",
    "You can also define a generator expression (also called a generator comprehension), which has a very similar syntax to list comprehensions. In this way, you can use the generator without calling a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_gen = (row for row in open(\"data/nile.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more succinct way to create the list csv_gen. You’ll learn more about the Python yield statement soon. For now, just remember this key difference:\n",
    "- Using yield will result in a generator object.\n",
    "- Using return will result in the first line of the file only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Generating an Infinite Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s switch gears and look at infinite sequence generation. In Python, to get a finite sequence, you call range() and evaluate it in a list context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating an infinite sequence, however, will require the use of a generator, since your computer memory is finite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_sequence():\n",
    "    num = 0\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is short and sweet. First, you initialize the variable num and start an infinite loop. Then, you immediately yield num so that you can capture the initial state. This mimics the action of range().\n",
    "\n",
    "After yield, you increment num by 1. If you try this with a for loop, then you’ll see that it really does seem infinite:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    for i in infinite_sequence():\n",
    "        print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will continue to execute until you stop it manually.\n",
    "\n",
    "Instead of using a for loop, you can also call next() on the generator object directly. This is especially useful for testing a generator in the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = infinite_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you have a generator called gen, which you manually iterate over by repeatedly calling next(). This works as a great sanity check to make sure your generators are producing the output you expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: When you use next(), Python calls .__next__() on the function you pass in as a parameter. There are some special effects that this parameterization allows, but it goes beyond the scope of this article. Experiment with changing the parameter you pass to next() and see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Creating New Iteration Patterns with Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to implement a custom iteration pattern that’s different than the usual builtin\n",
    "functions (e.g., range(), reversed(), etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to implement a new kind of iteration pattern, define it using a generator\n",
    "function. Here’s a generator that produces a range of floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(start, stop, increment):\n",
    "    x = start\n",
    "    while x < stop:\n",
    "        yield x\n",
    "        x += increment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use such a function, you iterate over it using a for loop or use it with some other\n",
    "function that consumes an iterable (e.g., sum(), list(), etc.). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5\n",
      "1.0\n",
      "1.5\n",
      "2.0\n",
      "2.5\n",
      "3.0\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "for n in frange(0, 4, 0.5):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(frange(0, 1, 0.125))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Creating Data Pipelines With Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pipelines allow you to string together code to process large datasets or streams of data without maxing out your machine’s memory. Imagine that you have a large CSV file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is pulled from the TechCrunch Continental USA set, which describes funding rounds and dollar amounts for various startups based in the USA. Click the link below to download the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s think of a strategy:\n",
    "- Read every line of the file.\n",
    "- Split each line into a list of values.\n",
    "- Extract the column names.\n",
    "- Use the column names and lists to create a dictionary.\n",
    "- Filter out the rounds you aren’t interested in.\n",
    "- Calculate the total and average values for the rounds you are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, you can do this with a package like pandas, but you can also achieve this functionality with just a few generators. You’ll start by reading each line from the file with a generator expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/techcrunch.csv\"\n",
    "lines = (line for line in open(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you’ll use another generator expression in concert with the previous one to split each line into a list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_line = (s.rstrip().split(\",\") for s in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you created the generator list_line, which iterates through the first generator lines. This is a common pattern to use when designing generator pipelines. Next, you’ll pull the column names out of techcrunch.csv. Since the column names tend to make up the first line in a CSV file, you can grab that with a short next() call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = next(list_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This call to next() advances the iterator over the list_line generator one time. Put it all together, and your code should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/techcrunch.csv\"\n",
    "lines = (line for line in open(file_name))\n",
    "list_line = (s.rstrip().split(\",\") for s in lines)\n",
    "cols = next(list_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum this up, you first create a generator expression lines to yield each line in a file. Next, you iterate through that generator within the definition of another generator expression called list_line, which turns each line into a list of values. Then, you advance the iteration of list_line just once with next() to get a list of the column names from your CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you filter and perform operations on the data, you’ll create dictionaries where the keys are the column names from the CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dicts = (dict(zip(cols, data)) for data in list_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generator expression iterates through the lists produced by list_line. Then, it uses zip() and dict() to create the dictionary as specified above. Now, you’ll use a fourth generator to filter the funding round you want and pull raisedAmt as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding = (\n",
    "    int(company_dict[\"raisedAmt\"])\n",
    "    for company_dict in company_dicts\n",
    "    if company_dict[\"round\"] == \"a\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, your generator expression iterates through the results of company_dicts and takes the raisedAmt for any company_dict where the round key is A.\n",
    "\n",
    "Remember, you aren’t iterating through all these at once in the generator expression. In fact, you aren’t iterating through anything until you actually use a for loop or a function that works on iterables, like sum(). In fact, call sum() now to iterate through the generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_series_a = sum(funding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18500000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_series_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this all together, you’ll produce the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total series A fundraising: $18500000\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/techcrunch.csv\"\n",
    "lines = (line for line in open(file_name))\n",
    "list_line = (s.rstrip().split(\",\") for s in lines)\n",
    "cols = next(list_line)\n",
    "company_dicts = (dict(zip(cols, data)) for data in list_line)\n",
    "funding = (\n",
    "    int(company_dict[\"raisedAmt\"])\n",
    "    for company_dict in company_dicts\n",
    "    if company_dict[\"round\"] == \"a\"\n",
    ")\n",
    "total_series_a = sum(funding)\n",
    "print(f\"Total series A fundraising: ${total_series_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script pulls together every generator you’ve built, and they all function as one big data pipeline. Here’s a line by line breakdown:\n",
    "- Line 2 reads in each line of the file.\n",
    "- Line 3 splits each line into values and puts the values into a list.\n",
    "- Line 4 uses next() to store the column names in a list.\n",
    "- Line 5 creates dictionaries and unites them with a zip() call:\n",
    "    - The keys are the column names cols from line 4.\n",
    "    - The values are the rows in list form, created in line 3.\n",
    "- Line 6 gets each company’s series A funding amounts. It also filters out any other raised amount.\n",
    "- Line 11 begins the iteration process by calling sum() to get the total amount of series A funding found in the CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The methods for handling CSV files developed in this tutorial are important for understanding how to use generators and the Python yield statement. However, when you work with CSV files in Python, you should instead use the csv module included in Python’s standard library. This module has optimized methods for handling CSV files efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: A generator that follows a log file like Unix 'tail -f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "follow.py. A generator that follows lines written to a real-time log file (like Unix 'tail -f'). To run this program, you need to have a log-file to work with. Run the program logsim.py to create a simulated web-server log (written in the file access-log). Leave this program running in the background for the next few parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`seek() method − fileObject.seek(offset[, whence])`\n",
    "- offset − This is the position of the read/write pointer within the file.\n",
    "- whence − This is optional and defaults to 0 which means absolute file positioning, other values are 1 which means seek relative to the current position and 2 means seek relative to the file's en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logsim.py\n",
    "import time, random\n",
    "\n",
    "from data import ips\n",
    "from data import docs\n",
    "\n",
    "with open(\"access-log\",\"w\") as f:\n",
    "    while True:\n",
    "        time.sleep(random.random())\n",
    "        n = random.randint(0,len(ips)-1)\n",
    "        m = random.randint(0,len(docs)-1)\n",
    "        t = time.time()\n",
    "        date = time.strftime(\"[%d/%b/%Y:%H:%M:%S -0600]\",time.localtime(t))\n",
    "        write_String = f'{ips[n]} - - {date} {docs[m]}\\n'\n",
    "        f.write(write_String)\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow.py\n",
    "#\n",
    "# A generator that follows a log file like Unix 'tail -f'.\n",
    "#\n",
    "# Note: To see this example work, you need to apply to \n",
    "# an active server log file.  Run the program \"logsim.py\"\n",
    "# in the background to simulate such a file.  This program\n",
    "# will write entries to a file \"access-log\".\n",
    "\n",
    "import time\n",
    "\n",
    "def follow(thefile):\n",
    "    thefile.seek(0,2)      # Go to the end of the file\n",
    "    while True:\n",
    "        line = thefile.readline()\n",
    "        if not line:\n",
    "            time.sleep(0.1)    # Sleep briefly\n",
    "            continue\n",
    "        yield line\n",
    "\n",
    "# Example use\n",
    "if __name__ == '__main__':\n",
    "    with open(\"access-log\") as logfile:\n",
    "        for line in follow(logfile):\n",
    "            print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline.py. An example of using generators to set up a simple processing pipeline. Print all server log entries containing the word 'python'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.py\n",
    "#\n",
    "# An example of setting up a processing pipeline with generators\n",
    "import re\n",
    "\n",
    "def grep(pattern,lines):\n",
    "    patc = re.compile(pattern)\n",
    "    for line in lines:\n",
    "        if patc.search(line):\n",
    "             yield line\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from follow import follow\n",
    "\n",
    "    # Set up a processing pipe : tail -f | grep python\n",
    "    with open(\"access-log\") as logfile:\n",
    "        loglines = follow(logfile)\n",
    "        pylines  = grep(r\"python\", loglines)\n",
    "\n",
    "        # Pull results out of the processing pipeline\n",
    "        for line in pylines:\n",
    "            print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Calculate the number of bytes transferred in an Apache server log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genlog.py\n",
    "#\n",
    "# Sum up the bytes transferred in an Apache server log using\n",
    "# generator expressions\n",
    "\n",
    "with open(\"access-log\") as wwwlog:\n",
    "    bytecolumn = (line.rsplit(None,1)[1] for line in wwwlog)\n",
    "    bytes_sent = (int(x) for x in bytecolumn if x != '-')\n",
    "    print(\"Total\", sum(bytes_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaja: Creating Data Processing Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to process data iteratively in the style of a data processing pipeline (similar to\n",
    "Unix pipes). For instance, you have a huge amount of data that needs to be processed,\n",
    "but it can’t fit entirely into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator functions are a good way to implement processing pipelines. To illustrate,\n",
    "suppose you have a huge directory of log files that you want to process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    foo/\n",
    "        access-log-012007.gz\n",
    "        access-log-022007.gz\n",
    "        access-log-032007.gz\n",
    "        ...\n",
    "        access-log-012008\n",
    "    bar/\n",
    "        access-log-092007.bz2\n",
    "        ...\n",
    "        access-log-022008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process these files, you could define a collection of small generator functions that\n",
    "perform specific self-contained tasks. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import gzip\n",
    "import bz2\n",
    "import re\n",
    "\n",
    "def gen_find(filepat, top):\n",
    "    '''\n",
    "    Find all filenames in a directory tree that match a shell wildcard pattern\n",
    "    '''\n",
    "    for path, dirlist, filelist in os.walk(top):\n",
    "        for name in fnmatch.filter(filelist, filepat):\n",
    "            yield os.path.join(path,name)\n",
    "            \n",
    "def gen_opener(filenames):\n",
    "    '''\n",
    "    Open a sequence of filenames one at a time producing a file object.\n",
    "    The file is closed immediately when proceeding to the next iteration.\n",
    "    '''\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "        yield f\n",
    "        f.close()\n",
    "        \n",
    "def gen_concatenate(iterators):\n",
    "    '''\n",
    "    Chain a sequence of iterators together into a single sequence.\n",
    "    '''\n",
    "    for it in iterators:\n",
    "        yield from it\n",
    "        \n",
    "def gen_grep(pattern, lines):\n",
    "    '''\n",
    "    Look for a regex pattern in a sequence of lines\n",
    "    '''\n",
    "    pat = re.compile(pattern)\n",
    "    for line in lines:\n",
    "        if pat.search(line):\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now easily stack these functions together to make a processing pipeline. For\n",
    "example, to find all log lines that contain the word python, you would just do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
      "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robotsl.txt ...\" 200 71\n"
     ]
    }
   ],
   "source": [
    "lognames = gen_find('access-log*', 'data/pipeline')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('robotsl?.txt', lines)\n",
    "\n",
    "for line in pylines:\n",
    "    print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extend the pipeline further, you can even feed the data in generator\n",
    "expressions. For example, this version finds the number of bytes transferred and sums\n",
    "the total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1704\n"
     ]
    }
   ],
   "source": [
    "lognames = gen_find('access-log*', 'data/pipeline')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('124.115.6.12', lines)\n",
    "bytecolumn = (line.rsplit(None,1)[1] for line in pylines)\n",
    "_bytes = (int(x) for x in bytecolumn if x != '-')\n",
    "print('Total', sum(_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing data in a pipelined manner works well for a wide variety of other problems,\n",
    "including parsing, reading from real-time data sources, periodic polling, and so on.\n",
    "\n",
    "In understanding the code, it is important to grasp that the yield statement acts as a\n",
    "kind of data producer whereas a for loop acts as a data consumer. When the generators\n",
    "are stacked together, each yield feeds a single item of data to the next stage of the\n",
    "pipeline that is consuming it with iteration. In the last example, the sum() function is\n",
    "actually driving the entire program, pulling one item at a time out of the pipeline of\n",
    "generators.\n",
    "\n",
    "One nice feature of this approach is that each generator function tends to be small and\n",
    "self-contained. As such, they are easy to write and maintain. In many cases, they are so\n",
    "general purpose that they can be reused in other contexts. The resulting code that glues\n",
    "the components together also tends to read like a simple recipe that is easily understood.\n",
    "\n",
    "The memory efficiency of this approach can also not be overstated. The code shown\n",
    "would still work even if used on a massive directory of files. In fact, due to the iterative\n",
    "nature of the processing, very little memory would be used at all.\n",
    "\n",
    "There is a bit of extreme subtlety involving the gen_concatenate() function. The\n",
    "purpose of this function is to concatenate input sequences together into one long sequence\n",
    "of lines. The itertools.chain() function performs a similar function, but requires\n",
    "that all of the chained iterables be specified as arguments. In the case of this\n",
    "particular recipe, doing that would involve a statement such as lines = iter\n",
    "tools.chain(*files), which would cause the gen_opener() generator to be fully consumed.\n",
    "Since that generator is producing a sequence of open files that are immediately\n",
    "closed in the next iteration step, chain() can’t be used. The solution shown avoids this\n",
    "issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also appearing in the gen_concatenate() function is the use of yield from to delegate\n",
    "to a subgenerator. The statement yield from it simply makes gen_concatenate()\n",
    "emit all of the values produced by the generator it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, but not least, it should be noted that a pipelined approach doesn’t always work for\n",
    "every data handling problem. Sometimes you just need to work with all of the data at\n",
    "once. However, even in that case, using generator pipelines can be a way to logically\n",
    "break a problem down into a kind of workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Več primerov](https://github.com/dabeaz/generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasveti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider Generator Expressions for Large Comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with list comprehensions  is that they may create a whole new list containing one item for each\n",
    "value in the input sequence. This is fine for small inputs, but for large inputs this could\n",
    "consume significant amounts of memory and cause your program to crash.\n",
    "\n",
    "For example, say you want to read a file and return the number of characters on each line.\n",
    "Doing this with a list comprehension would require holding the length of every line of the\n",
    "file in memory. If the file is absolutely enormous or perhaps a never-ending network\n",
    "socket, list comprehensions are problematic. Here, I use a list comprehension in a way that\n",
    "can only handle small input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94, 87, 89, 1, 91, 91, 93, 88, 31, 1, 88, 87, 47, 87, 85, 88, 21]\n"
     ]
    }
   ],
   "source": [
    "# vaja: v eni vrstici preštej število znakov v vsaki vrstici v datoteki\n",
    "value = [len(x) for x in open(\"data/example.txt\")]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this, Python provides generator expressions, a generalization of list\n",
    "comprehensions and generators. Generator expressions don’t materialize the whole output\n",
    "sequence when they’re run. Instead, generator expressions evaluate to an iterator that\n",
    "yields one item at a time from the expression.\n",
    "\n",
    "A generator expression is created by putting list-comprehension-like syntax between ()\n",
    "characters. Here, I use a generator expression that is equivalent to the code above.\n",
    "However, the generator expression immediately evaluates to an iterator and doesn’t make\n",
    "any forward progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f6341310480>\n"
     ]
    }
   ],
   "source": [
    "it = (len(x) for x in open(\"data/example.txt\"))\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned iterator can be advanced one step at a time to produce the next output from\n",
    "the generator expression as needed (using the next built-in function). Your code can\n",
    "consume as much of the generator expression as you want without risking a blowup in\n",
    "memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "print(next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another powerful outcome of generator expressions is that they can be composed together.\n",
    "Here, I take the iterator returned by the generator expression above and use it as the input\n",
    "for another generator expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = ((x, x**0.5) for x in it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time I advance this iterator, it will also advance the interior iterator, creating a\n",
    "domino effect of looping, evaluating conditional expressions, and passing around inputs\n",
    "and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 9.433981132056603)\n"
     ]
    }
   ],
   "source": [
    "print(next(roots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining generators like this executes very quickly in Python. When you’re looking for a\n",
    "way to compose functionality that’s operating on a large stream of input, generator\n",
    "expressions are the best tool for the job. The only gotcha is that the iterators returned by\n",
    "generator expressions are stateful, so you must be careful not to use them more than once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list comprehension in Python works by loading the entire output list into memory. For small or even medium-sized lists, this is generally fine. If you want to sum the squares of the first one-thousand integers, then a list comprehension will solve this problem admirably:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332833500"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i * i for i in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you wanted to sum the squares of the first billion integers? If you tried then on your machine, then you may notice that your computer becomes non-responsive. That’s because Python is trying to create a list with one billion integers, which consumes more memory than your computer would like. Your computer may not have the resources it needs to generate an enormous list and store it in memory. If you try to do it anyway, then your machine could slow down or even crash.\n",
    "\n",
    "When the size of a list becomes problematic, it’s often helpful to use a generator instead of a list comprehension in Python. A generator doesn’t create a single, large data structure in memory, but instead returns an iterable. Your code can ask for the next value from the iterable as many times as necessary or until you’ve reached the end of your sequence, while only storing a single value at a time.\n",
    "\n",
    "If you were to sum the first billion squares with a generator, then your program will likely run for a while, but it shouldn’t cause your computer to freeze. The example below uses a generator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333333283333335000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i * i for i in range(10000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell this is a generator because the expression isn’t surrounded by brackets or curly braces. Optionally, generators can be surrounded by parentheses.\n",
    "\n",
    "The example above still requires a lot of work, but it performs the operations lazily. Because of lazy evaluation, values are only calculated when they’re explicitly requested. After the generator yields a value (for example, 567 * 567), it can add that value to the running sum, then discard that value and generate the next value (568 * 568). When the sum function requests the next value, the cycle starts over. This process keeps the memory footprint small.\n",
    "\n",
    "map() also operates lazily, meaning memory won’t be an issue if you choose to use it in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333333283333335000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda i: i*i, range(10000000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s up to you whether you prefer the generator expression or map()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider Generators Instead of Returning Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest choice for functions that produce a sequence of results is to return a list of\n",
    "items. For example, say you want to find the index of every word in a string. Here, I\n",
    "accumulate results in a list using the append method and return it at the end of the\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_words(text):\n",
    "    result = []\n",
    "    if text:\n",
    "        result.append(0)\n",
    "    for index, letter in enumerate(text):\n",
    "        if letter == ' ':\n",
    "            result.append(index + 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works as expected for some sample input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 11, 15, 21, 27]\n"
     ]
    }
   ],
   "source": [
    "address = 'Four score and seven years ago…'\n",
    "result = index_words(address)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two problems with the index_words function.\n",
    "\n",
    "The first problem is that the code is a bit dense and noisy. Each time a new result is found,\n",
    "I call the append method. The method call’s bulk (result.append) deemphasizes the\n",
    "value being added to the list (index + 1). There is one line for creating the result list\n",
    "and another for returning it. While the function body contains ~130 characters (without\n",
    "whitespace), only ~75 characters are important.\n",
    "\n",
    "A better way to write this function is using a generator. Generators are functions that use\n",
    "yield expressions. When called, generator functions do not actually run but instead\n",
    "immediately return an iterator. With each call to the next built-in function, the iterator\n",
    "will advance the generator to its next yield expression. Each value passed to yield by\n",
    "the generator will be returned by the iterator to the caller.\n",
    "\n",
    "Here, I define a generator function that produces the same results as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_words_iter(text):\n",
    "    if text:\n",
    "        yield 0\n",
    "    for index, letter in enumerate(text):\n",
    "        if letter == ' ':\n",
    "            yield index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s significantly easier to read because all interactions with the result list have been\n",
    "eliminated. Results are passed to yield expressions instead. The iterator returned by the\n",
    "generator call can easily be converted to a list by passing it to the list built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(index_words_iter(address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 11, 15, 21, 27]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Generator Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned earlier that generators are a great way to optimize memory. While an infinite sequence generator is an extreme example of this optimization, let’s amp up the number squaring examples you just saw and inspect the size of the resulting objects. You can do this with a call to sys.getsizeof():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87624"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "nums_squared_lc = [i * 2 for i in range(10000)]\n",
    "sys.getsizeof(nums_squared_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "nums_squared_gc = (i ** 2 for i in range(10000))\n",
    "print(sys.getsizeof(nums_squared_gc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the list you get from the list comprehension is 87,624 bytes, while the generator object is only 120. This means that the list is over 700 times larger than the generator object!\n",
    "\n",
    "There is one thing to keep in mind, though. If the list is smaller than the running machine’s available memory, then list comprehensions can be faster to evaluate than the equivalent generator expression. To explore this, let’s sum across the results from the two comprehensions above. You can generate a readout with cProfile.run():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5 function calls in 0.002 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.001    0.001 <string>:1(<listcomp>)\n",
      "        1    0.000    0.000    0.002    0.002 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.002    0.002 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run('sum([i * 2 for i in range(10000)])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10005 function calls in 0.004 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    10001    0.003    0.000    0.003    0.000 <string>:1(<genexpr>)\n",
      "        1    0.000    0.000    0.004    0.004 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.004    0.004 {built-in method builtins.exec}\n",
      "        1    0.002    0.002    0.004    0.004 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run('sum((i * 2 for i in range(10000)))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can see that summing across all values in the list comprehension took about a third of the time as summing across the generator. If speed is an issue and memory isn’t, then a list comprehension is likely a better tool for the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: These measurements aren’t only valid for objects made with generator expressions. They’re also the same for objects made from the analogous generator function since the resulting generators are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, list comprehensions return full lists, while generator expressions return generators. Generators work the same whether they’re built from a function or an expression. Using an expression just allows you to define simple generators in a single line, with an assumed yield at the end of each inner iteration.\n",
    "\n",
    "The Python yield statement is certainly the linchpin on which all of the functionality of generators rests, so let’s dive into how yield works in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Take #3: A Generator Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pythonic implementation of the same functionality uses a generator function to replace\n",
    "the SequenceIterator class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import reprlib\n",
    "RE_WORD = re.compile('\\w+')\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.words = RE_WORD.findall(text)\n",
    "    def __repr__(self):\n",
    "        return 'Sentence(%s)' % reprlib.repr(self.text)\n",
    "    def __iter__(self):\n",
    "        for word in self.words: # Iterate over self.word.\n",
    "            yield word # Yield the current word.\n",
    "        return # This return is not needed; the function can just “fall-through” and return\n",
    "#automatically. Either way, a generator function doesn’t raise StopIteration: it\n",
    "#simply exits when it’s done producing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back in the Sentence code in Example 14-4, `__iter__` called the SentenceIterator\n",
    "constructor to build an iterator and return it. Now the iterator in Example 14-5 is in\n",
    "fact a generator object, built automatically when the `__iter__` method is called, because\n",
    "`__iter__` here is a generator function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a Generator Function Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any Python function that has the yield keyword in its body is a generator function: a\n",
    "function which, when called, returns a generator object. In other words, a generator\n",
    "function is a generator factory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The only syntax distinguishing a plain function from a generator\n",
    "function is the fact that the latter has a yield keyword somewhere\n",
    "in its body. Some argued that a new keyword like gen should\n",
    "be used for generator functions instead of def, but Guido did not\n",
    "agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the simplest function useful to demonstrate the behavior of a generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_123():  # Any Python function that contains the yield keyword is a generator function.\n",
    "    yield 1 # Usually the body of a generator function has loop, but not necessarily; here I\n",
    "#just repeat yield three times.\n",
    "    yield 2\n",
    "    yield 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.gen_123()>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_123 # Looking closely, we see gen_123 is a function object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object gen_123 at 0x7f39acbd65e8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_123() #But when invoked, gen_123() returns a generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in gen_123(): # Generators are iterators that produce the values of the expressions passed to yield.\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_123() # For closer inspection, we assign the generator object to g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g) # Because g is an iterator, calling next(g) fetches the next item produced by yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-e998d4ac5b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# When the body of the function completes, the generator object raises a StopIteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(g) # When the body of the function completes, the generator object raises a StopIteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator function builds a generator object that wraps the body of the function.\n",
    "When we invoke next(…) on the generator object, execution advances to the next yield\n",
    "in the function body, and the next(…) call evaluates to the value yielded when the function\n",
    "body is suspended. Finally, when the function body returns, the enclosing generator\n",
    "object raises StopIteration, in accordance with the Iterator protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I find it helpful to be strict when talking about the results obtained\n",
    "from a generator: I say that a generator yields or produces\n",
    "values. But it’s confusing to say a generator “returns” values. Functions\n",
    "return values. Calling a generator function returns a generator.\n",
    "A generator yields or produces values. A generator doesn’t\n",
    "“return” values in the usual way: the return statement in the body\n",
    "of a generator function causes StopIteration to be raised by the\n",
    "generator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example makes the interaction between a for loop and the body of the function\n",
    "more explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_AB(): #\n",
    "    print('start')\n",
    "    yield 'A' #\n",
    "    print('continue')\n",
    "    yield 'B' #\n",
    "    print('end.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "--> A\n",
      "continue\n",
      "--> B\n",
      "end.\n"
     ]
    }
   ],
   "source": [
    "for c in gen_AB(): #\n",
    "    print('-->', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generator function is defined like any function, but uses yield.\n",
    "- The first implicit call to next() in the for loop at will print 'start' and stop at the first yield, producing the value 'A'.\n",
    "- The second implicit call to next() in the for loop will print 'continue' and stop at the second yield, producing the value 'B'.\n",
    "- The third call to next() will print 'end.' and fall through the end of the function body, causing the generator object to raise StopIteration.\n",
    "- To iterate, the for machinery does the equivalent of g = iter(gen_AB()) to get a generator object, and then next(g) at each iteration.\n",
    "- The loop block prints --> and the value returned by next(g). But this output will be seen only after the output of the print calls inside the generator function.\n",
    "- The string 'start' appears as a result of print('start') in the generator function body.\n",
    "- yield 'A' in the generator function body produces the value A consumed by the for loop, which gets assigned to the c variable and results in the output -- > A.\n",
    "- Iteration continues with a second call next(g), advancing the generator function body from yield 'A' to yield 'B'. The text continue is output because of the second print in the generator function body.\n",
    "- yield 'B' produces the value B consumed by the for loop, which gets assigned to the c loop variable, so the loop prints --> B.\n",
    "- Iteration continues with a third call next(it), advancing to the end of the body of the function. The text end. appears in the output because of the third print in the generator function body.\n",
    "- When the generator function body runs to the end, the generator object raises StopIteration. The for loop machinery catches that exception, and the loop terminates cleanly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now hopefully it’s clear how `Sentence.__iter__` in Example 14-5 works: `__iter__` is\n",
    "a generator function which, when called, builds a generator object that implements the\n",
    "iterator interface, so the SentenceIterator class is no longer needed.\n",
    "This second version of Sentence is much shorter than the first, but it’s not as lazy as it\n",
    "could be. Nowadays, laziness is considered a good trait, at least in programming languages\n",
    "and APIs. A lazy implementation postpones producing values to the last possible\n",
    "moment. This saves memory and may avoid useless processing as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Take #4: A Lazy Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iterator interface is designed to be lazy: next(my_iterator) produces one item\n",
    "at a time. The opposite of lazy is eager: lazy evaluation and eager evaluation are actual\n",
    "technical terms in programming language theory.\n",
    "\n",
    "Our Sentence implementations so far have not been lazy because the `__init__` eagerly\n",
    "builds a list of all words in the text, binding it to the self.words attribute. This will\n",
    "entail processing the entire text, and the list may use as much memory as the text itself (probably more; it depends on how many nonword characters are in the text). Most of\n",
    "this work will be in vain if the user only iterates over the first couple words.\n",
    "Whenever you are using Python 3 and start wondering “Is there a lazy way of doing\n",
    "this?”, often the answer is “Yes.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The re.finditer function is a lazy version of re.findall which, instead of a list, returns\n",
    "a generator producing re.MatchObject instances on demand. If there are many\n",
    "matches, re.finditer saves a lot of memory. Using it, our third version of Sentence is\n",
    "now lazy: it only produces the next word when it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import reprlib\n",
    "\n",
    "RE_WORD = re.compile('\\w+')\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text # No need to have a words list.\n",
    "    def __repr__(self):\n",
    "        return 'Sentence(%s)' % reprlib.repr(self.text)\n",
    "    def __iter__(self):\n",
    "        # finditer builds an iterator over the matches of RE_WORD on self.text, yielding MatchObject instances.\n",
    "        for match in RE_WORD.finditer(self.text):\n",
    "            # match.group() extracts the actual matched text from the MatchObject instance.\n",
    "            yield match.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator functions are an awesome shortcut, but the code can be made even shorter\n",
    "with a generator expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Take #5: A Generator Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple generator functions like the one in the previous Sentence class \n",
    "can be replaced by a generator expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator expression can be understood as a lazy version of a list comprehension: it\n",
    "does not eagerly build a list, but returns a generator that will lazily produce the items  on demand. In other words, if a list comprehension is a factory of lists, a generator\n",
    "expression is a factory of generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_AB(): #\n",
    "    print('start')\n",
    "    yield 'A'\n",
    "    print('continue')\n",
    "    yield 'B'\n",
    "    print('end.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "continue\n",
      "end.\n"
     ]
    }
   ],
   "source": [
    "res1 = [x*3 for x in gen_AB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> AAA\n",
      "--> BBB\n"
     ]
    }
   ],
   "source": [
    "for i in res1: #\n",
    "    print('-->', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = (x*3 for x in gen_AB()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7f39acbd67c8>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "--> AAA\n",
      "continue\n",
      "--> BBB\n",
      "end.\n"
     ]
    }
   ],
   "source": [
    "for i in res2: \n",
    "    print('-->', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The list comprehension eagerly iterates over the items yielded by the generator object produced by calling gen_AB(): 'A' and 'B'. Note the output in the next lines: start, continue, end.\n",
    "2. This for loop is iterating over the res1 list produced by the list comprehension.\n",
    "3. The generator expression returns res2. The call to gen_AB() is made, but that call returns a generator, which is not consumed here. \n",
    "4. res2 is a generator object.\n",
    "5. Only when the for loop iterates over res2, the body of gen_AB actually executes.\n",
    "6. Each iteration of the for loop implicitly calls next(res2), advancing gen_AB to the next yield. Note the output of gen_AB with the output of the print in the for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, a generator expression produces a generator, and we can use it to further reduce the\n",
    "code in the Sentence class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import reprlib\n",
    "\n",
    "RE_WORD = re.compile('\\w+')\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    def __repr__(self):\n",
    "        return 'Sentence(%s)' % reprlib.repr(self.text)\n",
    "    def __iter__(self):\n",
    "        return (match.group() for match in RE_WORD.finditer(self.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference from Example 14-7 is the `__iter__` method, which here is not a\n",
    "generator function (it has no yield) but uses a generator expression to build a generator\n",
    "and then returns it. The end result is the same: the caller of `__iter__` gets a generator\n",
    "object.\n",
    "\n",
    "Generator expressions are syntactic sugar: they can always be replaced by generator\n",
    "functions, but sometimes are more convenient. The next section is about generator\n",
    "expression usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Expressions: When to Use Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 14-9, we saw that a generator expression is a syntactic shortcut to create a\n",
    "generator without defining and calling a function. On the other hand, generator functions are much more flexible: you can code complex logic with multiple statements, and can even use them as coroutines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simpler cases, a generator expression will do, and it’s easier to read at a glance,\n",
    "as the Vector example shows.\n",
    "\n",
    "My rule of thumb in choosing the syntax to use is simple: if the generator expression\n",
    "spans more than a couple of lines, I prefer to code a generator function for the sake of\n",
    "readability. Also, because generator functions have a name, they can be reused. You can\n",
    "always name a generator expression and use it later by assigning it to a variable, of course,\n",
    "but that is stretching its intended usage as a one-off generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentence examples we’ve seen exemplify the use of generators playing the role of\n",
    "classic iterators: retrieving items from a collection. But generators can also be used to\n",
    "produce values independent of a data source. The next section shows an example of\n",
    "that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example: Arithmetic Progression Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic Iterator pattern is all about traversal: navigating some data structure. But a\n",
    "standard interface based on a method to fetch the next item in a series is also useful\n",
    "when the items are produced on the fly, instead of retrieved from a collection. For\n",
    "example, the range built-in generates a bounded arithmetic progression (AP) of integers,\n",
    "and the itertools.count function generates a boundless AP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll cover itertools.count in the next section, but what if you need to generate a\n",
    "bounded AP of numbers of any type?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 14-10 shows a few console tests of an ArithmeticProgression class we will\n",
    "see in a moment. The signature of the constructor in Example 14-10 is Arithmetic\n",
    "Progression(begin, step[, end]). The range() function is similar to the ArithmeticProgression here, but its full signature is range(start, stop[, step]). I chose\n",
    "to implement a different signature because for an arithmetic progression the step is\n",
    "mandatory but end is optional. I also changed the argument names from start/stop\n",
    "to begin/end to make it very clear that I opted for a different signature. In each test in\n",
    "Example 14-10 I call list() on the result to inspect the generated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticProgression:\n",
    "    def __init__(self, begin, step, end=None):\n",
    "        self.begin = begin\n",
    "        self.step = step\n",
    "        self.end = end # None -> \"infinite\" series\n",
    "    def __iter__(self):\n",
    "        result = type(self.begin + self.step)(self.begin)\n",
    "        forever = self.end is None\n",
    "        index = 0\n",
    "        while forever or result < self.end:\n",
    "            yield result\n",
    "            index += 1\n",
    "            result = self.begin + self.step * index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `__init__` requires two arguments: begin and step. end is optional, if it’s None, the series will be unbounded.\n",
    "- This line produces a result value equal to self.begin, but coerced to the type of the subsequent additions.\n",
    "- For readability, the forever flag will be True if the self.end attribute is None, resulting in an unbounded series.\n",
    "- This loop runs forever or until the result matches or exceeds self.end. When this loop exits, so does the function.\n",
    "- The current result is produced.\n",
    "- The next potential result is calculated. It may never be yielded, because the while loop may terminate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = ArithmeticProgression(0, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = ArithmeticProgression(1, .5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.5, 2.0, 2.5]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = ArithmeticProgression(0, 1/3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.3333333333333333, 0.6666666666666666]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Fraction(0, 1), Fraction(1, 3), Fraction(2, 3)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "ap = ArithmeticProgression(0, Fraction(1, 3), 1)\n",
    "list(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Decimal('0'), Decimal('0.1'), Decimal('0.2')]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "ap = ArithmeticProgression(0, Decimal('.1'), .3)\n",
    "list(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that type of the numbers in the resulting arithmetic progression follows the type\n",
    "of begin or step, according to the numeric coercion rules of Python arithmetic. In\n",
    "Example 14-10, you see lists of int, float, Fraction, and Decimal numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last line of Example 14-11, instead of simply incrementing the result with\n",
    "self.step iteratively, I opted to use an index variable and calculate each result by\n",
    "adding self.begin to self.step multiplied by index to reduce the cumulative effect\n",
    "of errors when working with with floats.\n",
    "\n",
    "The ArithmeticProgression class from Example 14-11 works as intended, and is a\n",
    "clear example of the use of a generator function to implement the `__iter__` special\n",
    "method. However, if the whole point of a class is to build a generator by implementing\n",
    "`__iter__`, the class can be reduced to a generator function. A generator function is, after\n",
    "all, a generator factory.\n",
    "\n",
    "Example 14-12 shows a generator function called aritprog_gen that does the same job\n",
    "as ArithmeticProgression but with less code. The tests in Example 14-10 all pass if\n",
    "you just call aritprog_gen instead of ArithmeticProgression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aritprog_gen(begin, step, end=None):\n",
    "    result = type(begin + step)(begin)\n",
    "    forever = end is None\n",
    "    index = 0\n",
    "    while forever or result < end:\n",
    "        yield result\n",
    "        index += 1\n",
    "        result = begin + step * index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
