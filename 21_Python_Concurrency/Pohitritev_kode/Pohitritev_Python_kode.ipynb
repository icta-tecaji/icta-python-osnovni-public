{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008a68b7",
   "metadata": {},
   "source": [
    "# Pohitritev Python kode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c800fd",
   "metadata": {},
   "source": [
    "## Making Your Programs Run Faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14138c0b",
   "metadata": {},
   "source": [
    "https://www.loginradius.com/blog/async/speed-up-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fc8a2",
   "metadata": {},
   "source": [
    "Your program runs too slow and you’d like to speed it up without the assistance of more\n",
    "extreme solutions, such as C extensions or a just-in-time (JIT) compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb396a16",
   "metadata": {},
   "source": [
    "While the first rule of optimization might be to “not do it,” the second rule is almost\n",
    "certainly “don’t optimize the unimportant.” To that end, if your program is running slow,\n",
    "you might start by profiling your code. \n",
    "\n",
    "More often than not, you’ll find that your program spends its time in a few hotspots,\n",
    "such as inner data processing loops. Once you’ve identified those locations, you can use\n",
    "the no-nonsense techniques presented in the following sections to make your program\n",
    "run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c651378",
   "metadata": {},
   "source": [
    "### Use functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a513981",
   "metadata": {},
   "source": [
    "A lot of programmers start using Python as a language for writing simple scripts. When\n",
    "writing scripts, it is easy to fall into a practice of simply writing code with very little\n",
    "structure. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# somescript.py\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "with open(sys.argv[1]) as f:\n",
    "    for row in csv.reader(f):\n",
    "        # Some kind of processing\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042ada0",
   "metadata": {},
   "source": [
    "A little-known fact is that code defined in the global scope like this runs slower than\n",
    "code defined in a function. The speed difference has to do with the implementation of\n",
    "local versus global variables (operations involving locals are faster). So, if you want to\n",
    "make the program run faster, simply put the scripting statements in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ed629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# somescript.py\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "def main(filename):\n",
    "    with open(filename) as f:\n",
    "        for row in csv.reader(f):\n",
    "            # Some kind of processing\n",
    "            pass\n",
    "        \n",
    "main(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7429f",
   "metadata": {},
   "source": [
    "The speed difference depends heavily on the processing being performed, but in our\n",
    "experience, speedups of 15-30% are not uncommon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23a5b1",
   "metadata": {},
   "source": [
    "**Primer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_function_no.py\n",
    "n = 1000000\n",
    "\n",
    "while n > 0:\n",
    "    n -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f20a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_function_yes.py\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "\n",
    "countdown(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f670ca7",
   "metadata": {},
   "source": [
    "    time python 01_function_no.py\n",
    "    time python 01_function_yes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76409d72",
   "metadata": {},
   "source": [
    "### Selectively eliminate attribute access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f1cb0",
   "metadata": {},
   "source": [
    "Every use of the dot (.) operator to access attributes comes with a cost. Under the covers,\n",
    "this triggers special methods, such as `__getattribute__()` and `_getattr__()`, which\n",
    "often lead to dictionary lookups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906690d5",
   "metadata": {},
   "source": [
    "You can often avoid attribute lookups by using the from module import name form of\n",
    "import as well as making selected use of bound methods. To illustrate, consider the\n",
    "following code fragment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339965ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_access.py\n",
    "import math\n",
    "\n",
    "def compute_roots(nums):\n",
    "    result = []\n",
    "    for n in nums:\n",
    "        result.append(math.sqrt(n))\n",
    "    return result\n",
    "\n",
    "# Test\n",
    "nums = range(1000000)\n",
    "for n in range(10):\n",
    "    r = compute_roots(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1be0f6",
   "metadata": {},
   "source": [
    "When tested on our machine, this program runs in about 40 seconds. Now change the\n",
    "compute_roots() function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea29a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_noaccess.py\n",
    "from math import sqrt\n",
    "\n",
    "def compute_roots(nums):\n",
    "    result = []\n",
    "    result_append = result.append\n",
    "    for n in nums:\n",
    "        result_append(sqrt(n))\n",
    "    return result\n",
    "    \n",
    "# Test\n",
    "nums = range(1000000)\n",
    "for n in range(10):\n",
    "    r = compute_roots(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb519772",
   "metadata": {},
   "source": [
    "This version runs in about 29 seconds. The only difference between the two versions of\n",
    "code is the elimination of attribute access. Instead of using math.sqrt(), the code uses\n",
    "sqrt(). The result.append() method is additionally placed into a local variable result_append and reused in the inner loop.\n",
    "\n",
    "However, it must be emphasized that these changes only make sense in frequently executed\n",
    "code, such as loops. So, this optimization really only makes sense in carefully\n",
    "selected places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fb7a2",
   "metadata": {},
   "source": [
    "### Understand locality of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b2dde",
   "metadata": {},
   "source": [
    "As previously noted, local variables are faster than global variables. For frequently accessed\n",
    "names, speedups can be obtained by making those names as local as possible.\n",
    "For example, consider this modified version of the compute_roots() function just\n",
    "discussed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68004207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_roots(nums):\n",
    "    sqrt = math.sqrt\n",
    "    result = []\n",
    "    result_append = result.append\n",
    "    for n in nums:\n",
    "        result_append(sqrt(n))\n",
    "    return result\n",
    "\n",
    "# Test\n",
    "nums = range(1000000)\n",
    "for n in range(10):\n",
    "    r = compute_roots(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed13b0",
   "metadata": {},
   "source": [
    "In this version, sqrt has been lifted from the math module and placed into a local\n",
    "variable. If you run this code, it now runs in about 25 seconds (an improvement over\n",
    "the previous version, which took 29 seconds). That additional speedup is due to a local\n",
    "lookup of sqrt being a bit faster than a global lookup of sqrt.\n",
    "\n",
    "Locality arguments also apply when working in classes. In general, looking up a value\n",
    "such as self.name will be considerably slower than accessing a local variable. In inner\n",
    "loops, it might pay to lift commonly accessed attributes into a local variable. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60581f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slower\n",
    "class SomeClass:\n",
    "    # neki\n",
    "    def method(self):\n",
    "        for x in s:\n",
    "            op(self.value)\n",
    "\n",
    "# Faster\n",
    "class SomeClass:\n",
    "    # neki\n",
    "    def method(self):\n",
    "        value = self.value\n",
    "        for x in s:\n",
    "            op(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9703f7",
   "metadata": {},
   "source": [
    "### Avoid gratuitous abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4450a8d",
   "metadata": {},
   "source": [
    "Any time you wrap up code with extra layers of processing, such as decorators, properties,\n",
    "or descriptors, you’re going to make it slower. As an example, consider this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413c1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    @y.setter\n",
    "    def y(self, value):\n",
    "        self._y = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213978e",
   "metadata": {},
   "source": [
    "Now, try a simple timing test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f51f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "a = A(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c819eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11272381200024029"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit('a.x', 'from __main__ import a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b324e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2618356349998976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit('a.y', 'from __main__ import a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35f741",
   "metadata": {},
   "source": [
    "As you can observe, accessing the property y is not just slightly slower than a simple\n",
    "attribute x, it’s about 4.5 times slower. If this difference matters, you should ask yourself\n",
    "if the definition of y as a property was really necessary. If not, simply get rid of it and\n",
    "go back to using a simple attribute instead. Just because it might be common for programs\n",
    "in another programming language to use getter/setter functions, that doesn’t\n",
    "mean you should adopt that programming style for Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a84ac",
   "metadata": {},
   "source": [
    "### Use the built-in containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c735a32",
   "metadata": {},
   "source": [
    "Built-in data types such as strings, tuples, lists, sets, and dicts are all implemented in C,\n",
    "and are rather fast. If you’re inclined to make your own data structures as a replacement\n",
    "(e.g., linked lists, balanced trees, etc.), it may be rather difficult if not impossible to match\n",
    "the speed of the built-ins. Thus, you’re often better off just using them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aafa65",
   "metadata": {},
   "source": [
    "[collections — Container datatypes](https://docs.python.org/3.8/library/collections.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15655537",
   "metadata": {},
   "source": [
    "### Avoid making unnecessary data structures or copies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8a1805",
   "metadata": {},
   "source": [
    "Sometimes programmers get carried away with making unnecessary data structures\n",
    "when they just don’t have to. For example, someone might write code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9398ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tuple(range(50))\n",
    "\n",
    "values = [x for x in sequence]\n",
    "squares = [x*x for x in values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf3d7d",
   "metadata": {},
   "source": [
    "Perhaps the thinking here is to first collect a bunch of values into a list and then to start\n",
    "applying operations such as list comprehensions to it. However, the first list is completely\n",
    "unnecessary. Simply write the code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3192f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = [x*x for x in sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4baa03",
   "metadata": {},
   "source": [
    "Related to this, be on the lookout for code written by programmers who are overly\n",
    "paranoid about Python’s sharing of values. Overuse of functions such as copy.deep\n",
    "copy() may be a sign of code that’s been written by someone who doesn’t fully understand\n",
    "or trust Python’s memory model. In such code, it may be safe to eliminate many\n",
    "of the copies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bd22f",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0fcbc",
   "metadata": {},
   "source": [
    "Before optimizing, it’s usually worthwhile to study the algorithms that you’re using first.\n",
    "You’ll get a much bigger speedup by switching to an O(n log n) algorithm than by\n",
    "trying to tweak the implementation of an an O(n**2) algorithm.\n",
    "\n",
    "If you’ve decided that you still must optimize, it pays to consider the big picture. As a\n",
    "general rule, you don’t want to apply optimizations to every part of your program,\n",
    "because such changes are going to make the code hard to read and understand. Instead,\n",
    "focus only on known performance bottlenecks, such as inner loops.\n",
    "\n",
    "You need to be especially wary interpreting the results of micro-optimizations. For\n",
    "example, consider these two techniques for creating a dictionary:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f444fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "'name' : 'AAPL',\n",
    "'shares' : 100,\n",
    "'price' : 534.22\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3686f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dict(name='AAPL', shares=100, price=534.22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378a44e",
   "metadata": {},
   "source": [
    "The latter choice has the benefit of less typing (you don’t need to quote the key names).\n",
    "However, if you put the two code fragments in a head-to-head performance battle, you’ll\n",
    "find that using dict() runs three times slower! With this knowledge, you might be\n",
    "inclined to scan your code and replace every use of dict() with its more verbose alternative.\n",
    "However, a smart programmer will only focus on parts of a program where\n",
    "it might actually matter, such as an inner loop. In other places, the speed difference just\n",
    "isn’t going to matter at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecf46c",
   "metadata": {},
   "source": [
    "If, on the other hand, your performance needs go far beyond the simple techniques in\n",
    "this recipe, you might investigate the use of tools based on just-in-time (JIT) compilation\n",
    "techniques. For example, the PyPy project is an alternate implementation of the Python interpreter \n",
    "that analyzes the execution of your program and generates native machine\n",
    "code for frequently executed parts. It can sometimes make Python programs run an\n",
    "order of magnitude faster, often approaching (or even exceeding) the speed of code\n",
    "written in C. Unfortunately, as of this writing, PyPy does not yet fully support Python3. \n",
    "So, that is something to look for in the future. You might also consider the Numba\n",
    "project. Numba is a dynamic compiler where you annotate selected Python functions\n",
    "that you want to optimize with a decorator. Those functions are then compiled into\n",
    "native machine code through the use of LLVM. It too can produce signficant performance\n",
    "gains. However, like PyPy, support for Python 3 should be viewed as somewhat\n",
    "experimental.\n",
    "\n",
    "Last, but not least, the words of John Ousterhout come to mind: “The best performance\n",
    "improvement is the transition from the nonworking to the working state.” Don’t worry\n",
    "about optimization until you need to. Making sure your program works correctly is\n",
    "usually more important than making it run fast (at least initially)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7dad1",
   "metadata": {},
   "source": [
    "## PyPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd588f02",
   "metadata": {},
   "source": [
    "[PyPy: Faster Python With Minimal Effort](https://realpython.com/pypy-faster-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139593b",
   "metadata": {},
   "source": [
    "Python is one of the most popular programming languages among developers, but it has certain limitations. For example, depending on the application, it can be up to 100 times as slow as some lower-level languages. That’s why many companies rewrite their applications in another language once Python’s speed becomes a bottleneck for users. But what if there was a way to keep Python’s awesome features and improve its speed? Enter PyPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6bdc5",
   "metadata": {},
   "source": [
    "https://doc.pypy.org/en/latest/introduction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0afc1c",
   "metadata": {},
   "source": [
    "PyPy is a very compliant Python interpreter that is a worthy alternative to CPython 2.7, 3.6, and soon 3.7. By installing and running your application with it, you can gain noticeable speed improvements. How much of an improvement you’ll see depends on the application you’re running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d0691",
   "metadata": {},
   "source": [
    "### Python and PyPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20047ffb",
   "metadata": {},
   "source": [
    "The Python language specification is used in a number of implementations such as CPython (written in C), Jython (written in Java), IronPython (written for .NET), and PyPy (written in Python).\n",
    "\n",
    "CPython is the original implementation of Python and is by far the most popular and most maintained. When people refer to Python, they more often than not mean CPython. You’re probably using CPython right now!\n",
    "\n",
    "However, because it’s a high-level interpreted language, CPython has certain limitations and won’t win any medals for speed. That’s where PyPy can come in handy. Since it adheres to the Python language specification, PyPy requires no change in your codebase and can offer significant speed improvements thanks to the features you’ll see below.\n",
    "\n",
    "Now, you may be wondering why CPython doesn’t implement PyPy’s awesome features if they use the same syntax. The reason is that **implementing those features would require huge changes to the source code and would be a major undertaking**.\n",
    "\n",
    "Without diving too much into theory, let’s see PyPy in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cc4d1",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fe02b",
   "metadata": {},
   "source": [
    "If not, you can download a prebuilt binary for your OS and architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904780a",
   "metadata": {},
   "source": [
    "https://doc.pypy.org/en/latest/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07dcc20",
   "metadata": {},
   "source": [
    "Izpišemo možne verzije:\n",
    "    \n",
    "    pyenv install --list | grep pypy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a43a24",
   "metadata": {},
   "source": [
    "Namestimo:\n",
    "    \n",
    "    pyenv install -v pypy3.7-7.3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0e25f",
   "metadata": {},
   "source": [
    "#### PyPy in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f343b46",
   "metadata": {},
   "source": [
    "You now have PyPy installed and you’re ready to see it in action! To do that, create a Python file called script.py and put the following code in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "total = 0\n",
    "for i in range(1, 10000):\n",
    "    for j in range(1, 10000):\n",
    "        total += i + j\n",
    "\n",
    "print(f\"The result is {total}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"It took {end_time-start_time:.2f} seconds to compute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16786916",
   "metadata": {},
   "source": [
    "This is a script that, in two nested for loops, adds the numbers from 1 to 9,999, and prints the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7c55e",
   "metadata": {},
   "source": [
    "Try running it with Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616fc43",
   "metadata": {},
   "source": [
    "    pyenv local 3.9.5\n",
    "    python script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e683f",
   "metadata": {},
   "source": [
    "    The result is 999800010000\n",
    "    It took 48.34 seconds to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f295e42",
   "metadata": {},
   "source": [
    "Now run it with PyPy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d08abe",
   "metadata": {},
   "source": [
    "    pyenv local pypy3.7-7.3.4\n",
    "    python script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639c3b0",
   "metadata": {},
   "source": [
    "    The result is 999800010000\n",
    "    It took 0.49 seconds to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b801a7",
   "metadata": {},
   "source": [
    "In this small synthetic benchmark, PyPy is roughly 94 times as fast as Python!\n",
    "\n",
    "For more serious benchmarks, you can take a look at the PyPy Speed Center, where the developers run nightly benchmarks with different executables.\n",
    "\n",
    "https://speed.pypy.org/\n",
    "\n",
    "Keep in mind that how PyPy affects the performance of your code depends on what your code is doing. There are some situations in which PyPy is actually slower, as you’ll see later. However, on geometric average, it’s 4.3 times as fast as Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d267114",
   "metadata": {},
   "source": [
    "## PyPy and Its Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fa5fe",
   "metadata": {},
   "source": [
    "Historically, PyPy has referred to two things:\n",
    "\n",
    "1. A dynamic language framework for generating interpreters for dynamic languages\n",
    "2. A Python implementation using that framework\n",
    "\n",
    "You’ve already seen the second meaning in action by installing PyPy and running a small script with it. The Python implementation you used was written using a dynamic language framework called RPython, just like CPython was written in C and Jython was written in Java.\n",
    "\n",
    "But weren’t you told earlier that PyPy was written in Python? Well, that’s a little bit of a simplification. The reason PyPy became known as a Python interpreter written in Python (and not in RPython) is that RPython uses the same syntax as Python.\n",
    "\n",
    "To clear everything up, here’s how PyPy is produced:\n",
    "\n",
    "1. The source code is written in RPython.\n",
    "2. The RPython translation toolchain is applied to the code, which basically makes the code more efficient. It also compiles the code down into machine code, which is why Mac, Windows, and Linux users have to download different versions.\n",
    "3. A binary executable is produced. This is the Python interpreter that you used to run your small script.\n",
    "\n",
    "Keep in mind that you don’t need to go through all these steps to use PyPy. The executable is already available for you to install and use.\n",
    "\n",
    "Also, since it’s very confusing to use the same word for both the framework and the implementation, the team behind PyPy decided to move away from this double usage. Now, PyPy refers only to the Python implementation. The framework is referred to as the RPython translation toolchain.\n",
    "\n",
    "Next, you’ll learn about the features that make PyPy better and faster than Python in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6c28c",
   "metadata": {},
   "source": [
    "#### Just-In-Time (JIT) Compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fec26d",
   "metadata": {},
   "source": [
    "<section class=\"section3\" id=\"just-in-time-jit-compiler\">\n",
    "<p>Before getting into what JIT compilation is, let’s take a step back and review the properties of <a href=\"https://en.wikipedia.org/wiki/Compiled_language\">compiled</a> languages such as C and <a href=\"https://en.wikipedia.org/wiki/Interpreted_language\">interpreted languages</a> such as JavaScript.</p>\n",
    "<p><strong>Compiled</strong> programming languages are more performant but are harder to port to different CPU architectures and operating systems. <strong>Interpreted</strong> programming languages are more portable, but their performance is much worse than that of compiled languages. These are the two extremes of the spectrum.</p>\n",
    "<p>Then there are programming languages such as Python that do a mix of both compilation and interpretation. Specifically, Python is first compiled into an <strong>intermediate bytecode</strong>, which is then interpreted by CPython. This makes the code perform better than code written in a purely interpreted programming language, and it maintains the portability advantage.</p>\n",
    "<p>However, the performance is still nowhere near that of the compiled version. The reason is that the compiled code can do a lot of optimizations that just aren’t possible with bytecode.</p>\n",
    "<p>That’s where the <strong>just-in-time (JIT) compiler</strong> comes in. It tries to get the better parts of the both worlds by doing some real compilation into machine code and some interpretation. In a nutshell, here are the steps JIT compilation takes to provide faster performance:</p>\n",
    "<ol>\n",
    "<li>Identify the most frequently used components of the code, such as a function in a loop.</li>\n",
    "<li>Convert those parts into machine code during runtime.</li>\n",
    "<li>Optimize the generated machine code.</li>\n",
    "<li>Swap the previous implementation with the optimized machine code version.</li>\n",
    "</ol>\n",
    "<p>Remember the two nested loops at the beginning of the tutorial? PyPy detected that the same operation was being executed over and over again, compiled it into machine code, optimized the machine code, and then swapped the implementations. That’s why you saw such a big improvement in speed.</p>\n",
    "</section>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa06318",
   "metadata": {},
   "source": [
    "#### Garbage Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36554bcd",
   "metadata": {},
   "source": [
    "Whenever you create variables, functions, or any other objects, your computer allocates memory to them. Eventually, some of those objects will no longer be needed. If you don’t clean them up, then your computer may run out of memory and crash your program.\n",
    "\n",
    "In programming languages such as C and C++, you usually have to deal with this problem manually. Other programming languages such as Python and Java do it for you automatically. This is called automatic garbage collection, and there are several techniques for accomplishing it.\n",
    "\n",
    "CPython uses a technique called reference counting. Essentially, a Python object’s reference count is incremented whenever the object is referenced, and it’s decremented when the object is dereferenced. When the reference count is zero, CPython automatically calls the memory deallocation function for that object. It’s a straightforward and effective technique, but there’s a catch.\n",
    "\n",
    "When the reference count of a large tree of objects becomes zero, all the related objects are freed. As a result, you have a potentially long pause during which your program doesn’t progress at all.\n",
    "\n",
    "Also, there’s a use case in which reference counting simply doesn’t work. Consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(object):\n",
    "    pass\n",
    "\n",
    "a = A()\n",
    "a.some_property = a\n",
    "del a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fcfeb0",
   "metadata": {},
   "source": [
    "In the code above, you define new class. Then, you create an instance of the class and assign it to be a property on itself. Finally, you delete the instance.\n",
    "\n",
    "At this point, the instance is no longer accessible. However, reference counting doesn’t delete the instance from memory because it has a reference to itself, so the reference count is not zero. This problem is called a reference cycle, and it can’t be solved using reference counting.\n",
    "\n",
    "This is where CPython uses another tool called the cyclic garbage collector. It walks over all objects in memory starting from known roots like the type object. It then identifies all reachable objects and frees unreachable objects since they aren’t alive anymore. This solves the reference cycle problem. However, it can create even more noticeable pauses when there are a large number of objects in memory.\n",
    "\n",
    "PyPy, on the other hand, doesn’t use reference counting. Instead, it uses only the second technique, the cycle finder. That is, it periodically walks over alive objects starting from the roots. This gives PyPy some advantage over CPython since it doesn’t bother with reference counting, making the total time spent in memory management less than in CPython.\n",
    "\n",
    "Also, instead of doing everything in one major undertaking like CPython, PyPy splits the work into a variable number of pieces and runs each piece until none are left. This approach adds just a few milliseconds after each minor collection rather than adding hundreds of milliseconds in one go like CPython.\n",
    "\n",
    "Garbage collection is complex and has many more details that go beyond the scope of this tutorial. You can find more information about PyPy’s garbage collection in the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f378b0b",
   "metadata": {},
   "source": [
    "### Limitations of PyPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9e0b4",
   "metadata": {},
   "source": [
    "PyPy isn’t a silver bullet and may not always be the most suitable tool for your task. It may even make your application perform much slower than CPython. That’s why it’s important that you keep the following limitations in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eaf586",
   "metadata": {},
   "source": [
    "#### It Doesn’t Work Well With C Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b095f",
   "metadata": {},
   "source": [
    "**PyPy works best with pure Python applications**. Whenever you use a C extension module, it runs much slower than in CPython. The reason is that PyPy can’t optimize C extension modules since they’re not fully supported. In addition, PyPy has to emulate reference counting for that part of the code, making it even slower.\n",
    "\n",
    "In such cases, the PyPy team recommends taking out the CPython extension and replacing it with a pure Python version so that JIT can see it and do its optimizations. If that’s not an option, then you’ll have to use CPython.\n",
    "\n",
    "With that being said, the core team is working on C extensions. Some packages have already been ported to PyPy and work just as fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d10c7",
   "metadata": {},
   "source": [
    "#### It Only Works Well With Long-Running Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0e07d",
   "metadata": {},
   "source": [
    "Imagine you want to go to a shop that is very close to your home. You can either go on foot or drive.\n",
    "\n",
    "Your car is clearly much faster than your feet. However, think about what it would require you to do:\n",
    "\n",
    "- Go to your garage.\n",
    "- Start your car.\n",
    "- Warm the car up a little.\n",
    "- Drive to the shop.\n",
    "- Find a parking spot.\n",
    "- Repeat the process on your way back.\n",
    "\n",
    "There’s a lot of overhead involved in driving a car, and it’s not always worth it if the place you want to go is nearby!\n",
    "\n",
    "Now think about what would happen if you wanted to go to a neighboring city fifty miles away. It would certainly be worth it to drive there instead of going on foot.\n",
    "\n",
    "Although the difference in speed isn’t quite so noticeable as in the above analogy, the same is true with PyPy and CPython.\n",
    "\n",
    "When you run a script with PyPy, it does a lot of things to make your code run faster. If the script is too small, then the overhead will cause your script would run slower than in CPython. On the other hand, if you have a long-running script, then that overhead can pay significant performance dividends.\n",
    "\n",
    "To see for yourself, run the following small script in both CPython and PyPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"It took {end_time-start_time:.10f} seconds to compute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e6461",
   "metadata": {},
   "source": [
    "There’s a small delay at the beginning when you run it with PyPy, while CPython runs it instantly. In exact numbers, it takes 0.0004873276 seconds to run it on a 2015 MacBook Pro with CPython and 0.0019447803 seconds to run it with PyPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a3d7c",
   "metadata": {},
   "source": [
    "#### It Doesn’t Do Ahead-Of-Time Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca3673",
   "metadata": {},
   "source": [
    "As you saw at the beginning of this tutorial, PyPy isn’t a fully compiled Python implementation. It compiles Python code, but it isn’t a compiler for Python code. Because of the inherent dynamism of Python, it’s impossible to compile Python into a standalone binary and reuse it.\n",
    "\n",
    "PyPy is a runtime interpreter that is faster than a fully interpreted language, but it’s slower than a fully compiled language such as C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5edbcc",
   "metadata": {},
   "source": [
    "> PyPy is a fast and capable alternative to CPython. By running your script with it, you can get a major speed improvement without making a single change to your code. But it’s not a silver bullet. It has some limitations, and you’ll need to test your program to see if PyPy can be of help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4947a",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed670ba",
   "metadata": {},
   "source": [
    "- [Make python fast with numba](https://thedatafrog.com/en/articles/make-python-fast-numba/)\n",
    "- [Boost python with your GPU (numba+CUDA)](https://thedatafrog.com/en/articles/boost-python-gpu/)\n",
    "- [Speed Up your Algorithms Part 2— Numba](https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1)\n",
    "- [numba_tutorial_scipy2017](https://github.com/gforsyth/numba_tutorial_scipy2017/tree/master/notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4b2c7",
   "metadata": {},
   "source": [
    "https://numba.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d502cd4",
   "metadata": {},
   "source": [
    "Numba is a just-in-time compiler for Python that works best on code that uses NumPy arrays and functions, and loops. The most common way to use Numba is through its collection of decorators that can be applied to your functions to instruct Numba to compile them. When a call is made to a Numba decorated function it is compiled to machine code “just-in-time” for execution and all or part of your code can subsequently run at native machine code speed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16678b",
   "metadata": {},
   "source": [
    "Out of the box Numba works with the following:\n",
    "\n",
    "- OS: Windows (32 and 64 bit), OSX and Linux (32 and 64 bit)\n",
    "- Architecture: x86, x86_64, ppc64le. Experimental on armv7l, armv8l (aarch64).\n",
    "- GPUs: Nvidia CUDA. Experimental on AMD ROC.\n",
    "- CPython\n",
    "- NumPy 1.15 - latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf271519",
   "metadata": {},
   "source": [
    "- Works within the standard Python interpreter, and does not replace it\n",
    "- Integrates tightly with NumPy\n",
    "- Compatible with both multithreaded and distributed computing paradigms\n",
    "- Can be targeted at non-CPU hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782352d8",
   "metadata": {},
   "source": [
    "### A JIT Compiler for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f591c5a",
   "metadata": {},
   "source": [
    "Numba reads the Python bytecode for a decorated function and combines this with information about the types of the input arguments to the function. It analyzes and optimizes your code, and finally uses the LLVM compiler library to generate a machine code version of your function, tailored to your CPU capabilities. This compiled version is then used every time your function is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea4ef1",
   "metadata": {},
   "source": [
    "- An open-source, function-at-a-time compiler library for Python\n",
    "- Compiler toolbox for different targets and execution models:\n",
    "    - single-threaded CPU, multi-threaded CPU, GPU\n",
    "    - regular functions, “universal functions” (array functions), etc\n",
    "- Speedup: 2x (compared to basic NumPy code) to 200x (compared to pure Python)\n",
    "- Combine ease of writing Python with speeds approaching FORTRAN\n",
    "- BSD licensed (including GPU compiler)\n",
    "- Goal is to empower scientists who make tools for themselves and other scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc627ece",
   "metadata": {},
   "source": [
    "Numba may be best understood by what it **is not**:\n",
    "- Replacement Python interpreter: PyPy, Pyston, Pyjion\n",
    "    - Hard to implement\n",
    "    - Difficult (but not impossible) to maintain compatibility with existing Python extensions\n",
    "    - Does not address non-CPU targets\n",
    "- Translator of Python to C/C++: Cython, Pythran, Theano, ShedSkin, Nuitka\n",
    "    - Static analysis of dynamic languages is limiting\n",
    "    - Ahead-of-time generated code is either underspecialized (both in data types and CPU capabilities) or bloated to cover all variants\n",
    "    - JIT compilation requires C/C++ compiler on end user system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec342489",
   "metadata": {},
   "source": [
    "### Numba Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b156c",
   "metadata": {},
   "source": [
    "- Detects CPU model during compilation and optimizes for that target\n",
    "- Automatic type inference: No need to give type signatures for functions\n",
    "- Dispatches to multiple type-specializations for the same function\n",
    "- Call out to C libraries with CFFI and types\n",
    "- Special \"callback\" mode for creating C callbacks to use with external libraries\n",
    "- Optional caching to disk, and ahead-of-time creation of shared libraries\n",
    "- Compiler is extensible with new data types and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cae3a",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cca983",
   "metadata": {},
   "source": [
    "Numba also has wheels available:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfcc6d",
   "metadata": {},
   "source": [
    "    pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d65a3",
   "metadata": {},
   "source": [
    "Numba is often used as a core package so its dependencies are kept to an absolute minimum, however, extra packages can be installed as follows to provide additional functionality:\n",
    "- `scipy` - enables support for compiling numpy.linalg functions.\n",
    "- `colorama` - enables support for color highlighting in backtraces/error messages.\n",
    "- `pyyaml` - enables configuration of Numba via a YAML config file.\n",
    "- `icc_rt` - allows the use of the Intel SVML (high performance short vector math library, x86_64 only). Installation instructions are in the performance tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cda555",
   "metadata": {},
   "source": [
    "### Will Numba work for my code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf421012",
   "metadata": {},
   "source": [
    "This depends on what your code looks like, if your code is numerically orientated (does a lot of math), uses NumPy a lot and/or has a lot of loops, then Numba is often a good choice. In these examples we’ll apply the most fundamental of Numba’s JIT decorators, `@jit`, to try and speed up some functions to demonstrate what works well and what does not.\n",
    "\n",
    "Numba works well on code that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e970c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def go_fast(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "    return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "print(go_fast(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44d02c",
   "metadata": {},
   "source": [
    "It won’t work very well, if at all, on code that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e674fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import pandas as pd\n",
    "\n",
    "x = {'a': [1, 2, 3], 'b': [20, 30, 40]}\n",
    "\n",
    "@jit\n",
    "def use_pandas(a): # Function will not benefit from Numba jit\n",
    "    df = pd.DataFrame.from_dict(a) # Numba doesn't know about pd.DataFrame\n",
    "    df += 1                        # Numba doesn't understand what this is\n",
    "    return df.cov()                # or this!\n",
    "\n",
    "print(use_pandas(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7b309",
   "metadata": {},
   "source": [
    "Note that Pandas is not understood by Numba and as a result Numba would simply run this code via the interpreter but with the added cost of the Numba internal overheads!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563b3b2",
   "metadata": {},
   "source": [
    "The Numba `@jit` decorator fundamentally operates in two compilation modes, `nopython` mode and `object` mode. In the go_fast example above, `nopython=True` is set in the `@jit` decorator; this is instructing Numba to operate in `nopython` mode. The behaviour of the `nopython` compilation mode is to essentially compile the decorated function so that it will run entirely without the involvement of the Python interpreter. This is the recommended and best-practice way to use the Numba jit decorator as it leads to the best performance.\n",
    "\n",
    "Should the compilation in `nopython` mode fail, Numba can compile using `object` mode. This is a fall back mode for the `@jit` decorator if `nopython=True` is not set (as seen in the use_pandas example above). In this mode Numba will identify loops that it can compile and compile those into functions that run in machine code, and it will run the rest of the code in the interpreter. For best performance avoid using this mode!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b43a4",
   "metadata": {},
   "source": [
    "### How to measure the performance of Numba?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80597e9f",
   "metadata": {},
   "source": [
    "First, recall that Numba has to compile your function for the argument types given before it executes the machine code version of your function. This takes time. However, once the compilation has taken place Numba caches the machine code version of your function for the particular types of arguments presented. If it is called again with the same types, it can reuse the cached version instead of having to compile again.\n",
    "\n",
    "A really common mistake when measuring performance is to not account for the above behaviour and to time code once with a simple timer that includes the time taken to compile your function in the execution time.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa72424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (with compilation) = 0.9285945892333984\n",
      "Elapsed (after compilation) = 0.00021004676818847656\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a): # Function is compiled and runs in machine code\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed4642",
   "metadata": {},
   "source": [
    "A good way to measure the impact Numba JIT has on your code is to time execution using the timeit module functions; these measure multiple iterations of execution and, as a result, can be made to accommodate for the compilation time in the first execution.\n",
    "\n",
    "As a side note, if compilation time is an issue, Numba JIT supports on-disk caching of compiled functions and also has an Ahead-Of-Time compilation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb293de",
   "metadata": {},
   "source": [
    "https://numba.readthedocs.io/en/stable/reference/jit-compilation.html#jit-decorator-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef869d6",
   "metadata": {},
   "source": [
    "### How fast is it?\n",
    "Assuming Numba can operate in nopython mode, or at least compile some loops, it will target compilation to your specific CPU. Speed up varies depending on application but can be one to two orders of magnitude. Numba has a performance guide that covers common options for gaining extra performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57f9ac",
   "metadata": {},
   "source": [
    "https://numba.readthedocs.io/en/stable/user/performance-tips.html#performance-tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29036dfb",
   "metadata": {},
   "source": [
    "https://www.infoworld.com/article/3247799/what-is-llvm-the-power-behind-swift-rust-clang-and-more.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9595e",
   "metadata": {},
   "source": [
    "### When is Numba a Good Idea?\n",
    "- Numerical algorithms\n",
    "- Data is in the form of NumPy arrays, or (more broadly) flat data buffers\n",
    "- Performance bottleneck is a handful of well encapsulated functions\n",
    "- Example use cases:\n",
    "    - Compiling user-defined functions to call from another algorithm (like an optimizer)\n",
    "    - Creating \"missing\" NumPy/SciPy functions (librosa)\n",
    "    - Rapidly prototyping GPU algorithms (FBPIC)\n",
    "    - Constructing specialized Python compilers (HPAT, OAMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77b792",
   "metadata": {},
   "source": [
    "### Primer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97009c",
   "metadata": {},
   "source": [
    "Here is a function that can take a bit of time. This function takes a list of numbers, and returns the standard deviation of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040df122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def std(xs):\n",
    "    # compute the mean\n",
    "    mean = 0\n",
    "    for x in xs: \n",
    "        mean += x\n",
    "    mean /= len(xs)\n",
    "    # compute the variance\n",
    "    ms = 0\n",
    "    for x in xs:\n",
    "        ms += (x-mean)**2\n",
    "    variance = ms / len(xs)\n",
    "    std = math.sqrt(variance)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8195c5",
   "metadata": {},
   "source": [
    "As we can see in the code, we need to loop twice on the sample of numbers: first to compute the mean, and then to compute the variance, which is the square of the standard deviation.\n",
    "\n",
    "Obviously, the more numbers in the sample, the more time the function will take to complete. Let's start with 10 million numbers, drawn from a Gaussian distribution of unit standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae2fe288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.normal(0, 1, 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03eba6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 0 ns, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.000082316558144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c1d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 0 ns, total: 13 s\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.000082316558144"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time std(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0766521",
   "metadata": {},
   "source": [
    "The function takes a couple seconds to compute the standard deviation of the sample.\n",
    "\n",
    "Now, let's import the njit decorator from numba, and decorate our std function to create a new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "546f586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d83b4",
   "metadata": {},
   "source": [
    " To make it such that only no python mode is used and if compilation fails an exception is raised the decorators `@njit` and `@jit(nopython=True)` can be used (the first is an alias of the second for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9d03f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def c_std(xs):\n",
    "    # compute the mean\n",
    "    mean = 0\n",
    "    for x in xs: \n",
    "        mean += x\n",
    "    mean /= len(xs)\n",
    "    # compute the variance\n",
    "    ms = 0\n",
    "    for x in xs:\n",
    "        ms += (x-mean)**2\n",
    "    variance = ms / len(xs)\n",
    "    std = math.sqrt(variance)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc6e9d",
   "metadata": {},
   "source": [
    "The performance improvement might not seem striking, maybe due to some overhead related with interpreting the code in the notebook. Also, please keep in mind that the first time the function is called, numba will need to compile the function, which takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e36ad828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 490 ms, sys: 27.7 ms, total: 518 ms\n",
      "Wall time: 528 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.000082316558144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prvič je zraven še čas za complile\n",
    "%time c_std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "077cb221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 ms, sys: 0 ns, total: 41.8 ms\n",
      "Wall time: 41.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.000082316558144"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time c_std(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50d04b",
   "metadata": {},
   "source": [
    "Primer z vgrajeno numpy funkcijo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0376d2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.5 ms, sys: 28.3 ms, total: 81.8 ms\n",
      "Wall time: 79.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0000823165582082"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.std(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5477c",
   "metadata": {},
   "source": [
    "### Primer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f9d3f",
   "metadata": {},
   "source": [
    "Whilst NumPy has developed a strong idiom around the use of vector operations, Numba is perfectly happy with loops too. For users familiar with C or Fortran, writing Python in this style will work fine in Numba (after all, LLVM gets a lot of use in compiling C lineage languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4417f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "original = np.arange(0.0, 30.0, 0.01, dtype='f4')\n",
    "shuffled = original.copy()\n",
    "np.random.shuffle(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a70ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubblesort(X):\n",
    "    N = len(X)\n",
    "    for end in range(N, 1, -1):\n",
    "        for i in range(end - 1):\n",
    "            cur = X[i]\n",
    "            if cur > X[i + 1]:\n",
    "                tmp = X[i]\n",
    "                X[i] = X[i + 1]\n",
    "                X[i + 1] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5129e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.8 s, sys: 28.2 ms, total: 5.83 s\n",
      "Wall time: 5.84 s\n"
     ]
    }
   ],
   "source": [
    "%time bubblesort(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64391e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def c_bubblesort(X):\n",
    "    N = len(X)\n",
    "    for end in range(N, 1, -1):\n",
    "        for i in range(end - 1):\n",
    "            cur = X[i]\n",
    "            if cur > X[i + 1]:\n",
    "                tmp = X[i]\n",
    "                X[i] = X[i + 1]\n",
    "                X[i + 1] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46089ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 533 ms, sys: 44.1 ms, total: 577 ms\n",
      "Wall time: 576 ms\n"
     ]
    }
   ],
   "source": [
    "%time c_bubblesort(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93957f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 ms, sys: 0 ns, total: 15.5 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time c_bubblesort(shuffled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
