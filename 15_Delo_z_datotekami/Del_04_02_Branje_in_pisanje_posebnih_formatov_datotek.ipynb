{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 04: Parsanje, analiza podatkov in generiranje poročil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branje in pisanje posebnih formatov datotek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uvod v pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Namestimo pandas v virtualno okolje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><p>In the last two missions, we explored how the NumPy library makes working with data easier. Because we can easily work across multiple dimensions, our code is a lot easier to understand. By using vectorized operations instead of loops, our code runs faster with larger data.</p>\n",
    "<p>Although NumPy provides fundamental structures and tools that make working with data easier, there are several things that limit its usefulness:</p>\n",
    "<ul>\n",
    "<li>The lack of support for column names forces us to frame questions as multi-dimensional array operations.</li>\n",
    "<li>Support for only one data type per ndarray makes it more difficult to work with data that contains both numeric and string data.</li>\n",
    "<li>There are lots of low level methods, but there are many common analysis patterns that don't have pre-built methods.</li>\n",
    "</ul>\n",
    "<p>The <strong>pandas</strong> library provides solutions to all of these pain points and more. Pandas is not so much a replacement for NumPy as an <em>extension</em> of NumPy. The underlying code for pandas uses the NumPy library extensively, which means the concepts you've been learning will come in handy as you begin to learn more about pandas.</p>\n",
    "<p>The primary data structure in pandas is called a <a target=\"_blank\" href=\"(http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame)\"><strong>dataframe</strong></a>. Dataframes are the pandas equivalent of a Numpy 2D ndarray, with a few key differences:</p>\n",
    "<ul>\n",
    "<li>Axis values can have string <strong>labels</strong>, not just numeric ones.</li>\n",
    "<li>Dataframes can contain columns with <strong>multiple data types</strong>: including integer, float, and string.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is an open-source Python Library providing high-performance data manipulation and analysis tool using its powerful data structures. The name Pandas is derived from the word Panel Data – an Econometrics from Multidimensional data.\n",
    "\n",
    "In 2008, developer Wes McKinney started developing pandas when in need of high performance, flexible tool for analysis of data.\n",
    "\n",
    "Prior to Pandas, Python was majorly used for data munging and preparation. It had very little contribution towards data analysis. Pandas solved this problem. Using Pandas, we can accomplish five typical steps in the processing and analysis of data, regardless of the origin of data — load, prepare, manipulate, model, and analyze.\n",
    "\n",
    "Python with Pandas is used in a wide range of fields including academic and commercial domains including finance, economics, Statistics, analytics, etc.\n",
    "\n",
    "Key Features of Pandas\n",
    "- Fast and efficient DataFrame object with default and customized indexing.\n",
    "- Tools for loading data into in-memory data objects from different file formats.\n",
    "- Data alignment and integrated handling of missing data.\n",
    "- Reshaping and pivoting of date sets.\n",
    "- Label-based slicing, indexing and subsetting of large data sets.\n",
    "- Columns from a data structure can be deleted or inserted.\n",
    "- Group by data for aggregation and transformations.\n",
    "- High performance merging and joining of data.\n",
    "- Time Series functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the import convention for NumPy (import numpy as np), the import convention for pandas is:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f500 = pd.read_csv('data/f500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>rank</th>\n",
       "      <th>revenues</th>\n",
       "      <th>revenue_change</th>\n",
       "      <th>profits</th>\n",
       "      <th>assets</th>\n",
       "      <th>profit_change</th>\n",
       "      <th>ceo</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>previous_rank</th>\n",
       "      <th>country</th>\n",
       "      <th>hq_location</th>\n",
       "      <th>website</th>\n",
       "      <th>years_on_global_500_list</th>\n",
       "      <th>employees</th>\n",
       "      <th>total_stockholder_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>1</td>\n",
       "      <td>485873</td>\n",
       "      <td>0.8</td>\n",
       "      <td>13643.0</td>\n",
       "      <td>198825</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>C. Douglas McMillon</td>\n",
       "      <td>General Merchandisers</td>\n",
       "      <td>Retailing</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bentonville, AR</td>\n",
       "      <td>http://www.walmart.com</td>\n",
       "      <td>23</td>\n",
       "      <td>2300000</td>\n",
       "      <td>77798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State Grid</td>\n",
       "      <td>2</td>\n",
       "      <td>315199</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>9571.3</td>\n",
       "      <td>489838</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>Kou Wei</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Energy</td>\n",
       "      <td>2</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>http://www.sgcc.com.cn</td>\n",
       "      <td>17</td>\n",
       "      <td>926067</td>\n",
       "      <td>209456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sinopec Group</td>\n",
       "      <td>3</td>\n",
       "      <td>267518</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>1257.9</td>\n",
       "      <td>310726</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>Wang Yupu</td>\n",
       "      <td>Petroleum Refining</td>\n",
       "      <td>Energy</td>\n",
       "      <td>4</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>http://www.sinopec.com</td>\n",
       "      <td>19</td>\n",
       "      <td>713288</td>\n",
       "      <td>106523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company  rank  revenues  revenue_change  profits  assets  \\\n",
       "0        Walmart     1    485873             0.8  13643.0  198825   \n",
       "1     State Grid     2    315199            -4.4   9571.3  489838   \n",
       "2  Sinopec Group     3    267518            -9.1   1257.9  310726   \n",
       "\n",
       "   profit_change                  ceo               industry     sector  \\\n",
       "0           -7.2  C. Douglas McMillon  General Merchandisers  Retailing   \n",
       "1           -6.2              Kou Wei              Utilities     Energy   \n",
       "2          -65.0            Wang Yupu     Petroleum Refining     Energy   \n",
       "\n",
       "   previous_rank country      hq_location                 website  \\\n",
       "0              1     USA  Bentonville, AR  http://www.walmart.com   \n",
       "1              2   China   Beijing, China  http://www.sgcc.com.cn   \n",
       "2              4   China   Beijing, China  http://www.sinopec.com   \n",
       "\n",
       "   years_on_global_500_list  employees  total_stockholder_equity  \n",
       "0                        23    2300000                     77798  \n",
       "1                        17     926067                    209456  \n",
       "2                        19     713288                    106523  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f500.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pokažemo osnovne metode za pregled podatkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas I/O API is a set of top level reader functions accessed like pandas.read_csv() that generally return a pandas object. The corresponding writer functions are object methods that are accessed like DataFrame.to_csv(). Below is a table containing available readers and writers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IO tools (text, CSV, HDF5, …)](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"colwidths-given table\">\n",
    "<colgroup>\n",
    "<col style=\"width: 12%\">\n",
    "<col style=\"width: 40%\">\n",
    "<col style=\"width: 24%\">\n",
    "<col style=\"width: 24%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Format Type</p></th>\n",
    "<th class=\"head\"><p>Data Description</p></th>\n",
    "<th class=\"head\"><p>Reader</p></th>\n",
    "<th class=\"head\"><p>Writer</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p>text</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-read-csv-table\"><span class=\"std std-ref\">read_csv</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-store-in-csv\"><span class=\"std std-ref\">to_csv</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>text</p></td>\n",
    "<td><p>Fixed-Width Text File</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-fwf-reader\"><span class=\"std std-ref\">read_fwf</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>text</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://www.json.org/\">JSON</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-json-reader\"><span class=\"std std-ref\">read_json</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-json-writer\"><span class=\"std std-ref\">to_json</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>text</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/HTML\">HTML</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-read-html\"><span class=\"std std-ref\">read_html</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-html\"><span class=\"std std-ref\">to_html</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>text</p></td>\n",
    "<td><p>Local clipboard</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-clipboard\"><span class=\"std std-ref\">read_clipboard</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-clipboard\"><span class=\"std std-ref\">to_clipboard</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Microsoft_Excel\">MS Excel</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-excel-reader\"><span class=\"std std-ref\">read_excel</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-excel-writer\"><span class=\"std std-ref\">to_excel</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"http://www.opendocumentformat.org\">OpenDocument</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-ods\"><span class=\"std std-ref\">read_excel</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://support.hdfgroup.org/HDF5/whatishdf5.html\">HDF5 Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-hdf5\"><span class=\"std std-ref\">read_hdf</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-hdf5\"><span class=\"std std-ref\">to_hdf</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://github.com/wesm/feather\">Feather Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-feather\"><span class=\"std std-ref\">read_feather</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-feather\"><span class=\"std std-ref\">to_feather</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://parquet.apache.org/\">Parquet Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-parquet\"><span class=\"std std-ref\">read_parquet</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-parquet\"><span class=\"std std-ref\">to_parquet</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"//https://orc.apache.org/\">ORC Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-orc\"><span class=\"std std-ref\">read_orc</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://msgpack.org/index.html\">Msgpack</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-msgpack\"><span class=\"std std-ref\">read_msgpack</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-msgpack\"><span class=\"std std-ref\">to_msgpack</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Stata\">Stata</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-stata-reader\"><span class=\"std std-ref\">read_stata</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-stata-writer\"><span class=\"std std-ref\">to_stata</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SAS_(software)\">SAS</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-sas-reader\"><span class=\"std std-ref\">read_sas</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SPSS\">SPSS</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-spss-reader\"><span class=\"std std-ref\">read_spss</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://docs.python.org/3/library/pickle.html\">Python Pickle Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-pickle\"><span class=\"std std-ref\">read_pickle</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-pickle\"><span class=\"std std-ref\">to_pickle</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>SQL</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SQL\">SQL</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-sql\"><span class=\"std std-ref\">read_sql</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-sql\"><span class=\"std std-ref\">to_sql</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>SQL</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/BigQuery\">Google BigQuery</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-bigquery\"><span class=\"std std-ref\">read_gbq</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-bigquery\"><span class=\"std std-ref\">to_gbq</span></a></p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branje in pisanje JSON datotek\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since its inception, JSON has quickly become the de facto standard for information exchange. Chances are you’re here because you need to transport some data from here to there. Perhaps you’re gathering information through an API or storing your data in a document database. One way or another, you’re up to your neck in JSON, and you’ve got to Python your way out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A (Very) Brief History of JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so surprisingly, JavaScript Object Notation was inspired by a subset of the JavaScript programming language dealing with object literal syntax. They’ve got a nifty website that explains the whole thing. Don’t worry though: JSON has long since become language agnostic and exists as its own standard, so we can thankfully avoid JavaScript for the sake of this discussion.\n",
    "\n",
    "Ultimately, the community at large adopted JSON because it’s easy for both humans and machines to create and understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, JSON supports primitive types, like strings and numbers, as well as nested lists and objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Wait, that looks like a Python dictionary! I know, right? It’s pretty much universal object notation at this point, but I don’t think UON rolls off the tongue quite as nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Supports JSON Natively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python comes with a built-in package called json for encoding and decoding JSON data.\n",
    "\n",
    "Just throw this little guy up at the top of your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of encoding JSON is usually called serialization. This term refers to the transformation of data into a series of bytes (hence serial) to be stored or transmitted across a network. You may also hear the term marshaling, but that’s a whole other discussion. Naturally, deserialization is the reciprocal process of decoding data that has been stored or delivered in the JSON standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! That sounds pretty technical. Definitely. But in reality, all we’re talking about here is reading and writing. Think of it like this: encoding is for writing data to disk, while decoding is for reading data into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens after a computer processes lots of information? It needs to take a data dump. Accordingly, the json library exposes the dump() method for writing data to files. There is also a dumps() method (pronounced as “dump-s”) for writing to a Python string.\n",
    "\n",
    "Simple Python objects are translated to JSON according to a fairly intuitive conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"table-responsive\">\n",
    "<table class=\"table table-hover\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Python</th>\n",
    "<th>JSON</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><code>dict</code></td>\n",
    "<td><code>object</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>list</code>, <code>tuple</code></td>\n",
    "<td><code>array</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>str</code></td>\n",
    "<td><code>string</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>int</code>, <code>long</code>, <code>float</code></td>\n",
    "<td><code>number</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>True</code></td>\n",
    "<td><code>true</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>False</code></td>\n",
    "<td><code>false</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>None</code></td>\n",
    "<td><code>null</code></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you’re working with a Python object in memory that looks a little something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"president\": {\n",
    "        \"name\": \"Zaphod Beeblebrox\",\n",
    "        \"species\": \"Betelgeusian\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is critical that you save this information to disk, so your mission is to write it to a file.\n",
    "\n",
    "Using Python’s context manager, you can create a file called data_file.json and open it in write mode. (JSON files conveniently end in a .json extension.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/data_file.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that dump() takes two positional arguments: (1) the data object to be serialized, and (2) the file-like object to which the bytes will be written.\n",
    "\n",
    "Or, if you were so inclined as to continue using this serialized JSON data in your program, you could write it to a native Python str object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"president\": {\"name\": \"Zaphod Beeblebrox\", \"species\": \"Betelgeusian\"}}\n"
     ]
    }
   ],
   "source": [
    "json_string = json.dumps(data)\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the file-like object is absent since you aren’t actually writing to disk. Other than that, dumps() is just like dump()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserializing JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, looks like you’ve captured yourself some wild JSON! Now it’s time to whip it into shape. In the json library, you’ll find load() and loads() for turning JSON encoded data into Python objects.\n",
    "\n",
    "Just like serialization, there is a simple conversion table for deserialization, though you can probably guess what it looks like already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"table-responsive\">\n",
    "<table class=\"table table-hover\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>JSON</th>\n",
    "<th>Python</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><code>object</code></td>\n",
    "<td><code>dict</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>array</code></td>\n",
    "<td><code>list</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>string</code></td>\n",
    "<td><code>str</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>number</code> (int)</td>\n",
    "<td><code>int</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>number</code> (real)</td>\n",
    "<td><code>float</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>true</code></td>\n",
    "<td><code>True</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>false</code></td>\n",
    "<td><code>False</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>null</code></td>\n",
    "<td><code>None</code></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, this conversion isn’t a perfect inverse to the serialization table. That basically means that if you encode an object now and then decode it again later, you may not get exactly the same object back. I imagine it’s a bit like teleportation: break my molecules down over here and put them back together over there. Am I still the same person?\n",
    "\n",
    "In reality, it’s probably more like getting one friend to translate something into Japanese and another friend to translate it back into English. Regardless, the simplest example would be encoding a tuple and getting back a list after decoding, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackjack_hand = (8, \"Q\")\n",
    "encoded_hand = json.dumps(blackjack_hand)\n",
    "decoded_hand = json.loads(encoded_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackjack_hand == decoded_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blackjack_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(decoded_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackjack_hand == tuple(decoded_hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, imagine you’ve got some data stored on disk that you’d like to manipulate in memory. You’ll still use the context manager, but this time you’ll open up the existing data_file.json in read mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/data_file.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'president': {'name': 'Zaphod Beeblebrox', 'species': 'Betelgeusian'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are pretty straightforward here, but keep in mind that the result of this method could return any of the allowed data types from the conversion table. This is only important if you’re loading in data you haven’t seen before. In most cases, the root object will be a dict or a list.\n",
    "\n",
    "If you’ve pulled JSON data in from another program or have otherwise obtained a string of JSON formatted data in Python, you can easily deserialize that with loads(), which naturally loads from a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = \"\"\"\n",
    "{\n",
    "    \"researcher\": {\n",
    "        \"name\": \"Ford Prefect\",\n",
    "        \"species\": \"Betelgeusian\",\n",
    "        \"relatives\": [\n",
    "            {\n",
    "                \"name\": \"Zaphod Beeblebrox\",\n",
    "                \"species\": \"Betelgeusian\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "data = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'researcher': {'name': 'Ford Prefect',\n",
       "  'species': 'Betelgeusian',\n",
       "  'relatives': [{'name': 'Zaphod Beeblebrox', 'species': 'Betelgeusian'}]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaja: parsing JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: using data file 'interface-data.json', create output that resembles the following by parsing the included JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Interface Status\n",
    "    ================================================================================\n",
    "    DN                                                 Description           Speed    MTU  \n",
    "    -------------------------------------------------- --------------------  ------  ------\n",
    "    topology/pod-1/node-201/sys/phys-[eth1/33]                              inherit   9150 \n",
    "    topology/pod-1/node-201/sys/phys-[eth1/34]                              inherit   9150 \n",
    "    topology/pod-1/node-201/sys/phys-[eth1/35]                              inherit   9150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = \"\"\"================================================================\\n\n",
    "DN                                                  Speed    MTU\\n \n",
    "--------------------------------------------------  ------  ------\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/exer1-interface-data.json') as f:\n",
    "    #jsondata = f.read()\n",
    "    json_object = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdata = json_object[\"imdata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/interface_output.txt', 'w') as f:\n",
    "    f.write(head)\n",
    "    #print(head)\n",
    "    for interface in imdata:\n",
    "        attributes = interface[\"l1PhysIf\"][\"attributes\"]\n",
    "        dn = attributes[\"dn\"]\n",
    "        speed = attributes[\"speed\"]\n",
    "        mtu = attributes[\"mtu\"]\n",
    "        data_string = f\"{dn:50} {speed:8} {mtu:7}\\n\"\n",
    "        #print(data_string)\n",
    "        f.write(data_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing JSON Files With the pandas Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Primeri datasetov](https://github.com/jdorfman/awesome-json-datasets#bitcoin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a JSON string to pandas object can take a number of parameters. The parser will try to parse a DataFrame if typ is not supplied or is None. To explicitly force Series parsing, pass typ=series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pd.read_json(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dtype : if True, infer dtypes, if a dict of column to dtype, then use those, if False, then don’t infer dtypes at all, default is True, apply only to the data.\n",
    "- convert_axes : boolean, try to convert the axes to the proper dtypes, default is True\n",
    "- convert_dates : a list of columns to parse for dates; If True, then try to parse date-like columns, default is True.\n",
    "- keep_default_dates : boolean, default True. If parsing dates, then parse the default date-like columns.\n",
    "- numpy : direct decoding to NumPy arrays. default is False; Supports numeric data only, although labels may be non-numeric. Also note that the JSON ordering MUST be the same for each term if numpy=True.\n",
    "- precise_float : boolean, default False. Set to enable usage of higher precision (strtod) function when decoding string to double values. Default (False) is to use fast but less precise builtin functionality.\n",
    "- date_unit : string, the timestamp unit to detect if converting dates. Default None. By default the timestamp precision will be detected, if this is not desired then pass one of ‘s’, ‘ms’, ‘us’ or ‘ns’ to force timestamp precision to seconds, milliseconds, microseconds or nanoseconds respectively.\n",
    "- lines : reads file as one json object per line. \n",
    "- encoding : The encoding to use to decode py3 bytes.\n",
    "- chunksize : when used in combination with lines=True, return a JsonReader which reads in chunksize lines per iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orient options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`orient` :\n",
    "- Series:\n",
    "    - default is index\n",
    "    - allowed values are {split, records, index}\n",
    "- DataFrame:\n",
    "    - default is columns\n",
    "    - allowed values are {split, records, index, columns, values, table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjo = pd.DataFrame(dict(A=range(1, 4), B=range(4, 7), C=range(7, 10)), columns=list('ABC'), index=list('xyz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "x  1  4  7\n",
       "y  2  5  8\n",
       "z  3  6  9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the JSON string:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"colwidths-given table\">\n",
    "<colgroup>\n",
    "<col style=\"width: 12%\">\n",
    "<col style=\"width: 88%\">\n",
    "</colgroup>\n",
    "<tbody>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">split</span></code></p></td>\n",
    "<td><p>dict like {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">records</span></code></p></td>\n",
    "<td><p>list like [{column -&gt; value}, … , {column -&gt; value}]</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">index</span></code></p></td>\n",
    "<td><p>dict like {index -&gt; {column -&gt; value}}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">columns</span></code></p></td>\n",
    "<td><p>dict like {column -&gt; {index -&gt; value}}</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">values</span></code></p></td>\n",
    "<td><p>just the values array</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">table</span></code></p></td>\n",
    "<td><p>adhering to the JSON <a class=\"reference external\" href=\"https://specs.frictionlessdata.io/json-table-schema/\">Table Schema</a></p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Column oriented (the default for DataFrame) serializes the data as nested JSON objects with column labels acting as the primary index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"A\":{\"x\":1,\"y\":2,\"z\":3},\"B\":{\"x\":4,\"y\":5,\"z\":6},\"C\":{\"x\":7,\"y\":8,\"z\":9}}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo.to_json(orient=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Index oriented (the default for Series) similar to column oriented but the index labels are now primary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"x\":{\"A\":1,\"B\":4,\"C\":7},\"y\":{\"A\":2,\"B\":5,\"C\":8},\"z\":{\"A\":3,\"B\":6,\"C\":9}}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo.to_json(orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Record oriented serializes the data to a JSON array of column -> value records, index labels are not included. This is useful for passing DataFrame data to plotting libraries, for example the JavaScript library d3.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"A\":1,\"B\":4,\"C\":7},{\"A\":2,\"B\":5,\"C\":8},{\"A\":3,\"B\":6,\"C\":9}]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Value oriented is a bare-bones option which serializes to nested JSON arrays of values only, column and index labels are not included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[1,4,7],[2,5,8],[3,6,9]]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo.to_json(orient=\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split oriented serializes to a JSON object containing separate entries for values, index and columns. Name is also included for Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"columns\":[\"A\",\"B\",\"C\"],\"index\":[\"x\",\"y\",\"z\"],\"data\":[[1,4,7],[2,5,8],[3,6,9]]}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Table oriented serializes to the JSON Table Schema, allowing for the preservation of metadata including but not limited to dtypes and index names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"schema\":{\"fields\":[{\"name\":\"index\",\"type\":\"string\"},{\"name\":\"A\",\"type\":\"integer\"},{\"name\":\"B\",\"type\":\"integer\"},{\"name\":\"C\",\"type\":\"integer\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"0.20.0\"},\"data\":[{\"index\":\"x\",\"A\":1,\"B\":4,\"C\":7},{\"index\":\"y\",\"A\":2,\"B\":5,\"C\":8},{\"index\":\"z\",\"A\":3,\"B\":6,\"C\":9}]}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjo.to_json(orient=\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer: ocenas.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_anomaly_celsius</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      temp_anomaly_celsius\n",
       "year                      \n",
       "1880                 -0.12\n",
       "1881                 -0.09\n",
       "1882                 -0.10\n",
       "1883                 -0.18\n",
       "1884                 -0.27"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# način 1\n",
    "ocenas = pd.read_json('data/ocenas.json', orient='column')\n",
    "ocenas.drop(columns='description', inplace=True)\n",
    "ocenas.drop(['title', 'units', 'base_period', 'missing'], inplace=True)\n",
    "ocenas.index.name = 'year'\n",
    "ocenas.rename(columns={'data':'temp_anomaly_celsius'}, inplace=True)\n",
    "ocenas.index = pd.to_datetime(ocenas.index).year\n",
    "ocenas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer: temperatures.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat ./data/temperatures.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#load json object\n",
    "with open('data/temperatures.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podatke pretvorimo v json v pomnilniku\n",
    "temps_json = json.dumps(d['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189512</th>\n",
       "      <td>50.34</td>\n",
       "      <td>-1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189612</th>\n",
       "      <td>51.99</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189712</th>\n",
       "      <td>51.56</td>\n",
       "      <td>-0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189812</th>\n",
       "      <td>51.43</td>\n",
       "      <td>-0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189912</th>\n",
       "      <td>51.01</td>\n",
       "      <td>-1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        value  anomaly\n",
       "189512  50.34    -1.68\n",
       "189612  51.99    -0.03\n",
       "189712  51.56    -0.46\n",
       "189812  51.43    -0.59\n",
       "189912  51.01    -1.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temps = pd.read_json(temps_json, orient='index')\n",
    "temps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer: cities.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>:@computed_region_cbhk_fwbd</th>\n",
       "      <th>:@computed_region_nnqa_25f4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880-01-01T00:00:00.000</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [6.08333, 50....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951-01-01T00:00:00.000</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [10.23333, 56...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  id nametype recclass   mass  fall                     year  \\\n",
       "0  Aachen   1    Valid       L5   21.0  Fell  1880-01-01T00:00:00.000   \n",
       "1  Aarhus   2    Valid       H6  720.0  Fell  1951-01-01T00:00:00.000   \n",
       "\n",
       "     reclat   reclong                                        geolocation  \\\n",
       "0  50.77500   6.08333  {'type': 'Point', 'coordinates': [6.08333, 50....   \n",
       "1  56.18333  10.23333  {'type': 'Point', 'coordinates': [10.23333, 56...   \n",
       "\n",
       "   :@computed_region_cbhk_fwbd  :@computed_region_nnqa_25f4  \n",
       "0                          NaN                          NaN  \n",
       "1                          NaN                          NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lahko prodamo amapk ne moremo dobit geolokacije vn\n",
    "cities = pd.read_json('data/cities.json', orient='records')\n",
    "cities.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cities.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-26b1da13a1e9>:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  cities = json_normalize(d)\n"
     ]
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "cities = json_normalize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>geolocation.type</th>\n",
       "      <th>coordinates_x</th>\n",
       "      <th>coordinates_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aachen</th>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1880-01-01T00:00:00.000</td>\n",
       "      <td>50.775000</td>\n",
       "      <td>6.083330</td>\n",
       "      <td>Point</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>50.77500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aarhus</th>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1951-01-01T00:00:00.000</td>\n",
       "      <td>56.183330</td>\n",
       "      <td>10.233330</td>\n",
       "      <td>Point</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>56.18333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abee</th>\n",
       "      <td>6</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1952-01-01T00:00:00.000</td>\n",
       "      <td>54.216670</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>Point</td>\n",
       "      <td>-113.00000</td>\n",
       "      <td>54.21667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acapulco</th>\n",
       "      <td>10</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1976-01-01T00:00:00.000</td>\n",
       "      <td>16.883330</td>\n",
       "      <td>-99.900000</td>\n",
       "      <td>Point</td>\n",
       "      <td>-99.90000</td>\n",
       "      <td>16.88333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Achiras</th>\n",
       "      <td>370</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>1902-01-01T00:00:00.000</td>\n",
       "      <td>-33.166670</td>\n",
       "      <td>-64.950000</td>\n",
       "      <td>Point</td>\n",
       "      <td>-64.95000</td>\n",
       "      <td>-33.16667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id nametype     recclass      mass  fall                     year  \\\n",
       "name                                                                           \n",
       "Aachen      1    Valid           L5      21.0  Fell  1880-01-01T00:00:00.000   \n",
       "Aarhus      2    Valid           H6     720.0  Fell  1951-01-01T00:00:00.000   \n",
       "Abee        6    Valid          EH4  107000.0  Fell  1952-01-01T00:00:00.000   \n",
       "Acapulco   10    Valid  Acapulcoite    1914.0  Fell  1976-01-01T00:00:00.000   \n",
       "Achiras   370    Valid           L6     780.0  Fell  1902-01-01T00:00:00.000   \n",
       "\n",
       "              reclat      reclong geolocation.type  coordinates_x  \\\n",
       "name                                                                \n",
       "Aachen     50.775000     6.083330            Point        6.08333   \n",
       "Aarhus     56.183330    10.233330            Point       10.23333   \n",
       "Abee       54.216670  -113.000000            Point     -113.00000   \n",
       "Acapulco   16.883330   -99.900000            Point      -99.90000   \n",
       "Achiras   -33.166670   -64.950000            Point      -64.95000   \n",
       "\n",
       "          coordinates_y  \n",
       "name                     \n",
       "Aachen         50.77500  \n",
       "Aarhus         56.18333  \n",
       "Abee           54.21667  \n",
       "Acapulco       16.88333  \n",
       "Achiras       -33.16667  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['coordinates_x'] = cities['geolocation.coordinates'].str[0]\n",
    "cities['coordinates_y'] = cities['geolocation.coordinates'].str[1]\n",
    "cities.drop(columns=['geolocation.coordinates', ':@computed_region_cbhk_fwbd', ':@computed_region_nnqa_25f4'], inplace=True)\n",
    "cities.set_index('name', inplace=True)\n",
    "cities['mass'] = pd.to_numeric(cities['mass'])\n",
    "# na podoben način še ostale\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer: transactions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"txs\":[\r\n",
      "\r\n",
      "{\r\n",
      "   \"lock_time\":0,\r\n",
      "   \"ver\":1,\r\n",
      "   \"size\":373,\r\n",
      "   \"inputs\":[\r\n",
      "      {\r\n",
      "         \"sequence\":4294967295,\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/transactions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/transactions.json') as f:\n",
    "    data= json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas.json_normalize](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html): Normalize semi-structured JSON data into a flat table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "#json_normalize(data['txs']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-37877734e905>:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  trans = json_normalize(data['txs'], record_path=['out'], meta=['time', 'relayed_by', 'vout_sz', 'hash'])\n"
     ]
    }
   ],
   "source": [
    "trans = json_normalize(data['txs'], record_path=['out'], meta=['time', 'relayed_by', 'vout_sz', 'hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spent</th>\n",
       "      <th>tx_index</th>\n",
       "      <th>type</th>\n",
       "      <th>addr</th>\n",
       "      <th>value</th>\n",
       "      <th>n</th>\n",
       "      <th>script</th>\n",
       "      <th>time</th>\n",
       "      <th>relayed_by</th>\n",
       "      <th>vout_sz</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1H7r57SXAwaKs3Tf5ugbkRNxwfh9YaxC5b</td>\n",
       "      <td>7541</td>\n",
       "      <td>0</td>\n",
       "      <td>76a914b0cd787a7a879ac0a5277b0013ec7b11c145055d...</td>\n",
       "      <td>1586376721</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0f06714015f334626a168ee3e0aa5e0d3866a33dad504b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1BPULhbGfrojrknyD7aZYMtRVUu38Cn75j</td>\n",
       "      <td>1364400</td>\n",
       "      <td>1</td>\n",
       "      <td>76a91471f13b222426eb80b47d2413d21a8904ec1966b2...</td>\n",
       "      <td>1586376721</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0f06714015f334626a168ee3e0aa5e0d3866a33dad504b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1LQ6YURobx4EGZRp8bdEDHup6T56o5NGKN</td>\n",
       "      <td>3127836</td>\n",
       "      <td>0</td>\n",
       "      <td>76a914d4c895721d3a8cd74bb3ccbb699a3dbe342c0807...</td>\n",
       "      <td>1586376722</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3684072a50d7389933210d7adf4f98640d3d53c8cb245e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1HSLVVSSQmzaNG8sbakhFDrmpzUPZLnYCe</td>\n",
       "      <td>30036732</td>\n",
       "      <td>1</td>\n",
       "      <td>76a914b44cae99837337275d21d2c5c6ed6cddf7a7e9f7...</td>\n",
       "      <td>1586376722</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3684072a50d7389933210d7adf4f98640d3d53c8cb245e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3Lb2MJWbBE88BUHf6tAw8ZzhkR6H2cYRhR</td>\n",
       "      <td>206183</td>\n",
       "      <td>0</td>\n",
       "      <td>a914cf48401e3cf81080352f281ea859ccabd51a821487</td>\n",
       "      <td>1586376721</td>\n",
       "      <td>0.0.0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3d3cc141654170060a7e298a9e5298557970e8cd0051ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spent  tx_index  type                                addr     value  n  \\\n",
       "0  False         0     0  1H7r57SXAwaKs3Tf5ugbkRNxwfh9YaxC5b      7541  0   \n",
       "1  False         0     0  1BPULhbGfrojrknyD7aZYMtRVUu38Cn75j   1364400  1   \n",
       "2  False         0     0  1LQ6YURobx4EGZRp8bdEDHup6T56o5NGKN   3127836  0   \n",
       "3  False         0     0  1HSLVVSSQmzaNG8sbakhFDrmpzUPZLnYCe  30036732  1   \n",
       "4  False         0     0  3Lb2MJWbBE88BUHf6tAw8ZzhkR6H2cYRhR    206183  0   \n",
       "\n",
       "                                              script        time relayed_by  \\\n",
       "0  76a914b0cd787a7a879ac0a5277b0013ec7b11c145055d...  1586376721    0.0.0.0   \n",
       "1  76a91471f13b222426eb80b47d2413d21a8904ec1966b2...  1586376721    0.0.0.0   \n",
       "2  76a914d4c895721d3a8cd74bb3ccbb699a3dbe342c0807...  1586376722    0.0.0.0   \n",
       "3  76a914b44cae99837337275d21d2c5c6ed6cddf7a7e9f7...  1586376722    0.0.0.0   \n",
       "4     a914cf48401e3cf81080352f281ea859ccabd51a821487  1586376721    0.0.0.0   \n",
       "\n",
       "  vout_sz                                               hash  \n",
       "0       2  0f06714015f334626a168ee3e0aa5e0d3866a33dad504b...  \n",
       "1       2  0f06714015f334626a168ee3e0aa5e0d3866a33dad504b...  \n",
       "2       2  3684072a50d7389933210d7adf4f98640d3d53c8cb245e...  \n",
       "3       2  3684072a50d7389933210d7adf4f98640d3d53c8cb245e...  \n",
       "4       3  3d3cc141654170060a7e298a9e5298557970e8cd0051ab...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer: all_hour_geo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json object\n",
    "with open('data/all_hour_geo.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [element['properties'] for element in  d['features']]\n",
    "all_hour_geo = json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>place</th>\n",
       "      <th>time</th>\n",
       "      <th>updated</th>\n",
       "      <th>tz</th>\n",
       "      <th>url</th>\n",
       "      <th>detail</th>\n",
       "      <th>felt</th>\n",
       "      <th>cdi</th>\n",
       "      <th>mmi</th>\n",
       "      <th>...</th>\n",
       "      <th>ids</th>\n",
       "      <th>sources</th>\n",
       "      <th>types</th>\n",
       "      <th>nst</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>gap</th>\n",
       "      <th>magType</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69</td>\n",
       "      <td>16km ESE of Anza, CA</td>\n",
       "      <td>1586352802900</td>\n",
       "      <td>1586353032308</td>\n",
       "      <td>-480</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/feed/v...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>,ci39143639,</td>\n",
       "      <td>,ci,</td>\n",
       "      <td>,geoserve,nearby-cities,origin,phase-data,scit...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.05468</td>\n",
       "      <td>0.14</td>\n",
       "      <td>98.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 0.7 - 16km ESE of Anza, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.34</td>\n",
       "      <td>7km ENE of Pahala, Hawaii</td>\n",
       "      <td>1586352794640</td>\n",
       "      <td>1586353127910</td>\n",
       "      <td>-600</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/feed/v...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>,hv71464377,</td>\n",
       "      <td>,hv,</td>\n",
       "      <td>,geoserve,origin,phase-data,</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.02127</td>\n",
       "      <td>0.13</td>\n",
       "      <td>136.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 2.3 - 7km ENE of Pahala, Hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.85</td>\n",
       "      <td>15km ESE of Anza, CA</td>\n",
       "      <td>1586352704490</td>\n",
       "      <td>1586352926133</td>\n",
       "      <td>-480</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/eventp...</td>\n",
       "      <td>https://earthquake.usgs.gov/earthquakes/feed/v...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>,ci39143631,</td>\n",
       "      <td>,ci,</td>\n",
       "      <td>,geoserve,nearby-cities,origin,phase-data,scit...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.04884</td>\n",
       "      <td>0.14</td>\n",
       "      <td>55.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>M 0.9 - 15km ESE of Anza, CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mag                      place           time        updated   tz  \\\n",
       "0  0.69       16km ESE of Anza, CA  1586352802900  1586353032308 -480   \n",
       "1  2.34  7km ENE of Pahala, Hawaii  1586352794640  1586353127910 -600   \n",
       "2  0.85       15km ESE of Anza, CA  1586352704490  1586352926133 -480   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
       "1  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
       "2  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
       "\n",
       "                                              detail  felt   cdi   mmi  ...  \\\n",
       "0  https://earthquake.usgs.gov/earthquakes/feed/v...  None  None  None  ...   \n",
       "1  https://earthquake.usgs.gov/earthquakes/feed/v...  None  None  None  ...   \n",
       "2  https://earthquake.usgs.gov/earthquakes/feed/v...  None  None  None  ...   \n",
       "\n",
       "            ids sources                                              types  \\\n",
       "0  ,ci39143639,    ,ci,  ,geoserve,nearby-cities,origin,phase-data,scit...   \n",
       "1  ,hv71464377,    ,hv,                       ,geoserve,origin,phase-data,   \n",
       "2  ,ci39143631,    ,ci,  ,geoserve,nearby-cities,origin,phase-data,scit...   \n",
       "\n",
       "    nst     dmin   rms    gap magType        type  \\\n",
       "0  12.0  0.05468  0.14   98.0      ml  earthquake   \n",
       "1  49.0  0.02127  0.13  136.0      ml  earthquake   \n",
       "2  30.0  0.04884  0.14   55.0      ml  earthquake   \n",
       "\n",
       "                               title  \n",
       "0       M 0.7 - 16km ESE of Anza, CA  \n",
       "1  M 2.3 - 7km ENE of Pahala, Hawaii  \n",
       "2       M 0.9 - 15km ESE of Anza, CA  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hour_geo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer: rates.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json object\n",
    "with open('data/rates.json') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_normalize(d['rates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effective_from</th>\n",
       "      <th>rates.super_reduced</th>\n",
       "      <th>rates.reduced</th>\n",
       "      <th>rates.standard</th>\n",
       "      <th>rates.reduced1</th>\n",
       "      <th>rates.reduced2</th>\n",
       "      <th>rates.parking</th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ES</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>BG</td>\n",
       "      <td>BG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>HU</td>\n",
       "      <td>HU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>LV</td>\n",
       "      <td>LV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poland</td>\n",
       "      <td>PL</td>\n",
       "      <td>PL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  effective_from  rates.super_reduced  rates.reduced  rates.standard  \\\n",
       "0     0000-01-01                  4.0           10.0            21.0   \n",
       "1     0000-01-01                  NaN            9.0            20.0   \n",
       "2     0000-01-01                  NaN            NaN            27.0   \n",
       "3     0000-01-01                  NaN           12.0            21.0   \n",
       "4     0000-01-01                  NaN            NaN            23.0   \n",
       "\n",
       "   rates.reduced1  rates.reduced2  rates.parking      name code country_code  \n",
       "0             NaN             NaN            NaN     Spain   ES           ES  \n",
       "1             NaN             NaN            NaN  Bulgaria   BG           BG  \n",
       "2             5.0            18.0            NaN   Hungary   HU           HU  \n",
       "3             NaN             NaN            NaN    Latvia   LV           LV  \n",
       "4             5.0             8.0            NaN    Poland   PL           PL  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates = json_normalize(d['rates'], record_path=['periods'], meta=['name', 'code', 'country_code'])\n",
    "rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branje in pisanje CSV datotek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s face it: you need to get information into and out of your programs through more than just the keyboard and console. Exchanging information through text files is a common way to share info between programs. One of the most popular formats for exchanging data is the CSV format. But how do you use it?\n",
    "\n",
    "Let’s get one thing clear: you don’t have to (and you won’t) build your own CSV parser from scratch. There are several perfectly acceptable libraries you can use. The Python csv library will work for most cases. If your work requires lots of data or numerical analysis, the pandas library has CSV parsing capabilities as well, which should handle the rest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is a CSV File?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CSV file (Comma Separated Values file) is a type of plain text file that uses specific structuring to arrange tabular data. Because it’s a plain text file, it can contain only actual text data—in other words, printable ASCII or Unicode characters.\n",
    "\n",
    "The structure of a CSV file is given away by its name. Normally, CSV files use a comma to separate each specific data value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each piece of data is separated by a comma. Normally, the first line identifies each piece of data—in other words, the name of a data column. Every subsequent line after that is actual data and is limited only by file size constraints.\n",
    "\n",
    "In general, the separator character is called a delimiter, and the comma is not the only one used. Other popular delimiters include the tab (\\t), colon (:) and semi-colon (;) characters. Properly parsing a CSV file requires us to know which delimiter is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files are normally created by programs that handle large amounts of data. They are a convenient way to export data from spreadsheets and databases as well as import or use it in other programs. For example, you might export the results of a data mining program to a CSV file and then import that into a spreadsheet to analyze the data, generate graphs for a presentation, or prepare a report for publication.\n",
    "\n",
    "CSV files are very easy to work with programmatically. Any language that supports text file input and string manipulation (like Python) can work with CSV files directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing CSV Files With Python’s Built-in CSV Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv library provides functionality to both read from and write to CSV files. Designed to work out of the box with Excel-generated CSV files, it is easily adapted to work with a variety of CSV formats. The csv library contains objects and other code to read, write, and process data from and to CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading CSV Files With csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a CSV file is done using the reader object. The CSV file is opened as a text file with Python’s built-in open() function, which returns a file object. This is then passed to the reader, which does the heavy lifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s code to read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, department, birthday month\n",
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 3 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/employee_birthday.txt') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row returned by the reader is a list of String elements containing the data found by removing the delimiters. The first row returned contains the column names, which is handled in a special way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing CSV Files With csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also write to a CSV file using a writer object and the .write_row() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/employee_file1.csv', mode='w') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',')\n",
    "\n",
    "    employee_writer.writerow(['John Smith', 'Accounting', 'November'])\n",
    "    employee_writer.writerow(['Erica Meyers', 'IT', 'March'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing CSV Files With the pandas Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the Python CSV library isn’t the only game in town. Reading CSV files is possible in pandas as well. It is highly recommended if you have a lot of data to analyze.\n",
    "\n",
    "pandas is an open-source Python library that provides high performance data analysis tools and easy to use data structures. pandas is available for all Python installations, but it is a key part of the Anaconda distribution and works extremely well in Jupyter notebooks to share data, code, analysis results, visualizations, and narrative text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the CSV into a pandas DataFrame is quick and straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Sick Days remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graham Chapman</td>\n",
       "      <td>03/15/14</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Cleese</td>\n",
       "      <td>06/01/15</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eric Idle</td>\n",
       "      <td>05/12/14</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terry Jones</td>\n",
       "      <td>11/01/13</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terry Gilliam</td>\n",
       "      <td>08/12/14</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael Palin</td>\n",
       "      <td>05/23/13</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Hire Date   Salary  Sick Days remaining\n",
       "0  Graham Chapman  03/15/14  50000.0                   10\n",
       "1     John Cleese  06/01/15  65000.0                    8\n",
       "2       Eric Idle  05/12/14  45000.0                   10\n",
       "3     Terry Jones  11/01/13  70000.0                    3\n",
       "4   Terry Gilliam  08/12/14  48000.0                    7\n",
       "5   Michael Palin  05/23/13  66000.0                    8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('data/hrdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s it: three lines of code, and only one of them is doing the actual work. pandas.read_csv() opens, analyzes, and reads the CSV file provided, and stores the data in a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrinting data to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/hrdata.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\":{\"Name\":\"Graham Chapman\",\"Hire Date\":\"03\\/15\\/14\",\"Salary\":50000.0,\"Sick Days remaining\":10},\"1\":{\"Name\":\"John Cleese\",\"Hire Date\":\"06\\/01\\/15\",\"Salary\":65000.0,\"Sick Days remaining\":8},\"2\":{\"Name\":\"Eric Idle\",\"Hire Date\":\"05\\/12\\/14\",\"Salary\":45000.0,\"Sick Days remaining\":10},\"3\":{\"Name\":\"Terry Jones\",\"Hire Date\":\"11\\/01\\/13\",\"Salary\":70000.0,\"Sick Days remaining\":3},\"4\":{\"Name\":\"Terry Gilliam\",\"Hire Date\":\"08\\/12\\/14\",\"Salary\":48000.0,\"Sick Days remaining\":7},\"5\":{\"Name\":\"Michael Palin\",\"Hire Date\":\"05\\/23\\/13\",\"Salary\":66000.0,\"Sick Days remaining\":8}}"
     ]
    }
   ],
   "source": [
    "! cat data/hrdata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 1: seaslug.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaslug = pd.read_csv('data/seaslug.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  Percent\n",
       "0    99    0.067\n",
       "1    99    0.133\n",
       "2    99    0.067\n",
       "3    99    0.000\n",
       "4    99    0.000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seaslug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sep: str, defaults to ',' for read_csv(), \\t for read_table()`: Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python’s builtin sniffer tool, csv.Sniffer. In addition, separators longer than 1 character and different from '\\s+' will be interpreted as regular expressions and will also force the use of the Python parsing engine. Note that regex delimiters are prone to ignoring quoted data. Regex example: '\\\\r\\\\t'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `delimiter: str, default None`: Alias for sep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 2: FOOD_DES.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding: `iso-8859-1`, separator: `^`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~01001~^~0100~^~Butter, salted~^~BUTTER,WITH SALT~^~~^~~^~Y~^~~^0^~~^6.38^4.27^8.79^3.87\r",
      "\r\n",
      "~01002~^~0100~^~Butter, whipped, with salt~^~BUTTER,WHIPPED,W/ SALT~^~~^~~^~Y~^~~^0^~~^6.38^^^\r",
      "\r\n",
      "~01003~^~0100~^~Butter oil, anhydrous~^~BUTTER OIL,ANHYDROUS~^~~^~~^~Y~^~~^0^~~^6.38^4.27^8.79^3.87\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 ./data/FOOD_DES.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turns out the file, instead of using commas to separate the fields, uses carets ^.\n",
    "- By some reason, USDA people thought separating strings with tildes ~ was a good idea. Thankfully, we can use the quotechar argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>100</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>BUTTER,WITH SALT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>100</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>BUTTER,WHIPPED,W/ SALT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>100</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>BUTTER OIL,ANHYDROUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>100</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>CHEESE,BLUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>100</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>CHEESE,BRICK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1                           2                       3   4   5  6   \\\n",
       "0  1001  100              Butter, salted        BUTTER,WITH SALT NaN NaN  Y   \n",
       "1  1002  100  Butter, whipped, with salt  BUTTER,WHIPPED,W/ SALT NaN NaN  Y   \n",
       "2  1003  100       Butter oil, anhydrous    BUTTER OIL,ANHYDROUS NaN NaN  Y   \n",
       "3  1004  100                Cheese, blue             CHEESE,BLUE NaN NaN  Y   \n",
       "4  1005  100               Cheese, brick            CHEESE,BRICK NaN NaN  Y   \n",
       "\n",
       "   7   8   9     10    11    12    13  \n",
       "0 NaN   0 NaN  6.38  4.27  8.79  3.87  \n",
       "1 NaN   0 NaN  6.38   NaN   NaN   NaN  \n",
       "2 NaN   0 NaN  6.38  4.27  8.79  3.87  \n",
       "3 NaN   0 NaN  6.38  4.27  8.79  3.87  \n",
       "4 NaN   0 NaN  6.38  4.27  8.79  3.87  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/FOOD_DES.txt', sep='^', encoding='iso-8859-1', header=None, nrows=5, quotechar='~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `nrows: int, default None` Number of rows of file to read. Useful for reading pieces of large files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `header: int or list of ints, default 'infer'` Row number(s) to use as the column names, and the start of the data. Default behavior is to infer the column names: if no names are passed the behavior is identical to header=0 and column names are inferred from the first line of the file, if column names are passed explicitly then the behavior is identical to header=None. Explicitly pass header=0 to be able to replace existing names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encoding: str, default None` Encoding to use for UTF when reading/writing (e.g. 'utf-8'). [List of Python standard encodings](https://docs.python.org/3/library/codecs.html#standard-encodings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `quotechar: str (length 1)`: The character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 3: MplsStops.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0,id Num,date,problem,MDC,citation Issued,person Search,vehicle Search,pre Race,race,gender,lat,long,police Precinct,neighborhood\r\n",
      ",idNum,date,problem,MDC,citationIssued,personSearch,vehicleSearch,preRace,race,gender,lat,long,policePrecinct,neighborhood\r\n",
      "6823.0,17-000003,2017-01-01 00:00:42,suspicious,MDC,,NO,NO,Unknown,Unknown,Unknown,44.96661711,-93.24645826,1,Cedar Riverside\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 ./data/mpls_stops.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id Num</th>\n",
       "      <th>date</th>\n",
       "      <th>problem</th>\n",
       "      <th>MDC</th>\n",
       "      <th>citation Issued</th>\n",
       "      <th>person Search</th>\n",
       "      <th>vehicle Search</th>\n",
       "      <th>pre Race</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>police Precinct</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>idNum</td>\n",
       "      <td>date</td>\n",
       "      <td>problem</td>\n",
       "      <td>MDC</td>\n",
       "      <td>citationIssued</td>\n",
       "      <td>personSearch</td>\n",
       "      <td>vehicleSearch</td>\n",
       "      <td>preRace</td>\n",
       "      <td>race</td>\n",
       "      <td>gender</td>\n",
       "      <td>lat</td>\n",
       "      <td>long</td>\n",
       "      <td>policePrecinct</td>\n",
       "      <td>neighborhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6823.0</td>\n",
       "      <td>17-000003</td>\n",
       "      <td>2017-01-01 00:00:42</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>44.96661711</td>\n",
       "      <td>-93.24645826</td>\n",
       "      <td>1</td>\n",
       "      <td>Cedar Riverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6824.0</td>\n",
       "      <td>17-000007</td>\n",
       "      <td>2017-01-01 00:03:07</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.98045</td>\n",
       "      <td>-93.27134</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id Num                 date     problem  MDC  \\\n",
       "0         NaN      idNum                 date     problem  MDC   \n",
       "1      6823.0  17-000003  2017-01-01 00:00:42  suspicious  MDC   \n",
       "2      6824.0  17-000007  2017-01-01 00:03:07  suspicious  MDC   \n",
       "\n",
       "  citation Issued person Search vehicle Search pre Race     race   gender  \\\n",
       "0  citationIssued  personSearch  vehicleSearch  preRace     race   gender   \n",
       "1             NaN            NO             NO  Unknown  Unknown  Unknown   \n",
       "2             NaN            NO             NO  Unknown  Unknown     Male   \n",
       "\n",
       "           lat          long police Precinct     neighborhood  \n",
       "0          lat          long  policePrecinct     neighborhood  \n",
       "1  44.96661711  -93.24645826               1  Cedar Riverside  \n",
       "2     44.98045     -93.27134               1    Downtown West  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpls = pd.read_csv('data/mpls_stops.csv', nrows=3)\n",
    "mpls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id Num', 'date', 'problem', 'MDC', 'citation Issued',\n",
       "       'person Search', 'vehicle Search', 'pre Race', 'race', 'gender', 'lat',\n",
       "       'long', 'police Precinct', 'neighborhood'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpls.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = ['Unnamed: 0', 'id Num', 'date', 'problem', 'MDC', 'citation Issued',\n",
    "       'person Search', 'vehicle Search', 'pre Race', 'race', 'gender', 'lat',\n",
    "       'long', 'police Precinct', 'neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case_number_id', 'id_num', 'date', 'problem', 'mdc', 'citation_issued', 'person_search', 'vehicle_search', 'pre_race', 'race', 'gender', 'lat', 'long', 'police_precinct', 'neighborhood']\n"
     ]
    }
   ],
   "source": [
    "new_column_names = [name.lower().replace(' ', '_') for name in new_column_names]\n",
    "new_column_names[0] = 'case_number_id'\n",
    "print(new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>date</th>\n",
       "      <th>problem</th>\n",
       "      <th>mdc</th>\n",
       "      <th>citation_issued</th>\n",
       "      <th>person_search</th>\n",
       "      <th>vehicle_search</th>\n",
       "      <th>pre_race</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>police_precinct</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_number_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6823</th>\n",
       "      <td>17-000003</td>\n",
       "      <td>2017-01-01 00:00:42</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.966617</td>\n",
       "      <td>-93.246458</td>\n",
       "      <td>1</td>\n",
       "      <td>Cedar Riverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6824</th>\n",
       "      <td>17-000007</td>\n",
       "      <td>2017-01-01 00:03:07</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.980450</td>\n",
       "      <td>-93.271340</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6825</th>\n",
       "      <td>17-000073</td>\n",
       "      <td>2017-01-01 00:23:15</td>\n",
       "      <td>traffic</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.948350</td>\n",
       "      <td>-93.275380</td>\n",
       "      <td>5</td>\n",
       "      <td>Whittier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6826</th>\n",
       "      <td>17-000092</td>\n",
       "      <td>2017-01-01 00:33:48</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East African</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.948360</td>\n",
       "      <td>-93.281350</td>\n",
       "      <td>5</td>\n",
       "      <td>Whittier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6827</th>\n",
       "      <td>17-000098</td>\n",
       "      <td>2017-01-01 00:37:58</td>\n",
       "      <td>traffic</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.979078</td>\n",
       "      <td>-93.262076</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id_num                date     problem  mdc  \\\n",
       "case_number_id                                                   \n",
       "6823            17-000003 2017-01-01 00:00:42  suspicious  MDC   \n",
       "6824            17-000007 2017-01-01 00:03:07  suspicious  MDC   \n",
       "6825            17-000073 2017-01-01 00:23:15     traffic  MDC   \n",
       "6826            17-000092 2017-01-01 00:33:48  suspicious  MDC   \n",
       "6827            17-000098 2017-01-01 00:37:58     traffic  MDC   \n",
       "\n",
       "                citation_issued  person_search  vehicle_search pre_race  \\\n",
       "case_number_id                                                            \n",
       "6823                        1.0            0.0             0.0      NaN   \n",
       "6824                        1.0            0.0             0.0      NaN   \n",
       "6825                        1.0            0.0             0.0      NaN   \n",
       "6826                        1.0            0.0             0.0      NaN   \n",
       "6827                        1.0            0.0             0.0      NaN   \n",
       "\n",
       "                        race  gender        lat       long  police_precinct  \\\n",
       "case_number_id                                                                \n",
       "6823                     NaN     NaN  44.966617 -93.246458                1   \n",
       "6824                     NaN    Male  44.980450 -93.271340                1   \n",
       "6825                   White  Female  44.948350 -93.275380                5   \n",
       "6826            East African    Male  44.948360 -93.281350                5   \n",
       "6827                   White  Female  44.979078 -93.262076                1   \n",
       "\n",
       "                   neighborhood  \n",
       "case_number_id                   \n",
       "6823            Cedar Riverside  \n",
       "6824              Downtown West  \n",
       "6825                   Whittier  \n",
       "6826                   Whittier  \n",
       "6827              Downtown West  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpls = pd.read_csv('data/mpls_stops.csv', \n",
    "                   names=new_column_names, \n",
    "                   skiprows=2, \n",
    "                   engine='c',\n",
    "                   true_values=['YES'],\n",
    "                   false_values=['NO'],\n",
    "                   dtype={'mdc': 'category', 'problem':'category', 'citation_issued': 'float',\n",
    "                         'person_search': 'float', 'vehicle_search': 'float',  'pre_race':'category'},\n",
    "                   index_col='case_number_id',\n",
    "                   parse_dates=['date'],\n",
    "                   date_parser=dateparse,\n",
    "                   na_values=['Unknown'])\n",
    "\n",
    "mpls.index = mpls.index.astype('int')\n",
    "mpls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `names: array-like, default None` List of column names to use. If file contains no header row, then you should explicitly pass header=None. Duplicates in this list are not allowed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `skiprows: list-like or integer, default None` Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `engine: {'c', 'python'}` Parser engine to use. The C engine is faster while the Python engine is currently more feature-complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 ms ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mpls = pd.read_csv('data/mpls_stops.csv', names=new_column_names, skiprows=2, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 ms ± 3.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mpls = pd.read_csv('data/mpls_stops.csv', names=new_column_names, skiprows=2, engine='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `true_values: list, default None` Values to consider as True.\n",
    "- `false_values: list, default None` Values to consider as False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `index_col: int, str, sequence of int / str, or False, default None` Column(s) to use as the row labels of the DataFrame, either given as string name or column index. If a sequence of int / str is given, a MultiIndex is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dtype: Type name or dict of column -> type, default None` Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32} (unsupported with engine='python'). Use str or object together with suitable na_values settings to preserve and not interpret dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `parse_dates: boolean or list of ints or names or list of lists or dict, default False.` \n",
    "    - If True -> try parsing the index.\n",
    "    - If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
    "    - If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
    "    - If {'foo': [1, 3]} -> parse columns 1, 3 as date and call result ‘foo’. A fast-path exists for iso8601-formatted dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `date_parserfunction, default None` Function to use for converting a sequence of string columns to an array of datetime instances. The default uses dateutil.parser.parser to do the conversion. pandas will try to call date_parser in three different ways, advancing to the next if an exception occurs: 1) Pass one or more arrays (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string values from the columns defined by parse_dates into a single array and pass that; and 3) call date_parser once for each row using one or more strings (corresponding to the columns defined by parse_dates) as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `na_values: scalar, str, list-like, or dict, default None` Additional strings to recognize as NA/NaN. If dict passed, specific per-column NA values. See na values const below for a list of the values interpreted as NaN by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 4: iperf.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 15 19:35:11 CEST 2018\r\n",
      "Connecting to host x.x.x.x, port 5201\r\n",
      "[  4] local x.x.x.x port 48944 connected to x.x.x.x port 5201\r\n",
      "[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd\r\n",
      "[  4]   0.00-1.00   sec   375 MBytes  3.14 Gbits/sec  273    471 KBytes\r\n",
      "[  4]   1.00-2.00   sec   428 MBytes  3.59 Gbits/sec  145    376 KBytes\r\n",
      "[  4]   2.00-3.00   sec   360 MBytes  3.02 Gbits/sec  148    454 KBytes\r\n",
      "[  4]   3.00-4.00   sec   339 MBytes  2.84 Gbits/sec   83    407 KBytes\r\n",
      "[  4]   4.00-5.00   sec   305 MBytes  2.56 Gbits/sec  104    414 KBytes\r\n",
      "[  4]   5.00-6.00   sec   301 MBytes  2.53 Gbits/sec  186    440 KBytes\r\n"
     ]
    }
   ],
   "source": [
    "!head data/iperf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Želimo stolpce: \n",
    "- timestamp, transfer_mbytesec, bandwidth_gbitsec, retr, cwnd_kbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vidimo da ne gre\n",
    "#pd.read_csv('data/iperf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preberemo podatke v list\n",
    "with open('data/iperf.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = [line.strip() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wed Aug 15 19:35:11 CEST 2018', 'Connecting to host x.x.x.x, port 5201', '[  4] local x.x.x.x port 48944 connected to x.x.x.x port 5201', '[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd', '[  4]   0.00-1.00   sec   375 MBytes  3.14 Gbits/sec  273    471 KBytes', '[  4]   1.00-2.00   sec   428 MBytes  3.59 Gbits/sec  145    376 KBytes', '[  4]   2.00-3.00   sec   360 MBytes  3.02 Gbits/sec  148    454 KBytes', '[  4]   3.00-4.00   sec   339 MBytes  2.84 Gbits/sec   83    407 KBytes', '[  4]   4.00-5.00   sec   305 MBytes  2.56 Gbits/sec  104    414 KBytes', '[  4]   5.00-6.00   sec   301 MBytes  2.53 Gbits/sec  186    440 KBytes', '[  4]   6.00-7.00   sec   325 MBytes  2.73 Gbits/sec  174    485 KBytes', '[  4]   7.00-8.00   sec   434 MBytes  3.64 Gbits/sec   81    677 KBytes', '[  4]   8.00-9.00   sec   412 MBytes  3.46 Gbits/sec  226    537 KBytes', '[  4]   9.00-10.00  sec   409 MBytes  3.43 Gbits/sec   47    372 KBytes', '[  4]   10.00-11.00  sec   523 MBytes  3.81 Gbits/sec   96    422 KBytes']\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-15 19:35:11 <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "# izluščimo začetni čas -> tabela https://www.journaldev.com/23365/python-string-to-datetime-strptime\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.strptime(data[0], '%a %b %d %H:%M:%S CEST %Y')\n",
    "print(start_time, type(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.datetime(2018, 8, 15, 19, 35, 11), 375, 3.14, 273, 471), (datetime.datetime(2018, 8, 15, 19, 35, 12), 428, 3.59, 145, 376), (datetime.datetime(2018, 8, 15, 19, 35, 13), 360, 3.02, 148, 454), (datetime.datetime(2018, 8, 15, 19, 35, 14), 339, 2.84, 83, 407), (datetime.datetime(2018, 8, 15, 19, 35, 15), 305, 2.56, 104, 414), (datetime.datetime(2018, 8, 15, 19, 35, 16), 301, 2.53, 186, 440), (datetime.datetime(2018, 8, 15, 19, 35, 17), 325, 2.73, 174, 485), (datetime.datetime(2018, 8, 15, 19, 35, 18), 434, 3.64, 81, 677), (datetime.datetime(2018, 8, 15, 19, 35, 19), 412, 3.46, 226, 537), (datetime.datetime(2018, 8, 15, 19, 35, 20), 409, 3.43, 47, 372), (datetime.datetime(2018, 8, 15, 19, 35, 21), 523, 3.81, 96, 422)]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for line in data[4:]:\n",
    "    line_splited = line.split()\n",
    "    # seconds to add to start time\n",
    "    add_seconds = int(line_splited[2].split('.')[0])\n",
    "    timestamp = start_time + datetime.timedelta(seconds=add_seconds)\n",
    "    transfer_mbytesec = int(line_splited[4])\n",
    "    bandwidth_gbitsec = float(line_splited[6])\n",
    "    retr = int(line_splited[8])\n",
    "    cwnd_kbytes = int(line_splited[9])\n",
    "    rows.append((timestamp, transfer_mbytesec, bandwidth_gbitsec, retr, cwnd_kbytes))\n",
    "    \n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podatke vpišemo v novo datoteko\n",
    "import csv\n",
    "\n",
    "headers = ['timestamp', 'transfer_mbytesec', 'bandwidth_gbitsec', 'retr', 'cwnd_kbytes']\n",
    "\n",
    "with open('data/iperf_clean.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transfer_mbytesec</th>\n",
       "      <th>bandwidth_gbitsec</th>\n",
       "      <th>retr</th>\n",
       "      <th>cwnd_kbytes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:11</th>\n",
       "      <td>375</td>\n",
       "      <td>3.14</td>\n",
       "      <td>273</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:12</th>\n",
       "      <td>428</td>\n",
       "      <td>3.59</td>\n",
       "      <td>145</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:13</th>\n",
       "      <td>360</td>\n",
       "      <td>3.02</td>\n",
       "      <td>148</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:14</th>\n",
       "      <td>339</td>\n",
       "      <td>2.84</td>\n",
       "      <td>83</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:15</th>\n",
       "      <td>305</td>\n",
       "      <td>2.56</td>\n",
       "      <td>104</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:16</th>\n",
       "      <td>301</td>\n",
       "      <td>2.53</td>\n",
       "      <td>186</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:17</th>\n",
       "      <td>325</td>\n",
       "      <td>2.73</td>\n",
       "      <td>174</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:18</th>\n",
       "      <td>434</td>\n",
       "      <td>3.64</td>\n",
       "      <td>81</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:19</th>\n",
       "      <td>412</td>\n",
       "      <td>3.46</td>\n",
       "      <td>226</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:20</th>\n",
       "      <td>409</td>\n",
       "      <td>3.43</td>\n",
       "      <td>47</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:21</th>\n",
       "      <td>523</td>\n",
       "      <td>3.81</td>\n",
       "      <td>96</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     transfer_mbytesec  bandwidth_gbitsec  retr  cwnd_kbytes\n",
       "timestamp                                                                   \n",
       "2018-08-15 19:35:11                375               3.14   273          471\n",
       "2018-08-15 19:35:12                428               3.59   145          376\n",
       "2018-08-15 19:35:13                360               3.02   148          454\n",
       "2018-08-15 19:35:14                339               2.84    83          407\n",
       "2018-08-15 19:35:15                305               2.56   104          414\n",
       "2018-08-15 19:35:16                301               2.53   186          440\n",
       "2018-08-15 19:35:17                325               2.73   174          485\n",
       "2018-08-15 19:35:18                434               3.64    81          677\n",
       "2018-08-15 19:35:19                412               3.46   226          537\n",
       "2018-08-15 19:35:20                409               3.43    47          372\n",
       "2018-08-15 19:35:21                523               3.81    96          422"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preberemo podatke\n",
    "iperf_data = pd.read_csv('data/iperf_clean.csv', parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "iperf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11 entries, 2018-08-15 19:35:11 to 2018-08-15 19:35:21\n",
      "Data columns (total 4 columns):\n",
      "transfer_mbytesec    11 non-null int64\n",
      "bandwidth_gbitsec    11 non-null float64\n",
      "retr                 11 non-null int64\n",
      "cwnd_kbytes          11 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 440.0 bytes\n"
     ]
    }
   ],
   "source": [
    "iperf_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branje in pisanje excel datotek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate working with multiple sheets from the same file, the ExcelFile class can be used to wrap the file and can be passed into read_excel There will be a performance benefit for reading multiple sheets as the file is read into memory only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sheet_names property will generate a list of the sheet names in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2002', '2004']\n"
     ]
    }
   ],
   "source": [
    "# Assign spreadsheet filename: file\n",
    "file = 'data/battledeath.xlsx'\n",
    "\n",
    "# Load spreadsheet: xls\n",
    "xls = pd.ExcelFile(file)\n",
    "\n",
    "# Print xlssheet names\n",
    "print(xls.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read an Excel file into a pandas DataFrame.\n",
    "\n",
    "Supports xls, xlsx, xlsm, xlsb, and odf file extensions read from a local filesystem or URL. Supports an option to read a single sheet or a list of sheets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pandas.read_excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2002 = pd.read_excel(xls, '2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>War, age-adjusted mortality due to</th>\n",
       "      <th>2002</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>36.083990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.128908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>18.314120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>18.964560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  War, age-adjusted mortality due to       2002\n",
       "0                        Afghanistan  36.083990\n",
       "1                            Albania   0.128908\n",
       "2                            Algeria  18.314120\n",
       "3                            Andorra   0.000000\n",
       "4                             Angola  18.964560"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2002.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ExcelFile class can also be used as a context manager. The primary use-case for an ExcelFile is parsing multiple sheets with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelFile(file) as xls:\n",
    "    df_2002 = pd.read_excel(xls, '2002', names=['Country', 'AAM due to War (2002)'], index_col='Country')\n",
    "    df_2004 = pd.read_excel(xls, '2004', names=['Country', 'War(2004)'], index_col='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAM due to War (2002)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>36.083990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.128908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAM due to War (2002)\n",
       "Country                           \n",
       "Afghanistan              36.083990\n",
       "Albania                   0.128908"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2002.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>War(2004)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>9.451028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.130354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             War(2004)\n",
       "Country               \n",
       "Afghanistan   9.451028\n",
       "Albania       0.130354"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2004.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ostali formati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are common situations that you may encounter while working with files. Most of these cases can be handled using other modules. Two common file types you may need to work with are .csv and .json. Real Python has already put together some great articles on how to handle these:\n",
    "- Reading and Writing CSV Files in Python\n",
    "- Working With JSON Data in Python\n",
    "\n",
    "Additionally, there are built-in libraries out there that you can use to help you:\n",
    "- wave: read and write WAV files (audio)\n",
    "- aifc: read and write AIFF and AIFC files (audio)\n",
    "- sunau: read and write Sun AU files\n",
    "- tarfile: read and write tar archive files\n",
    "- zipfile: work with ZIP archives\n",
    "- configparser: easily create and parse configuration files\n",
    "- xml.etree.ElementTree: create or read XML based files\n",
    "- msilib: read and write Microsoft Installer files\n",
    "- plistlib: generate and parse Mac OS X .plist files\n",
    "There are plenty more out there. Additionally there are even more third party tools available on PyPI. Some popular ones are the following:\n",
    "\n",
    "PyPDF2: \n",
    "- PDF toolkit\n",
    "- xlwings: read and write Excel files\n",
    "- Pillow: image reading and manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barvanje celic in izvoz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/version/0.20/whatsnew.html#excel-output-for-styled-dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def highlight_cols(value):\n",
    "    if value == True:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    return f'background-color: {color}'\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'rez1': [2, 4, 8, 0,10],\n",
    "                   'rez2': [2, 0, 0, 0,5],\n",
    "                   'uspesnost': [True, False, False, True, True]})\n",
    "\n",
    "styled = df.style.applymap(highlight_cols, subset=pd.IndexSlice[:, ['uspesnost']])\n",
    "styled.to_excel('data/styled.xlsx', engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
