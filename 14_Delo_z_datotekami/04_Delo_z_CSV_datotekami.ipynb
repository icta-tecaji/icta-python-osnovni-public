{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delo z CSV datotekami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s face it: you need to get information into and out of your programs through more than just the keyboard and console. Exchanging information through text files is a common way to share info between programs. One of the most popular formats for exchanging data is the CSV format. But how do you use it?\n",
    "\n",
    "Let’s get one thing clear: you don’t have to (and you won’t) build your own CSV parser from scratch. There are several perfectly acceptable libraries you can use. The Python csv library will work for most cases. If your work requires lots of data or numerical analysis, the pandas library has CSV parsing capabilities as well, which should handle the rest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is a CSV File?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CSV file (Comma Separated Values file) is a type of plain text file that uses specific structuring to arrange tabular data. Because it’s a plain text file, it can contain only actual text data—in other words, printable ASCII or Unicode characters.\n",
    "\n",
    "The structure of a CSV file is given away by its name. Normally, CSV files use a comma to separate each specific data value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each piece of data is separated by a comma. Normally, the first line identifies each piece of data—in other words, the name of a data column. Every subsequent line after that is actual data and is limited only by file size constraints.\n",
    "\n",
    "In general, the separator character is called a delimiter, and the comma is not the only one used. Other popular delimiters include the tab (\\t), colon (:) and semi-colon (;) characters. Properly parsing a CSV file requires us to know which delimiter is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files are normally created by programs that handle large amounts of data. They are a convenient way to export data from spreadsheets and databases as well as import or use it in other programs. For example, you might export the results of a data mining program to a CSV file and then import that into a spreadsheet to analyze the data, generate graphs for a presentation, or prepare a report for publication.\n",
    "\n",
    "CSV files are very easy to work with programmatically. Any language that supports text file input and string manipulation (like Python) can work with CSV files directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing CSV Files With Python’s Built-in CSV Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv library provides functionality to both read from and write to CSV files. Designed to work out of the box with Excel-generated CSV files, it is easily adapted to work with a variety of CSV formats. The csv library contains objects and other code to read, write, and process data from and to CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading CSV Files With csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a CSV file is done using the reader object. The CSV file is opened as a text file with Python’s built-in open() function, which returns a file object. This is then passed to the reader, which does the heavy lifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s code to read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, department, birthday month\n",
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 3 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/employee_birthday.txt') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row returned by the reader is a list of String elements containing the data found by removing the delimiters. The first row returned contains the column names, which is handled in a special way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing CSV Files With csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also write to a CSV file using a writer object and the .write_row() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/employee_file1.csv', mode='w') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',')\n",
    "\n",
    "    employee_writer.writerow(['John Smith', 'Accounting', 'November'])\n",
    "    employee_writer.writerow(['Erica Meyers', 'IT', 'March'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uvod v pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Namestimo pandas v virtualno okolje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><p>In the last two missions, we explored how the NumPy library makes working with data easier. Because we can easily work across multiple dimensions, our code is a lot easier to understand. By using vectorized operations instead of loops, our code runs faster with larger data.</p>\n",
    "<p>Although NumPy provides fundamental structures and tools that make working with data easier, there are several things that limit its usefulness:</p>\n",
    "<ul>\n",
    "<li>The lack of support for column names forces us to frame questions as multi-dimensional array operations.</li>\n",
    "<li>Support for only one data type per ndarray makes it more difficult to work with data that contains both numeric and string data.</li>\n",
    "<li>There are lots of low level methods, but there are many common analysis patterns that don't have pre-built methods.</li>\n",
    "</ul>\n",
    "<p>The <strong>pandas</strong> library provides solutions to all of these pain points and more. Pandas is not so much a replacement for NumPy as an <em>extension</em> of NumPy. The underlying code for pandas uses the NumPy library extensively, which means the concepts you've been learning will come in handy as you begin to learn more about pandas.</p>\n",
    "<p>The primary data structure in pandas is called a <a target=\"_blank\" href=\"(http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame)\"><strong>dataframe</strong></a>. Dataframes are the pandas equivalent of a Numpy 2D ndarray, with a few key differences:</p>\n",
    "<ul>\n",
    "<li>Axis values can have string <strong>labels</strong>, not just numeric ones.</li>\n",
    "<li>Dataframes can contain columns with <strong>multiple data types</strong>: including integer, float, and string.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is an open-source Python Library providing high-performance data manipulation and analysis tool using its powerful data structures. The name Pandas is derived from the word Panel Data – an Econometrics from Multidimensional data.\n",
    "\n",
    "In 2008, developer Wes McKinney started developing pandas when in need of high performance, flexible tool for analysis of data.\n",
    "\n",
    "Prior to Pandas, Python was majorly used for data munging and preparation. It had very little contribution towards data analysis. Pandas solved this problem. Using Pandas, we can accomplish five typical steps in the processing and analysis of data, regardless of the origin of data — load, prepare, manipulate, model, and analyze.\n",
    "\n",
    "Python with Pandas is used in a wide range of fields including academic and commercial domains including finance, economics, Statistics, analytics, etc.\n",
    "\n",
    "Key Features of Pandas\n",
    "- Fast and efficient DataFrame object with default and customized indexing.\n",
    "- Tools for loading data into in-memory data objects from different file formats.\n",
    "- Data alignment and integrated handling of missing data.\n",
    "- Reshaping and pivoting of date sets.\n",
    "- Label-based slicing, indexing and subsetting of large data sets.\n",
    "- Columns from a data structure can be deleted or inserted.\n",
    "- Group by data for aggregation and transformations.\n",
    "- High performance merging and joining of data.\n",
    "- Time Series functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the import convention for NumPy (import numpy as np), the import convention for pandas is:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f500 = pd.read_csv('data/f500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>rank</th>\n",
       "      <th>revenues</th>\n",
       "      <th>revenue_change</th>\n",
       "      <th>profits</th>\n",
       "      <th>assets</th>\n",
       "      <th>profit_change</th>\n",
       "      <th>ceo</th>\n",
       "      <th>industry</th>\n",
       "      <th>sector</th>\n",
       "      <th>previous_rank</th>\n",
       "      <th>country</th>\n",
       "      <th>hq_location</th>\n",
       "      <th>website</th>\n",
       "      <th>years_on_global_500_list</th>\n",
       "      <th>employees</th>\n",
       "      <th>total_stockholder_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>1</td>\n",
       "      <td>485873</td>\n",
       "      <td>0.8</td>\n",
       "      <td>13643.0</td>\n",
       "      <td>198825</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>C. Douglas McMillon</td>\n",
       "      <td>General Merchandisers</td>\n",
       "      <td>Retailing</td>\n",
       "      <td>1</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bentonville, AR</td>\n",
       "      <td>http://www.walmart.com</td>\n",
       "      <td>23</td>\n",
       "      <td>2300000</td>\n",
       "      <td>77798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State Grid</td>\n",
       "      <td>2</td>\n",
       "      <td>315199</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>9571.3</td>\n",
       "      <td>489838</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>Kou Wei</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Energy</td>\n",
       "      <td>2</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>http://www.sgcc.com.cn</td>\n",
       "      <td>17</td>\n",
       "      <td>926067</td>\n",
       "      <td>209456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sinopec Group</td>\n",
       "      <td>3</td>\n",
       "      <td>267518</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>1257.9</td>\n",
       "      <td>310726</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>Wang Yupu</td>\n",
       "      <td>Petroleum Refining</td>\n",
       "      <td>Energy</td>\n",
       "      <td>4</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>http://www.sinopec.com</td>\n",
       "      <td>19</td>\n",
       "      <td>713288</td>\n",
       "      <td>106523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company  rank  revenues  revenue_change  profits  assets  \\\n",
       "0        Walmart     1    485873             0.8  13643.0  198825   \n",
       "1     State Grid     2    315199            -4.4   9571.3  489838   \n",
       "2  Sinopec Group     3    267518            -9.1   1257.9  310726   \n",
       "\n",
       "   profit_change                  ceo               industry     sector  \\\n",
       "0           -7.2  C. Douglas McMillon  General Merchandisers  Retailing   \n",
       "1           -6.2              Kou Wei              Utilities     Energy   \n",
       "2          -65.0            Wang Yupu     Petroleum Refining     Energy   \n",
       "\n",
       "   previous_rank country      hq_location                 website  \\\n",
       "0              1     USA  Bentonville, AR  http://www.walmart.com   \n",
       "1              2   China   Beijing, China  http://www.sgcc.com.cn   \n",
       "2              4   China   Beijing, China  http://www.sinopec.com   \n",
       "\n",
       "   years_on_global_500_list  employees  total_stockholder_equity  \n",
       "0                        23    2300000                     77798  \n",
       "1                        17     926067                    209456  \n",
       "2                        19     713288                    106523  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f500.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pokažemo osnovne metode za pregled podatkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas I/O API is a set of top level reader functions accessed like pandas.read_csv() that generally return a pandas object. The corresponding writer functions are object methods that are accessed like DataFrame.to_csv(). Below is a table containing available readers and writers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IO tools (text, CSV, HDF5, …)](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"colwidths-given table\">\n",
    "<colgroup>\n",
    "<col style=\"width: 12%\">\n",
    "<col style=\"width: 40%\">\n",
    "<col style=\"width: 24%\">\n",
    "<col style=\"width: 24%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Format Type</p></th>\n",
    "<th class=\"head\"><p>Data Description</p></th>\n",
    "<th class=\"head\"><p>Reader</p></th>\n",
    "<th class=\"head\"><p>Writer</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p>text</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-read-csv-table\"><span class=\"std std-ref\">read_csv</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-store-in-csv\"><span class=\"std std-ref\">to_csv</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>text</p></td>\n",
    "<td><p>Fixed-Width Text File</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-fwf-reader\"><span class=\"std std-ref\">read_fwf</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>text</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://www.json.org/\">JSON</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-json-reader\"><span class=\"std std-ref\">read_json</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-json-writer\"><span class=\"std std-ref\">to_json</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>text</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/HTML\">HTML</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-read-html\"><span class=\"std std-ref\">read_html</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-html\"><span class=\"std std-ref\">to_html</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>text</p></td>\n",
    "<td><p>Local clipboard</p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-clipboard\"><span class=\"std std-ref\">read_clipboard</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-clipboard\"><span class=\"std std-ref\">to_clipboard</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Microsoft_Excel\">MS Excel</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-excel-reader\"><span class=\"std std-ref\">read_excel</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-excel-writer\"><span class=\"std std-ref\">to_excel</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"http://www.opendocumentformat.org\">OpenDocument</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-ods\"><span class=\"std std-ref\">read_excel</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://support.hdfgroup.org/HDF5/whatishdf5.html\">HDF5 Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-hdf5\"><span class=\"std std-ref\">read_hdf</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-hdf5\"><span class=\"std std-ref\">to_hdf</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://github.com/wesm/feather\">Feather Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-feather\"><span class=\"std std-ref\">read_feather</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-feather\"><span class=\"std std-ref\">to_feather</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://parquet.apache.org/\">Parquet Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-parquet\"><span class=\"std std-ref\">read_parquet</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-parquet\"><span class=\"std std-ref\">to_parquet</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"//https://orc.apache.org/\">ORC Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-orc\"><span class=\"std std-ref\">read_orc</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://msgpack.org/index.html\">Msgpack</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-msgpack\"><span class=\"std std-ref\">read_msgpack</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-msgpack\"><span class=\"std std-ref\">to_msgpack</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/Stata\">Stata</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-stata-reader\"><span class=\"std std-ref\">read_stata</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-stata-writer\"><span class=\"std std-ref\">to_stata</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SAS_(software)\">SAS</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-sas-reader\"><span class=\"std std-ref\">read_sas</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SPSS\">SPSS</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-spss-reader\"><span class=\"std std-ref\">read_spss</span></a></p></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>binary</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://docs.python.org/3/library/pickle.html\">Python Pickle Format</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-pickle\"><span class=\"std std-ref\">read_pickle</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-pickle\"><span class=\"std std-ref\">to_pickle</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p>SQL</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/SQL\">SQL</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-sql\"><span class=\"std std-ref\">read_sql</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-sql\"><span class=\"std std-ref\">to_sql</span></a></p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p>SQL</p></td>\n",
    "<td><p><a class=\"reference external\" href=\"https://en.wikipedia.org/wiki/BigQuery\">Google BigQuery</a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-bigquery\"><span class=\"std std-ref\">read_gbq</span></a></p></td>\n",
    "<td><p><a class=\"reference internal\" href=\"#io-bigquery\"><span class=\"std std-ref\">to_gbq</span></a></p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing CSV Files With the pandas Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the Python CSV library isn’t the only game in town. Reading CSV files is possible in pandas as well. It is highly recommended if you have a lot of data to analyze.\n",
    "\n",
    "pandas is an open-source Python library that provides high performance data analysis tools and easy to use data structures. pandas is available for all Python installations, but it is a key part of the Anaconda distribution and works extremely well in Jupyter notebooks to share data, code, analysis results, visualizations, and narrative text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the CSV into a pandas DataFrame is quick and straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Sick Days remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graham Chapman</td>\n",
       "      <td>03/15/14</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Cleese</td>\n",
       "      <td>06/01/15</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eric Idle</td>\n",
       "      <td>05/12/14</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terry Jones</td>\n",
       "      <td>11/01/13</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terry Gilliam</td>\n",
       "      <td>08/12/14</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael Palin</td>\n",
       "      <td>05/23/13</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Hire Date   Salary  Sick Days remaining\n",
       "0  Graham Chapman  03/15/14  50000.0                   10\n",
       "1     John Cleese  06/01/15  65000.0                    8\n",
       "2       Eric Idle  05/12/14  45000.0                   10\n",
       "3     Terry Jones  11/01/13  70000.0                    3\n",
       "4   Terry Gilliam  08/12/14  48000.0                    7\n",
       "5   Michael Palin  05/23/13  66000.0                    8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('data/hrdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s it: three lines of code, and only one of them is doing the actual work. pandas.read_csv() opens, analyzes, and reads the CSV file provided, and stores the data in a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrinting data to json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/hrdata.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\":{\"Name\":\"Graham Chapman\",\"Hire Date\":\"03\\/15\\/14\",\"Salary\":50000.0,\"Sick Days remaining\":10},\"1\":{\"Name\":\"John Cleese\",\"Hire Date\":\"06\\/01\\/15\",\"Salary\":65000.0,\"Sick Days remaining\":8},\"2\":{\"Name\":\"Eric Idle\",\"Hire Date\":\"05\\/12\\/14\",\"Salary\":45000.0,\"Sick Days remaining\":10},\"3\":{\"Name\":\"Terry Jones\",\"Hire Date\":\"11\\/01\\/13\",\"Salary\":70000.0,\"Sick Days remaining\":3},\"4\":{\"Name\":\"Terry Gilliam\",\"Hire Date\":\"08\\/12\\/14\",\"Salary\":48000.0,\"Sick Days remaining\":7},\"5\":{\"Name\":\"Michael Palin\",\"Hire Date\":\"05\\/23\\/13\",\"Salary\":66000.0,\"Sick Days remaining\":8}}"
     ]
    }
   ],
   "source": [
    "! cat data/hrdata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 1: seaslug.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaslug = pd.read_csv('data/seaslug.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  Percent\n",
       "0    99    0.067\n",
       "1    99    0.133\n",
       "2    99    0.067\n",
       "3    99    0.000\n",
       "4    99    0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaslug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `sep: str, defaults to ',' for read_csv(), \\t for read_table()`: Delimiter to use. If sep is None, the C engine cannot automatically detect the separator, but the Python parsing engine can, meaning the latter will be used and automatically detect the separator by Python’s builtin sniffer tool, csv.Sniffer. In addition, separators longer than 1 character and different from '\\s+' will be interpreted as regular expressions and will also force the use of the Python parsing engine. Note that regex delimiters are prone to ignoring quoted data. Regex example: '\\\\r\\\\t'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `delimiter: str, default None`: Alias for sep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 2: FOOD_DES.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding: `iso-8859-1`, separator: `^`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~01001~^~0100~^~Butter, salted~^~BUTTER,WITH SALT~^~~^~~^~Y~^~~^0^~~^6.38^4.27^8.79^3.87\r\n",
      "\r\n",
      "~01002~^~0100~^~Butter, whipped, with salt~^~BUTTER,WHIPPED,W/ SALT~^~~^~~^~Y~^~~^0^~~^6.38^^^\r\n",
      "\r\n",
      "~01003~^~0100~^~Butter oil, anhydrous~^~BUTTER OIL,ANHYDROUS~^~~^~~^~Y~^~~^0^~~^6.38^4.27^8.79^3.87\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 ./data/FOOD_DES.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Turns out the file, instead of using commas to separate the fields, uses carets ^.\n",
    "- By some reason, USDA people thought separating strings with tildes ~ was a good idea. Thankfully, we can use the quotechar argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>100</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>BUTTER,WITH SALT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>100</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>BUTTER,WHIPPED,W/ SALT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>100</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>BUTTER OIL,ANHYDROUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>100</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>CHEESE,BLUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>100</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>CHEESE,BRICK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.79</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1                           2                       3   4   5  6   \\\n",
       "0  1001  100              Butter, salted        BUTTER,WITH SALT NaN NaN  Y   \n",
       "1  1002  100  Butter, whipped, with salt  BUTTER,WHIPPED,W/ SALT NaN NaN  Y   \n",
       "2  1003  100       Butter oil, anhydrous    BUTTER OIL,ANHYDROUS NaN NaN  Y   \n",
       "3  1004  100                Cheese, blue             CHEESE,BLUE NaN NaN  Y   \n",
       "4  1005  100               Cheese, brick            CHEESE,BRICK NaN NaN  Y   \n",
       "\n",
       "   7   8   9     10    11    12    13  \n",
       "0 NaN   0 NaN  6.38  4.27  8.79  3.87  \n",
       "1 NaN   0 NaN  6.38   NaN   NaN   NaN  \n",
       "2 NaN   0 NaN  6.38  4.27  8.79  3.87  \n",
       "3 NaN   0 NaN  6.38  4.27  8.79  3.87  \n",
       "4 NaN   0 NaN  6.38  4.27  8.79  3.87  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv('data/FOOD_DES.txt', sep='^', encoding='iso-8859-1', header=None, nrows=5, quotechar='~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `nrows: int, default None` Number of rows of file to read. Useful for reading pieces of large files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `header: int or list of ints, default 'infer'` Row number(s) to use as the column names, and the start of the data. Default behavior is to infer the column names: if no names are passed the behavior is identical to header=0 and column names are inferred from the first line of the file, if column names are passed explicitly then the behavior is identical to header=None. Explicitly pass header=0 to be able to replace existing names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encoding: str, default None` Encoding to use for UTF when reading/writing (e.g. 'utf-8'). [List of Python standard encodings](https://docs.python.org/3/library/codecs.html#standard-encodings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `quotechar: str (length 1)`: The character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 3: MplsStops.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0,id Num,date,problem,MDC,citation Issued,person Search,vehicle Search,pre Race,race,gender,lat,long,police Precinct,neighborhood\r\n",
      ",idNum,date,problem,MDC,citationIssued,personSearch,vehicleSearch,preRace,race,gender,lat,long,policePrecinct,neighborhood\r\n",
      "6823.0,17-000003,2017-01-01 00:00:42,suspicious,MDC,,NO,NO,Unknown,Unknown,Unknown,44.96661711,-93.24645826,1,Cedar Riverside\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 ./data/mpls_stops.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id Num</th>\n",
       "      <th>date</th>\n",
       "      <th>problem</th>\n",
       "      <th>MDC</th>\n",
       "      <th>citation Issued</th>\n",
       "      <th>person Search</th>\n",
       "      <th>vehicle Search</th>\n",
       "      <th>pre Race</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>police Precinct</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>idNum</td>\n",
       "      <td>date</td>\n",
       "      <td>problem</td>\n",
       "      <td>MDC</td>\n",
       "      <td>citationIssued</td>\n",
       "      <td>personSearch</td>\n",
       "      <td>vehicleSearch</td>\n",
       "      <td>preRace</td>\n",
       "      <td>race</td>\n",
       "      <td>gender</td>\n",
       "      <td>lat</td>\n",
       "      <td>long</td>\n",
       "      <td>policePrecinct</td>\n",
       "      <td>neighborhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6823.0</td>\n",
       "      <td>17-000003</td>\n",
       "      <td>2017-01-01 00:00:42</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>44.96661711</td>\n",
       "      <td>-93.24645826</td>\n",
       "      <td>1</td>\n",
       "      <td>Cedar Riverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6824.0</td>\n",
       "      <td>17-000007</td>\n",
       "      <td>2017-01-01 00:03:07</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.98045</td>\n",
       "      <td>-93.27134</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id Num                 date     problem  MDC  \\\n",
       "0         NaN      idNum                 date     problem  MDC   \n",
       "1      6823.0  17-000003  2017-01-01 00:00:42  suspicious  MDC   \n",
       "2      6824.0  17-000007  2017-01-01 00:03:07  suspicious  MDC   \n",
       "\n",
       "  citation Issued person Search vehicle Search pre Race     race   gender  \\\n",
       "0  citationIssued  personSearch  vehicleSearch  preRace     race   gender   \n",
       "1             NaN            NO             NO  Unknown  Unknown  Unknown   \n",
       "2             NaN            NO             NO  Unknown  Unknown     Male   \n",
       "\n",
       "           lat          long police Precinct     neighborhood  \n",
       "0          lat          long  policePrecinct     neighborhood  \n",
       "1  44.96661711  -93.24645826               1  Cedar Riverside  \n",
       "2     44.98045     -93.27134               1    Downtown West  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpls = pd.read_csv('data/mpls_stops.csv', nrows=3)\n",
    "mpls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id Num', 'date', 'problem', 'MDC', 'citation Issued',\n",
       "       'person Search', 'vehicle Search', 'pre Race', 'race', 'gender', 'lat',\n",
       "       'long', 'police Precinct', 'neighborhood'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpls.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = ['Unnamed: 0', 'id Num', 'date', 'problem', 'MDC', 'citation Issued',\n",
    "       'person Search', 'vehicle Search', 'pre Race', 'race', 'gender', 'lat',\n",
    "       'long', 'police Precinct', 'neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case_number_id', 'id_num', 'date', 'problem', 'mdc', 'citation_issued', 'person_search', 'vehicle_search', 'pre_race', 'race', 'gender', 'lat', 'long', 'police_precinct', 'neighborhood']\n"
     ]
    }
   ],
   "source": [
    "new_column_names = [name.lower().replace(' ', '_') for name in new_column_names]\n",
    "new_column_names[0] = 'case_number_id'\n",
    "print(new_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_num</th>\n",
       "      <th>date</th>\n",
       "      <th>problem</th>\n",
       "      <th>mdc</th>\n",
       "      <th>citation_issued</th>\n",
       "      <th>person_search</th>\n",
       "      <th>vehicle_search</th>\n",
       "      <th>pre_race</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>police_precinct</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_number_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6823</th>\n",
       "      <td>17-000003</td>\n",
       "      <td>2017-01-01 00:00:42</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.966617</td>\n",
       "      <td>-93.246458</td>\n",
       "      <td>1</td>\n",
       "      <td>Cedar Riverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6824</th>\n",
       "      <td>17-000007</td>\n",
       "      <td>2017-01-01 00:03:07</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.980450</td>\n",
       "      <td>-93.271340</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6825</th>\n",
       "      <td>17-000073</td>\n",
       "      <td>2017-01-01 00:23:15</td>\n",
       "      <td>traffic</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.948350</td>\n",
       "      <td>-93.275380</td>\n",
       "      <td>5</td>\n",
       "      <td>Whittier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6826</th>\n",
       "      <td>17-000092</td>\n",
       "      <td>2017-01-01 00:33:48</td>\n",
       "      <td>suspicious</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East African</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.948360</td>\n",
       "      <td>-93.281350</td>\n",
       "      <td>5</td>\n",
       "      <td>Whittier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6827</th>\n",
       "      <td>17-000098</td>\n",
       "      <td>2017-01-01 00:37:58</td>\n",
       "      <td>traffic</td>\n",
       "      <td>MDC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.979078</td>\n",
       "      <td>-93.262076</td>\n",
       "      <td>1</td>\n",
       "      <td>Downtown West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id_num                date     problem  mdc  \\\n",
       "case_number_id                                                   \n",
       "6823            17-000003 2017-01-01 00:00:42  suspicious  MDC   \n",
       "6824            17-000007 2017-01-01 00:03:07  suspicious  MDC   \n",
       "6825            17-000073 2017-01-01 00:23:15     traffic  MDC   \n",
       "6826            17-000092 2017-01-01 00:33:48  suspicious  MDC   \n",
       "6827            17-000098 2017-01-01 00:37:58     traffic  MDC   \n",
       "\n",
       "                citation_issued  person_search  vehicle_search pre_race  \\\n",
       "case_number_id                                                            \n",
       "6823                        1.0            0.0             0.0      NaN   \n",
       "6824                        1.0            0.0             0.0      NaN   \n",
       "6825                        1.0            0.0             0.0      NaN   \n",
       "6826                        1.0            0.0             0.0      NaN   \n",
       "6827                        1.0            0.0             0.0      NaN   \n",
       "\n",
       "                        race  gender        lat       long  police_precinct  \\\n",
       "case_number_id                                                                \n",
       "6823                     NaN     NaN  44.966617 -93.246458                1   \n",
       "6824                     NaN    Male  44.980450 -93.271340                1   \n",
       "6825                   White  Female  44.948350 -93.275380                5   \n",
       "6826            East African    Male  44.948360 -93.281350                5   \n",
       "6827                   White  Female  44.979078 -93.262076                1   \n",
       "\n",
       "                   neighborhood  \n",
       "case_number_id                   \n",
       "6823            Cedar Riverside  \n",
       "6824              Downtown West  \n",
       "6825                   Whittier  \n",
       "6826                   Whittier  \n",
       "6827              Downtown West  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpls = pd.read_csv('data/mpls_stops.csv', \n",
    "                   names=new_column_names, \n",
    "                   skiprows=2, \n",
    "                   engine='c',\n",
    "                   true_values=['YES'],\n",
    "                   false_values=['NO'],\n",
    "                   dtype={'mdc': 'category', 'problem':'category', 'citation_issued': 'float',\n",
    "                         'person_search': 'float', 'vehicle_search': 'float',  'pre_race':'category'},\n",
    "                   index_col='case_number_id',\n",
    "                   parse_dates=['date'],\n",
    "                   date_parser=dateparse,\n",
    "                   na_values=['Unknown'])\n",
    "\n",
    "mpls.index = mpls.index.astype('int')\n",
    "mpls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `names: array-like, default None` List of column names to use. If file contains no header row, then you should explicitly pass header=None. Duplicates in this list are not allowed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `skiprows: list-like or integer, default None` Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `engine: {'c', 'python'}` Parser engine to use. The C engine is faster while the Python engine is currently more feature-complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 ms ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mpls = pd.read_csv('data/mpls_stops.csv', names=new_column_names, skiprows=2, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 ms ± 3.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mpls = pd.read_csv('data/mpls_stops.csv', names=new_column_names, skiprows=2, engine='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `true_values: list, default None` Values to consider as True.\n",
    "- `false_values: list, default None` Values to consider as False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `index_col: int, str, sequence of int / str, or False, default None` Column(s) to use as the row labels of the DataFrame, either given as string name or column index. If a sequence of int / str is given, a MultiIndex is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dtype: Type name or dict of column -> type, default None` Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32} (unsupported with engine='python'). Use str or object together with suitable na_values settings to preserve and not interpret dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `parse_dates: boolean or list of ints or names or list of lists or dict, default False.` \n",
    "    - If True -> try parsing the index.\n",
    "    - If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
    "    - If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
    "    - If {'foo': [1, 3]} -> parse columns 1, 3 as date and call result ‘foo’. A fast-path exists for iso8601-formatted dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `date_parserfunction, default None` Function to use for converting a sequence of string columns to an array of datetime instances. The default uses dateutil.parser.parser to do the conversion. pandas will try to call date_parser in three different ways, advancing to the next if an exception occurs: 1) Pass one or more arrays (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string values from the columns defined by parse_dates into a single array and pass that; and 3) call date_parser once for each row using one or more strings (corresponding to the columns defined by parse_dates) as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `na_values: scalar, str, list-like, or dict, default None` Additional strings to recognize as NA/NaN. If dict passed, specific per-column NA values. See na values const below for a list of the values interpreted as NaN by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primer 4: iperf.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 15 19:35:11 CEST 2018\r\n",
      "Connecting to host x.x.x.x, port 5201\r\n",
      "[  4] local x.x.x.x port 48944 connected to x.x.x.x port 5201\r\n",
      "[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd\r\n",
      "[  4]   0.00-1.00   sec   375 MBytes  3.14 Gbits/sec  273    471 KBytes\r\n",
      "[  4]   1.00-2.00   sec   428 MBytes  3.59 Gbits/sec  145    376 KBytes\r\n",
      "[  4]   2.00-3.00   sec   360 MBytes  3.02 Gbits/sec  148    454 KBytes\r\n",
      "[  4]   3.00-4.00   sec   339 MBytes  2.84 Gbits/sec   83    407 KBytes\r\n",
      "[  4]   4.00-5.00   sec   305 MBytes  2.56 Gbits/sec  104    414 KBytes\r\n",
      "[  4]   5.00-6.00   sec   301 MBytes  2.53 Gbits/sec  186    440 KBytes\r\n"
     ]
    }
   ],
   "source": [
    "!head data/iperf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Želimo stolpce: \n",
    "- timestamp, transfer_mbytesec, bandwidth_gbitsec, retr, cwnd_kbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vidimo da ne gre\n",
    "#pd.read_csv('data/iperf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preberemo podatke v list\n",
    "with open('data/iperf.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = [line.strip() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wed Aug 15 19:35:11 CEST 2018', 'Connecting to host x.x.x.x, port 5201', '[  4] local x.x.x.x port 48944 connected to x.x.x.x port 5201', '[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd', '[  4]   0.00-1.00   sec   375 MBytes  3.14 Gbits/sec  273    471 KBytes', '[  4]   1.00-2.00   sec   428 MBytes  3.59 Gbits/sec  145    376 KBytes', '[  4]   2.00-3.00   sec   360 MBytes  3.02 Gbits/sec  148    454 KBytes', '[  4]   3.00-4.00   sec   339 MBytes  2.84 Gbits/sec   83    407 KBytes', '[  4]   4.00-5.00   sec   305 MBytes  2.56 Gbits/sec  104    414 KBytes', '[  4]   5.00-6.00   sec   301 MBytes  2.53 Gbits/sec  186    440 KBytes', '[  4]   6.00-7.00   sec   325 MBytes  2.73 Gbits/sec  174    485 KBytes', '[  4]   7.00-8.00   sec   434 MBytes  3.64 Gbits/sec   81    677 KBytes', '[  4]   8.00-9.00   sec   412 MBytes  3.46 Gbits/sec  226    537 KBytes', '[  4]   9.00-10.00  sec   409 MBytes  3.43 Gbits/sec   47    372 KBytes', '[  4]   10.00-11.00  sec   523 MBytes  3.81 Gbits/sec   96    422 KBytes']\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-15 19:35:11 <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "# izluščimo začetni čas -> tabela https://www.journaldev.com/23365/python-string-to-datetime-strptime\n",
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.strptime(data[0], '%a %b %d %H:%M:%S CEST %Y')\n",
    "print(start_time, type(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.datetime(2018, 8, 15, 19, 35, 11), 375, 3.14, 273, 471), (datetime.datetime(2018, 8, 15, 19, 35, 12), 428, 3.59, 145, 376), (datetime.datetime(2018, 8, 15, 19, 35, 13), 360, 3.02, 148, 454), (datetime.datetime(2018, 8, 15, 19, 35, 14), 339, 2.84, 83, 407), (datetime.datetime(2018, 8, 15, 19, 35, 15), 305, 2.56, 104, 414), (datetime.datetime(2018, 8, 15, 19, 35, 16), 301, 2.53, 186, 440), (datetime.datetime(2018, 8, 15, 19, 35, 17), 325, 2.73, 174, 485), (datetime.datetime(2018, 8, 15, 19, 35, 18), 434, 3.64, 81, 677), (datetime.datetime(2018, 8, 15, 19, 35, 19), 412, 3.46, 226, 537), (datetime.datetime(2018, 8, 15, 19, 35, 20), 409, 3.43, 47, 372), (datetime.datetime(2018, 8, 15, 19, 35, 21), 523, 3.81, 96, 422)]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for line in data[4:]:\n",
    "    line_splited = line.split()\n",
    "    # seconds to add to start time\n",
    "    add_seconds = int(line_splited[2].split('.')[0])\n",
    "    timestamp = start_time + datetime.timedelta(seconds=add_seconds)\n",
    "    transfer_mbytesec = int(line_splited[4])\n",
    "    bandwidth_gbitsec = float(line_splited[6])\n",
    "    retr = int(line_splited[8])\n",
    "    cwnd_kbytes = int(line_splited[9])\n",
    "    rows.append((timestamp, transfer_mbytesec, bandwidth_gbitsec, retr, cwnd_kbytes))\n",
    "    \n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podatke vpišemo v novo datoteko\n",
    "import csv\n",
    "\n",
    "headers = ['timestamp', 'transfer_mbytesec', 'bandwidth_gbitsec', 'retr', 'cwnd_kbytes']\n",
    "\n",
    "with open('data/iperf_clean.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transfer_mbytesec</th>\n",
       "      <th>bandwidth_gbitsec</th>\n",
       "      <th>retr</th>\n",
       "      <th>cwnd_kbytes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:11</th>\n",
       "      <td>375</td>\n",
       "      <td>3.14</td>\n",
       "      <td>273</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:12</th>\n",
       "      <td>428</td>\n",
       "      <td>3.59</td>\n",
       "      <td>145</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:13</th>\n",
       "      <td>360</td>\n",
       "      <td>3.02</td>\n",
       "      <td>148</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:14</th>\n",
       "      <td>339</td>\n",
       "      <td>2.84</td>\n",
       "      <td>83</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:15</th>\n",
       "      <td>305</td>\n",
       "      <td>2.56</td>\n",
       "      <td>104</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:16</th>\n",
       "      <td>301</td>\n",
       "      <td>2.53</td>\n",
       "      <td>186</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:17</th>\n",
       "      <td>325</td>\n",
       "      <td>2.73</td>\n",
       "      <td>174</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:18</th>\n",
       "      <td>434</td>\n",
       "      <td>3.64</td>\n",
       "      <td>81</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:19</th>\n",
       "      <td>412</td>\n",
       "      <td>3.46</td>\n",
       "      <td>226</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:20</th>\n",
       "      <td>409</td>\n",
       "      <td>3.43</td>\n",
       "      <td>47</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-15 19:35:21</th>\n",
       "      <td>523</td>\n",
       "      <td>3.81</td>\n",
       "      <td>96</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     transfer_mbytesec  bandwidth_gbitsec  retr  cwnd_kbytes\n",
       "timestamp                                                                   \n",
       "2018-08-15 19:35:11                375               3.14   273          471\n",
       "2018-08-15 19:35:12                428               3.59   145          376\n",
       "2018-08-15 19:35:13                360               3.02   148          454\n",
       "2018-08-15 19:35:14                339               2.84    83          407\n",
       "2018-08-15 19:35:15                305               2.56   104          414\n",
       "2018-08-15 19:35:16                301               2.53   186          440\n",
       "2018-08-15 19:35:17                325               2.73   174          485\n",
       "2018-08-15 19:35:18                434               3.64    81          677\n",
       "2018-08-15 19:35:19                412               3.46   226          537\n",
       "2018-08-15 19:35:20                409               3.43    47          372\n",
       "2018-08-15 19:35:21                523               3.81    96          422"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preberemo podatke\n",
    "iperf_data = pd.read_csv('data/iperf_clean.csv', parse_dates=['timestamp'], index_col=['timestamp'])\n",
    "iperf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11 entries, 2018-08-15 19:35:11 to 2018-08-15 19:35:21\n",
      "Data columns (total 4 columns):\n",
      "transfer_mbytesec    11 non-null int64\n",
      "bandwidth_gbitsec    11 non-null float64\n",
      "retr                 11 non-null int64\n",
      "cwnd_kbytes          11 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 440.0 bytes\n"
     ]
    }
   ],
   "source": [
    "iperf_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
